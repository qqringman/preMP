#!/usr/bin/env python3
"""
Manifest Pinning Tool - è‡ªå‹•åŒ–å®šç‰ˆå·¥å…· (æ”¹é€²ç‰ˆ)
ç”¨æ–¼å¾ SFTP ä¸‹è¼‰ manifest æª”æ¡ˆä¸¦åŸ·è¡Œ repo å®šç‰ˆæ“ä½œ
ä¿®æ­£ç‰ˆæœ¬ï¼šè§£æ±ºé‚è¼¯ç¼ºé™·ä¸¦æ”¹å–„æ¨¡çµ„åŒ–è¨­è¨ˆ
"""

from enum import Enum
import os
import sys
import argparse
import pandas as pd
import paramiko
import subprocess
import json
import re
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
import time
import logging
from dataclasses import dataclass, field, asdict
import signal
import atexit
from contextlib import contextmanager
from collections import defaultdict
import random
import socket
from threading import Semaphore, Lock

# =====================================
# ===== ç‰ˆæœ¬è³‡è¨Š =====
# =====================================
__version__ = '2.0.0'
__author__ = 'Vince Lin'
__date__ = '2024-12-19'

# =====================================
# ===== é…ç½®ç®¡ç†å™¨ï¼ˆé›†ä¸­ç®¡ç†æ‰€æœ‰é…ç½®ï¼‰ =====
# =====================================

class ConfigManager:
    """é…ç½®ç®¡ç†å™¨ - çµ±ä¸€ç®¡ç†æ‰€æœ‰é…ç½®çš„å„ªå…ˆç´šå’Œä¾†æº"""
    
    def __init__(self):
        # åŸºç¤é…ç½®
        self.sftp_config = {
            'host': 'mmsftpx.realtek.com',
            'port': 22,
            'username': 'lgwar_user',
            'password': 'Ab!123456',
            'timeout': 45,
            'retry_count': 5,
            'retry_delay': 10
        }
        
        self.jira_config = {
            'site': 'jira.realtek.com',
            'username': 'vince_lin',
            'password': 'Amon200!Amon200!',
            'api_url': 'https://jira.realtek.com/rest/api/2'
        }
        
        self.path_config = {
            'default_output_dir': './DB-source',
            'default_mapping_table': '../all_chip_mapping_table.xlsx',
            'manifest_pattern': r'manifest_(\d+)\.xml',
            'report_filename': 'pinning_report.xlsx',
            'progress_update_interval': 1
        }
        
        self.repo_config = {
            'repo_command': 'repo',
            'sync_jobs': 8,
            'sync_retry': 2,
            'init_timeout': 60,
            'sync_timeout': 7200,
            'async_sync': True,
            'show_sync_output': False
        }
        
        self.parallel_config = {
            'max_workers': 4,
            'enable_parallel': True,
        }
        
        self.log_config = {
            'level': logging.INFO,
            'format': '%(asctime)s - [%(levelname)s] - %(name)s - %(message)s',
            'date_format': '%Y-%m-%d %H:%M:%S'
        }
        
        # é è¨­åŸ·è¡Œé…ç½®
        self.default_execution_config = {
            'mapping_table': os.path.join(os.path.dirname(__file__), '..', 'all_chip_mapping_table.xlsx'),
            'db_type': 'all',
            'selected_dbs': ['DB2145', 'DB2858', 'DB2575', 'DB2919'],
            'db_versions': {},
            'output_dir': './DB-source',
            'auto_confirm': False,
            'sftp_override': {}
        }
        
        # é…ç½®å„ªå…ˆç´šè¿½è¹¤
        self.config_sources = {}
        
    def apply_overrides(self, overrides: Dict[str, Any], source: str = 'user'):
        """æ‡‰ç”¨é…ç½®è¦†è“‹ä¸¦è¨˜éŒ„ä¾†æº"""
        for key, value in overrides.items():
            if value is not None:
                self.config_sources[key] = source
                # æ ¹æ“š key æ›´æ–°å°æ‡‰çš„é…ç½®
                if key.startswith('sftp_'):
                    sftp_key = key.replace('sftp_', '')
                    if sftp_key in self.sftp_config:
                        self.sftp_config[sftp_key] = value
                elif key.startswith('repo_'):
                    repo_key = key.replace('repo_', '')
                    if repo_key in self.repo_config:
                        self.repo_config[repo_key] = value
                elif key.startswith('parallel_'):
                    parallel_key = key.replace('parallel_', '')
                    if parallel_key in self.parallel_config:
                        self.parallel_config[parallel_key] = value
    
    def get_config_source(self, key: str) -> str:
        """ç²å–é…ç½®é …çš„ä¾†æº"""
        return self.config_sources.get(key, 'default')
    
    def validate_config(self) -> Tuple[bool, List[str]]:
        """é©—è­‰é…ç½®çš„å®Œæ•´æ€§å’Œåˆç†æ€§"""
        errors = []
        
        # é©—è­‰ SFTP é…ç½®
        if not self.sftp_config.get('host'):
            errors.append("SFTP host ä¸èƒ½ç‚ºç©º")
        if not self.sftp_config.get('username'):
            errors.append("SFTP username ä¸èƒ½ç‚ºç©º")
        
        # é©—è­‰è·¯å¾‘é…ç½®
        if not self.path_config.get('default_output_dir'):
            errors.append("è¼¸å‡ºç›®éŒ„ä¸èƒ½ç‚ºç©º")
        
        # é©—è­‰ä¸¦è¡Œé…ç½®
        if self.parallel_config['max_workers'] < 1:
            errors.append("max_workers å¿…é ˆå¤§æ–¼ 0")
        
        return len(errors) == 0, errors

# å…¨åŸŸé…ç½®ç®¡ç†å™¨å¯¦ä¾‹
config_manager = ConfigManager()

# =====================================
# ===== JIRA API å®¢æˆ¶ç«¯ï¼ˆæ–°å¢ï¼‰ =====
# =====================================

from jira import JIRA
import requests
from urllib.parse import quote
import urllib3

# é—œé–‰ SSL è­¦å‘Šï¼ˆå¦‚æœ JIRA ä½¿ç”¨è‡ªç°½æ†‘è­‰ï¼‰
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

class JiraAPIClient:
    """æ”¹å–„å¾Œçš„ JIRA API å®¢æˆ¶ç«¯ - é‡å° DB å‘½åæ…£ä¾‹å’Œ manifest æå–"""
    
    def __init__(self):
        self.logger = setup_logger(self.__class__.__name__)
        self.jira = None
        self.session = None
        self._connected = False
        self.base_url = f"https://{config_manager.jira_config['site']}"
        
    def _setup_logger(self):
        """è¨­å®šå°ˆç”¨çš„ logger"""
        logger = logging.getLogger(self.__class__.__name__)
        logger.setLevel(config_manager.log_config['level'])
        return logger
        
    def connect(self) -> bool:
        """é€£æ¥åˆ° JIRA"""
        try:
            username = config_manager.jira_config['username']
            password = config_manager.jira_config['password']
            
            self.logger.info(f"é€£æ¥åˆ° JIRA: {self.base_url}")
            
            # å»ºç«‹ session
            self.session = requests.Session()
            self.session.auth = (username, password)
            self.session.headers.update({
                'Accept': 'application/json',
                'Content-Type': 'application/json'
            })
            self.session.verify = False  # å¦‚æœæœ‰ SSL å•é¡Œ
            
            # æ¸¬è©¦é€£æ¥
            test_url = f"{self.base_url}/rest/api/2/myself"
            response = self.session.get(test_url)
            
            if response.status_code == 200:
                self._connected = True
                user_info = response.json()
                self.logger.info(f"JIRA é€£æ¥æˆåŠŸï¼Œç”¨æˆ¶: {user_info.get('displayName', username)}")
                return True
            elif response.status_code == 401:
                self.logger.error("JIRA èªè­‰å¤±æ•—ï¼Œè«‹æª¢æŸ¥ç”¨æˆ¶åå’Œå¯†ç¢¼")
                return False
            else:
                self.logger.error(f"JIRA é€£æ¥å¤±æ•—: HTTP {response.status_code}")
                return False
                
        except Exception as e:
            self.logger.error(f"JIRA é€£æ¥å¤±æ•—: {e}")
            return False

    def search_db_ticket(self, db_name: str, module: str = None) -> Optional[str]:
        """
        æ ¹æ“š DB å‘½åæ…£ä¾‹æœå°‹å°æ‡‰çš„ JIRA ticket
        
        Args:
            db_name: DB åç¨± (ä¾‹å¦‚: DB2302)
            module: æ¨¡çµ„åç¨± (ä¾‹å¦‚: Phoenix)
        
        Returns:
            æ‰¾åˆ°çš„ ticket key (ä¾‹å¦‚: MMQCDB-2302)
        """
        try:
            if not self._connected:
                if not self.connect():
                    return None
            
            # ç­–ç•¥ 1: æ ¹æ“š DB å‘½åæ…£ä¾‹ç›´æ¥æ§‹å»º ticket key
            ticket = self._search_by_naming_convention(db_name)
            if ticket:
                return ticket
            
            # ç­–ç•¥ 2: å¦‚æœå‘½åæ…£ä¾‹ä¸é©ç”¨ï¼Œä½¿ç”¨å‚³çµ±æœå°‹
            ticket = self._search_by_text(db_name, module)
            if ticket:
                return ticket
            
            self.logger.warning(f"æœªæ‰¾åˆ° {db_name} ç›¸é—œçš„ JIRA ticket")
            return None
            
        except Exception as e:
            self.logger.error(f"æœå°‹ JIRA ticket å¤±æ•—: {e}")
            return None

    def _search_by_naming_convention(self, db_name: str) -> Optional[str]:
        """æ ¹æ“š DB å‘½åæ…£ä¾‹ç›´æ¥æ§‹å»º ticket key"""
        try:
            # è§£æ DB åç¨±ï¼Œä¾‹å¦‚ DB2302 -> 2302
            db_number = db_name.replace('DB', '')
            
            # æ ¹æ“šå‘½åæ…£ä¾‹æ§‹å»ºå¯èƒ½çš„ ticket key
            possible_tickets = [
                f"MMQCDB-{db_number}",  # ä¸»è¦æ…£ä¾‹ï¼šMMQCDB-2302
                f"LGSWRD-{db_number}",  # å‚™ç”¨æ…£ä¾‹
                f"RTK-{db_number}",     # å‚™ç”¨æ…£ä¾‹
                f"DB-{db_number}",      # å‚™ç”¨æ…£ä¾‹
            ]
            
            for ticket_key in possible_tickets:
                self.logger.debug(f"æª¢æŸ¥ ticket æ˜¯å¦å­˜åœ¨: {ticket_key}")
                if self._check_ticket_exists(ticket_key):
                    self.logger.info(f"æ ¹æ“šå‘½åæ…£ä¾‹æ‰¾åˆ° ticket: {ticket_key}")
                    return ticket_key
            
            self.logger.debug(f"å‘½åæ…£ä¾‹æœå°‹æœªæ‰¾åˆ° {db_name} å°æ‡‰çš„ ticket")
            return None
            
        except Exception as e:
            self.logger.debug(f"å‘½åæ…£ä¾‹æœå°‹å¤±æ•—: {e}")
            return None

    def _check_ticket_exists(self, ticket_key: str) -> bool:
        """æª¢æŸ¥æŒ‡å®šçš„ ticket æ˜¯å¦å­˜åœ¨"""
        try:
            url = f"{self.base_url}/rest/api/2/issue/{ticket_key}"
            response = self.session.get(url)
            
            if response.status_code == 200:
                return True
            elif response.status_code == 404:
                return False
            else:
                self.logger.debug(f"æª¢æŸ¥ ticket {ticket_key} æ™‚ç™¼ç”ŸéŒ¯èª¤: HTTP {response.status_code}")
                return False
                
        except Exception as e:
            self.logger.debug(f"æª¢æŸ¥ ticket {ticket_key} å­˜åœ¨æ€§æ™‚ç™¼ç”Ÿç•°å¸¸: {e}")
            return False

    def _search_by_text(self, db_name: str, module: str = None) -> Optional[str]:
        """å‚³çµ±æ–‡å­—æœå°‹æ–¹å¼"""
        try:
            jql = f'text ~ "{db_name}"'
            
            if module:
                jql += f' AND text ~ "{module}"'
            
            jql += ' ORDER BY updated DESC'
            
            url = f"{self.base_url}/rest/api/2/search"
            params = {
                'jql': jql,
                'maxResults': 5,
                'fields': 'key,summary,description'
            }
            
            response = self.session.get(url, params=params)
            
            if response.status_code == 200:
                data = response.json()
                issues = data.get('issues', [])
                
                if issues:
                    ticket_key = issues[0]['key']
                    self.logger.info(f"é€éæ–‡å­—æœå°‹æ‰¾åˆ° {db_name} çš„ JIRA ticket: {ticket_key}")
                    return ticket_key
            
            return None
            
        except Exception as e:
            self.logger.error(f"æ–‡å­—æœå°‹å¤±æ•—: {e}")
            return None

    def get_source_command_from_ticket(self, ticket_key: str) -> Optional[str]:
        """
        å¾ JIRA ticket ä¸­æå– source command
        å°ˆé–€é‡å°åŒ…å« "-m" åƒæ•¸æˆ– [Latest] çš„ repo init å‘½ä»¤
        
        Args:
            ticket_key: JIRA ticket key (ä¾‹å¦‚: MMQCDB-2302)
        
        Returns:
            æ‰¾åˆ°çš„ repo init å‘½ä»¤
        """
        try:
            if not self._connected:
                if not self.connect():
                    return None
            
            url = f"{self.base_url}/rest/api/2/issue/{ticket_key}"
            response = self.session.get(url)
            
            if response.status_code == 200:
                data = response.json()
                fields = data.get('fields', {})
                
                # æª¢æŸ¥æè¿°æ¬„ä½
                description = fields.get('description', '')
                if description:
                    self.logger.debug(f"æª¢æŸ¥ {ticket_key} çš„æè¿°æ¬„ä½...")
                    
                    # 1. å„ªå…ˆå°‹æ‰¾ [Latest] å‘½ä»¤
                    cmd = self._extract_latest_repo_command(description)
                    if cmd:
                        self.logger.info(f"å¾ {ticket_key} çš„æè¿°ä¸­æ‰¾åˆ° [Latest] source command")
                        return cmd
                    
                    # 2. å°‹æ‰¾å¸¶ "-m" åƒæ•¸çš„å‘½ä»¤
                    cmd = self._extract_repo_command_with_manifest(description)
                    if cmd:
                        self.logger.info(f"å¾ {ticket_key} çš„æè¿°ä¸­æ‰¾åˆ°å¸¶ -m åƒæ•¸çš„ source command")
                        return cmd
                    
                    # 3. å°‹æ‰¾ä»»ä½• repo init å‘½ä»¤
                    cmd = self._extract_any_repo_command(description)
                    if cmd:
                        self.logger.info(f"å¾ {ticket_key} çš„æè¿°ä¸­æ‰¾åˆ° source command")
                        return cmd
                
                # æª¢æŸ¥è©•è«–
                comments_data = fields.get('comment', {})
                comments = comments_data.get('comments', [])
                for comment in comments:
                    body = comment.get('body', '')
                    if body:
                        cmd = self._extract_latest_repo_command(body)
                        if cmd:
                            self.logger.info(f"å¾ {ticket_key} çš„è©•è«–ä¸­æ‰¾åˆ° [Latest] source command")
                            return cmd
                        
                        cmd = self._extract_repo_command_with_manifest(body)
                        if cmd:
                            self.logger.info(f"å¾ {ticket_key} çš„è©•è«–ä¸­æ‰¾åˆ°å¸¶ -m åƒæ•¸çš„ source command")
                            return cmd
                
                self.logger.warning(f"åœ¨ ticket {ticket_key} ä¸­æœªæ‰¾åˆ° source command")
                return None
            
            elif response.status_code == 404:
                self.logger.warning(f"Ticket {ticket_key} ä¸å­˜åœ¨")
                return None
            else:
                self.logger.error(f"ç²å– ticket {ticket_key} å¤±æ•—: HTTP {response.status_code}")
                return None
                
        except Exception as e:
            self.logger.error(f"å¾ ticket {ticket_key} ç²å– source command å¤±æ•—: {e}")
            return None

    def _extract_latest_repo_command(self, text: str) -> Optional[str]:
        """
        æå–ä»¥ [Latest] é–‹é ­çš„ repo init å‘½ä»¤
        ä¾‹å¦‚ï¼š=> [Latest] repo init -u ssh://mm2sd.rtkbf.com:29418/realtek/android/manifest -b realtek/android-14/master -m atv-google-refplus.xml
        """
        if not text or 'repo init' not in text:
            return None
        
        lines = text.split('\n')
        for line in lines:
            line = line.strip()
            
            # å°‹æ‰¾åŒ…å« [Latest] å’Œ repo init çš„è¡Œ
            if '[Latest]' in line and 'repo init' in line:
                # æå– repo init å‘½ä»¤éƒ¨åˆ†
                repo_start = line.find('repo init')
                if repo_start != -1:
                    cmd = line[repo_start:].strip()
                    # æ¸…ç†å¯èƒ½çš„å°¾éš¨å­—ç¬¦
                    cmd = self._clean_command(cmd)
                    if self._is_valid_repo_command(cmd):
                        return cmd
        
        return None

    def _extract_repo_command_with_manifest(self, text: str) -> Optional[str]:
        """
        æå–åŒ…å« "-m" åƒæ•¸çš„ repo init å‘½ä»¤
        """
        if not text or 'repo init' not in text:
            return None
        
        lines = text.split('\n')
        for line in lines:
            line = line.strip()
            
            # å°‹æ‰¾åŒ…å« repo init å’Œ -m åƒæ•¸çš„è¡Œ
            if line.startswith('repo init') and ' -m ' in line:
                cmd = self._clean_command(line)
                if self._is_valid_repo_command(cmd):
                    return cmd
            
            # è™•ç†å¯èƒ½çš„å‰ç¶´ï¼ˆå¦‚ $, >, # ç­‰ï¼‰
            if 'repo init' in line and ' -m ' in line:
                repo_start = line.find('repo init')
                if repo_start != -1:
                    cmd = line[repo_start:].strip()
                    cmd = self._clean_command(cmd)
                    if self._is_valid_repo_command(cmd):
                        return cmd
        
        return None

    def _extract_any_repo_command(self, text: str) -> Optional[str]:
        """
        æå–ä»»ä½• repo init å‘½ä»¤
        """
        if not text or 'repo init' not in text:
            return None
        
        lines = text.split('\n')
        for line in lines:
            line = line.strip()
            
            if 'repo init' in line:
                repo_start = line.find('repo init')
                if repo_start != -1:
                    cmd = line[repo_start:].strip()
                    cmd = self._clean_command(cmd)
                    if self._is_valid_repo_command(cmd):
                        return cmd
        
        return None

    def _clean_command(self, cmd: str) -> str:
        """æ¸…ç†å‘½ä»¤å­—ç¬¦ä¸²"""
        # ç§»é™¤å¸¸è¦‹çš„å‰ç¶´
        prefixes = ['$', '>', '#', '//', '*', '-', '=>']
        for prefix in prefixes:
            if cmd.startswith(prefix):
                cmd = cmd[len(prefix):].strip()
        
        # ç§»é™¤å°¾éš¨çš„æ›è¡Œç¬¦å’Œç‰¹æ®Šå­—ç¬¦
        cmd = cmd.rstrip('\n\r\\')
        
        return cmd.strip()

    def _is_valid_repo_command(self, cmd: str) -> bool:
        """é©—è­‰æ˜¯å¦ç‚ºæœ‰æ•ˆçš„ repo init å‘½ä»¤"""
        if not cmd or not cmd.startswith('repo init'):
            return False
        
        # æª¢æŸ¥æ˜¯å¦åŒ…å«å¿…è¦çš„åƒæ•¸
        required_parts = ['-u', '-b']
        return all(part in cmd for part in required_parts)

    def disconnect(self):
        """æ–·é–‹ JIRA é€£æ¥"""
        self._connected = False
        if self.session:
            self.session.close()
            self.session = None
        self.logger.info("JIRA é€£æ¥å·²é—œé–‰")

# =====================================
# ===== æ—¥èªŒè¨­å®šå‡½å¼ =====
# =====================================

def setup_logger(name: str = __name__) -> logging.Logger:
    """è¨­å®šæ—¥èªŒè¨˜éŒ„å™¨"""
    logger = logging.getLogger(name)
    logger.setLevel(config_manager.log_config['level'])
    
    if not logger.handlers:
        # Console handler
        console_handler = logging.StreamHandler()
        console_handler.setLevel(config_manager.log_config['level'])
        
        # Formatter
        formatter = logging.Formatter(
            config_manager.log_config['format'],
            datefmt=config_manager.log_config['date_format']
        )
        console_handler.setFormatter(formatter)
        
        logger.addHandler(console_handler)
    
    return logger

logger = setup_logger(__name__)

# =====================================
# ===== é€²åº¦ç‹€æ…‹å®šç¾© =====
# =====================================

class DBStatus(Enum):
    """DB è™•ç†ç‹€æ…‹"""
    PENDING = "ç­‰å¾…ä¸­"
    DOWNLOADING_MANIFEST = "ä¸‹è¼‰ manifest"
    CHECKING_REPO = "æª¢æŸ¥ repo ç‹€æ…‹"
    REPO_INIT = "åŸ·è¡Œ repo init"
    REPO_SYNC = "åŸ·è¡Œ repo sync"
    EXPORTING = "å°å‡ºç‰ˆæœ¬"
    SUCCESS = "âœ… å®Œæˆ"
    FAILED = "âŒ å¤±æ•—"
    SKIPPED = "â­ï¸ è·³é"
    
# =====================================
# ===== è³‡æ–™çµæ§‹å®šç¾© =====
# =====================================

@dataclass
class DBInfo:
    """DB è³‡è¨Šè³‡æ–™çµæ§‹ï¼ˆå¢å¼·ç‰ˆï¼‰"""
    sn: int
    module: str
    db_type: str
    db_info: str
    db_folder: str
    sftp_path: str
    version: Optional[str] = None
    jira_link: Optional[str] = None
    source_command: Optional[str] = None
    manifest_file: Optional[str] = None
    manifest_full_path: Optional[str] = None
    local_path: Optional[str] = None
    has_existing_repo: bool = False
    status: DBStatus = DBStatus.PENDING
    error_message: Optional[str] = None
    start_time: Optional[datetime] = None
    end_time: Optional[datetime] = None
    sync_process: Optional[subprocess.Popen] = None
    # æ–°å¢ï¼šè¨˜éŒ„å¯¦éš›ä½¿ç”¨çš„ source command
    actual_source_cmd: Optional[str] = None
    # æ–°å¢ï¼šè¨˜éŒ„ sync æ—¥èªŒè·¯å¾‘
    sync_log_path: Optional[str] = None

    def to_dict(self) -> dict:
        """è½‰æ›ç‚ºå­—å…¸æ ¼å¼ï¼ˆå®Œæ•´ç‰ˆï¼‰"""
        result = asdict(self)
        
        # è™•ç† Enum å’Œ datetime
        if isinstance(result['status'], DBStatus):
            result['status'] = result['status'].value
        if result['start_time']:
            result['start_time'] = result['start_time'].strftime('%Y-%m-%d %H:%M:%S')
        if result['end_time']:
            result['end_time'] = result['end_time'].strftime('%Y-%m-%d %H:%M:%S')
        
        # æ–°å¢ï¼šç¢ºä¿åŒ…å«æ‰€æœ‰é‡è¦æ¬„ä½
        result['source_command_used'] = self.actual_source_cmd or 'æœªè¨˜éŒ„'
        result['manifest_version'] = self.version or 'æœ€æ–°'
        result['manifest_filename'] = self.manifest_file or 'æœªä¸‹è¼‰'
        
        # ç§»é™¤ Popen ç‰©ä»¶ï¼ˆç„¡æ³•åºåˆ—åŒ–ï¼‰
        result.pop('sync_process', None)
        
        return result

@dataclass
class PinningReport:
    """å®šç‰ˆå ±å‘Šè³‡æ–™çµæ§‹"""
    total_dbs: int = 0
    successful_dbs: int = 0
    failed_dbs: int = 0
    skipped_dbs: int = 0
    db_details: List[DBInfo] = field(default_factory=list)
    start_time: datetime = field(default_factory=datetime.now)
    end_time: Optional[datetime] = None
    
    def add_db(self, db_info: DBInfo):
        self.db_details.append(db_info)
        if db_info.status == DBStatus.SUCCESS:
            self.successful_dbs += 1
        elif db_info.status == DBStatus.FAILED:
            self.failed_dbs += 1
        elif db_info.status == DBStatus.SKIPPED:
            self.skipped_dbs += 1
    
    def finalize(self):
        """å®Œæˆå ±å‘Š"""
        self.end_time = datetime.now()
        self.total_dbs = len(self.db_details)

# =====================================
# ===== è³‡æºç®¡ç†å™¨ï¼ˆæ”¹å–„è³‡æºæ´©æ¼å•é¡Œï¼‰ =====
# =====================================

class ResourceManager:
    """çµ±ä¸€ç®¡ç†æ‰€æœ‰ç³»çµ±è³‡æºï¼Œç¢ºä¿æ­£ç¢ºæ¸…ç†"""
    
    def __init__(self):
        self.active_processes = {}
        self.sftp_connections = []
        self.lock = threading.Lock()
        self.logger = setup_logger(self.__class__.__name__)
        
        # è¨»å†Šæ¸…ç†å‡½å¼
        atexit.register(self.cleanup_all)
        signal.signal(signal.SIGINT, self._signal_handler)
        signal.signal(signal.SIGTERM, self._signal_handler)
    
    def _signal_handler(self, signum, frame):
        """è™•ç†ä¸­æ–·ä¿¡è™Ÿ"""
        self.logger.warning(f"æ”¶åˆ°ä¿¡è™Ÿ {signum}ï¼Œé–‹å§‹æ¸…ç†è³‡æº...")
        self.cleanup_all()
        sys.exit(1)
    
    def register_process(self, name: str, process: subprocess.Popen):
        """è¨»å†Šæ–°çš„å­é€²ç¨‹"""
        with self.lock:
            self.active_processes[name] = process
            self.logger.debug(f"è¨»å†Šé€²ç¨‹ {name} (PID: {process.pid})")
    
    def unregister_process(self, name: str):
        """å–æ¶ˆè¨»å†Šå­é€²ç¨‹"""
        with self.lock:
            if name in self.active_processes:
                del self.active_processes[name]
                self.logger.debug(f"å–æ¶ˆè¨»å†Šé€²ç¨‹ {name}")
    
    def register_sftp(self, connection):
        """è¨»å†Š SFTP é€£ç·š"""
        with self.lock:
            self.sftp_connections.append(connection)
    
    def cleanup_all(self):
        """æ¸…ç†æ‰€æœ‰è³‡æº"""
        with self.lock:
            # çµ‚æ­¢æ‰€æœ‰å­é€²ç¨‹
            for name, process in self.active_processes.items():
                try:
                    if process.poll() is None:
                        self.logger.info(f"çµ‚æ­¢é€²ç¨‹ {name} (PID: {process.pid})")
                        process.terminate()
                        process.wait(timeout=5)
                except Exception as e:
                    self.logger.error(f"çµ‚æ­¢é€²ç¨‹ {name} å¤±æ•—: {e}")
                    try:
                        process.kill()
                    except:
                        pass
            
            # é—œé–‰æ‰€æœ‰ SFTP é€£ç·š
            for conn in self.sftp_connections:
                try:
                    # æ‡‰è©²æª¢æŸ¥æ˜¯å¦æœ‰ disconnect æ–¹æ³•
                    if hasattr(conn, 'disconnect'):
                        conn.disconnect()
                    elif hasattr(conn, 'close'):
                        conn.close()
                except:
                    pass
            
            self.active_processes.clear()
            self.sftp_connections.clear()

# å…¨åŸŸè³‡æºç®¡ç†å™¨
resource_manager = ResourceManager()

# =====================================
# ===== é€²åº¦ç®¡ç†å™¨ =====
# =====================================

class ProgressManager:
    """ç®¡ç†æ‰€æœ‰ DB çš„è™•ç†é€²åº¦ï¼ˆå®Œæ•´ç‰ˆï¼‰"""
    
    def __init__(self):
        self.db_status = {}  # {db_name: (status, message)}
        self.db_sync_progress = {}  # {db_name: sync_progress_info}
        self.db_info_cache = {}  # {db_name: DBInfo} - ç·©å­˜ DB ä¿¡æ¯
        self.lock = threading.Lock()
        self.start_time = datetime.now()
        self.completed_count = 0
        self.total_count = 0
        self.sync_progress_parser = RepoSyncProgress()
        self.logger = setup_logger(self.__class__.__name__)
        
    def init_db(self, db_name: str, db_info: DBInfo = None):
        """åˆå§‹åŒ– DB ç‹€æ…‹"""
        with self.lock:
            self.db_status[db_name] = (DBStatus.PENDING, "")
            self.db_sync_progress[db_name] = None
            if db_info:
                self.db_info_cache[db_name] = db_info
            self.total_count += 1
    
    def update_status(self, db_name: str, status: DBStatus, message: str = ""):
        """æ›´æ–° DB ç‹€æ…‹"""
        with self.lock:
            self.db_status[db_name] = (status, message)
            if status in [DBStatus.SUCCESS, DBStatus.FAILED, DBStatus.SKIPPED]:
                self.completed_count += 1
    
    def update_sync_progress(self, db_name: str, log_file: str):
        """æ›´æ–° repo sync é€²åº¦"""
        try:
            progress_info = self.sync_progress_parser.parse_sync_log(log_file)
            
            with self.lock:
                self.db_sync_progress[db_name] = progress_info
                db_info = self.db_info_cache.get(db_name)
                
                # æ ¹æ“š sync ç‹€æ…‹æ›´æ–°æ•´é«”ç‹€æ…‹
                if progress_info['status'] == 'completed':
                    self.db_status[db_name] = (DBStatus.REPO_SYNC, "âœ… åŒæ­¥å®Œæˆï¼Œæº–å‚™å°å‡º")
                elif progress_info['status'] == 'failed':
                    error_msg = progress_info['errors'][0] if progress_info['errors'] else "åŒæ­¥å¤±æ•—"
                    self.db_status[db_name] = (DBStatus.FAILED, f"âŒ {error_msg}")
                else:
                    # æ§‹å»ºé€²åº¦æ¶ˆæ¯
                    progress_msg = self._build_sync_progress_message(progress_info, db_info)
                    self.db_status[db_name] = (DBStatus.REPO_SYNC, progress_msg)
                    
        except Exception as e:
            self.logger.error(f"æ›´æ–° {db_name} sync é€²åº¦å¤±æ•—: {e}")
    
    def _build_sync_progress_message(self, progress_info: Dict, db_info: DBInfo = None) -> str:
        """æ§‹å»º sync é€²åº¦æ¶ˆæ¯ï¼ˆå¢å¼·ç‰ˆï¼‰"""
        parts = []
        
        # ç‰ˆæœ¬ä¿¡æ¯
        if db_info and db_info.version:
            parts.append(f"ğŸ“‹ v{db_info.version}")
        
        # æ•´é«”é€²åº¦
        if progress_info['overall_progress'] != '0%':
            parts.append(f"ğŸ”„ {progress_info['overall_progress']}")
            
            # é …ç›®è¨ˆæ•¸
            if progress_info['total_projects'] > 0:
                parts.append(f"({progress_info['current_projects']}/{progress_info['total_projects']})")
        else:
            parts.append("ğŸ”„ åŒæ­¥ä¸­...")
        
        # ç•¶å‰ repository
        if progress_info['current_repo']:
            repo_short = progress_info['current_repo'].split('/')[-1] if '/' in progress_info['current_repo'] else progress_info['current_repo']
            if len(repo_short) > 15:
                repo_short = repo_short[:12] + "..."
            parts.append(f"ğŸ“¦ {repo_short}")
        
        # ä¸‹è¼‰é€Ÿåº¦
        if progress_info['speed']:
            parts.append(f"âš¡ {progress_info['speed']}")
        
        return " ".join(parts)
    
    def get_progress_display(self) -> str:
        """å–å¾—é€²åº¦é¡¯ç¤ºå­—ä¸²ï¼ˆå®Œæ•´ç‰ˆ - åŒ…å«è©³ç´°ä¿¡æ¯ï¼‰"""
        with self.lock:
            lines = []
            lines.append("\n" + "="*100)
            lines.append(f"ğŸ“Š Manifest å®šç‰ˆé€²åº¦ - {datetime.now().strftime('%H:%M:%S')}")
            lines.append(f"   å®Œæˆ: {self.completed_count}/{self.total_count}")
            
            elapsed = datetime.now() - self.start_time
            lines.append(f"   è€—æ™‚: {str(elapsed).split('.')[0]}")
            
            # è¨ˆç®—é ä¼°å‰©é¤˜æ™‚é–“
            if self.completed_count > 0:
                avg_time = elapsed.total_seconds() / self.completed_count
                remaining = (self.total_count - self.completed_count) * avg_time
                lines.append(f"   é ä¼°å‰©é¤˜: {str(timedelta(seconds=int(remaining)))}")
            
            lines.append("="*100)
            
            # åˆ†çµ„é¡¯ç¤ºä¸åŒç‹€æ…‹çš„ DB - å¢å¼·ç‰ˆ
            for status in DBStatus:
                dbs_in_status = [(name, msg) for name, (s, msg) in self.db_status.items() if s == status]
                if dbs_in_status:
                    lines.append(f"\n{status.value}:")
                    for name, msg in dbs_in_status:
                        db_info = self.db_info_cache.get(name)
                        
                        # æ§‹å»ºå®Œæ•´çš„é¡¯ç¤ºä¿¡æ¯
                        display_parts = [f"  â€¢ {name}:"]
                        
                        # æ·»åŠ ç‰ˆæœ¬ä¿¡æ¯
                        if db_info and db_info.version:
                            display_parts.append(f"[v{db_info.version}]")
                        
                        # æ·»åŠ ç‹€æ…‹æ¶ˆæ¯
                        if msg:
                            display_parts.append(msg)
                        
                        # å¦‚æœæ˜¯ sync ç‹€æ…‹ï¼Œæ·»åŠ  source command ä¿¡æ¯
                        if status == DBStatus.REPO_SYNC and db_info and db_info.actual_source_cmd:
                            # ç°¡åŒ– source command é¡¯ç¤º
                            cmd_short = self._simplify_source_command(db_info.actual_source_cmd)
                            display_parts.append(f"ğŸ“ {cmd_short}")
                        
                        lines.append(" ".join(display_parts))
            
            lines.append("="*100)
            return "\n".join(lines)
    
    def _simplify_source_command(self, source_cmd: str) -> str:
        """ç°¡åŒ– source command é¡¯ç¤º"""
        if not source_cmd:
            return ""
        
        # æå–é—œéµä¿¡æ¯ï¼šä¸»æ©Ÿå’Œåˆ†æ”¯
        try:
            # æå– -u å¾Œçš„ä¸»æ©Ÿä¿¡æ¯
            u_match = re.search(r'-u\s+(\S+)', source_cmd)
            host_info = ""
            if u_match:
                url = u_match.group(1)
                if "mm2sd" in url:
                    host_info = "mm2sd"
                elif "ssh://" in url:
                    host_info = url.split("://")[1].split("/")[0].split(".")[0]
                else:
                    host_info = "repo"
            
            # æå– -b å¾Œçš„åˆ†æ”¯ä¿¡æ¯
            b_match = re.search(r'-b\s+(\S+)', source_cmd)
            branch_info = ""
            if b_match:
                branch = b_match.group(1)
                if "android-14" in branch:
                    branch_info = "android-14"
                elif "android" in branch:
                    branch_info = branch.split("/")[-1] if "/" in branch else branch
                else:
                    branch_info = branch.split("/")[-1] if "/" in branch else branch
            
            # æå– -m å¾Œçš„ manifest ä¿¡æ¯
            m_match = re.search(r'-m\s+(\S+)', source_cmd)
            manifest_info = ""
            if m_match:
                manifest = m_match.group(1)
                manifest_info = manifest.replace('.xml', '').replace('atv-', '').replace('google-', '')
            
            # çµ„åˆç°¡åŒ–ä¿¡æ¯
            parts = []
            if host_info:
                parts.append(host_info)
            if branch_info:
                parts.append(branch_info)
            if manifest_info:
                parts.append(manifest_info)
            
            return "/".join(parts) if parts else "repo"
            
        except Exception:
            # å¦‚æœè§£æå¤±æ•—ï¼Œè¿”å›å‰ 30 å€‹å­—ç¬¦
            return source_cmd[:30] + "..." if len(source_cmd) > 30 else source_cmd

    def display_progress(self, clear_screen: bool = True):
        """é¡¯ç¤ºé€²åº¦ï¼ˆå¯é¸æ¸…å±ï¼‰"""
        try:
            if clear_screen:
                os.system('cls' if os.name == 'nt' else 'clear')
            print(self.get_progress_display())
        except Exception as e:
            self.logger.error(f"é¡¯ç¤ºé€²åº¦å¤±æ•—: {e}")
            print(f"é€²åº¦æ›´æ–°éŒ¯èª¤: {e}")

# =====================================
# ===== Source Command ç®¡ç†å™¨ï¼ˆè§£æ±ºå›ºå®šå‘½ä»¤å•é¡Œï¼‰ =====
# =====================================

# =====================================
# ===== Source Command ç®¡ç†å™¨ï¼ˆä½¿ç”¨ JIRA APIï¼‰ =====
# =====================================

class SourceCommandManager:
    """ç®¡ç†ä¸åŒ DB çš„ source command - å¾ JIRA å³æ™‚ç²å–"""
    
    def __init__(self):
        self.logger = setup_logger(self.__class__.__name__)
        self.jira_client = JiraAPIClient()
        self.cache = {}  # å¿«å–æŸ¥è©¢çµæœï¼Œé¿å…é‡è¤‡æŸ¥è©¢
        
    def get_source_command(self, db_info: DBInfo, mapping_df: pd.DataFrame = None) -> Optional[str]:
        """
        æ ¹æ“š DB è³‡è¨Šç²å–å°æ‡‰çš„ source command
        å„ªå…ˆç´šï¼š
        1. å¿«å–çµæœ
        2. å¾ mapping table ä¸­çš„ JIRA ticket ç²å–
        3. å¾ JIRA æœå°‹ DB ç›¸é—œ ticket
        4. æœ€çµ‚å‚™ç”¨å‘½ä»¤
        """
        db_name = db_info.db_info
        
        # 1. æª¢æŸ¥å¿«å–
        if db_name in self.cache:
            self.logger.info(f"ä½¿ç”¨å¿«å–çš„ source command for {db_name}")
            return self.cache[db_name]
        
        # 2. å˜—è©¦å¾ mapping table ç²å–
        if mapping_df is not None:
            cmd = self._get_from_jira_or_mapping(db_info, mapping_df)
            if cmd:
                self.cache[db_name] = cmd
                return cmd
        
        # 3. ç›´æ¥å¾ JIRA æœå°‹
        self.logger.info(f"å¾ JIRA æœå°‹ {db_name} ç›¸é—œ ticket...")
        ticket_key = self.jira_client.search_db_ticket(db_name, db_info.module)
        if ticket_key:
            cmd = self.jira_client.get_source_command_from_ticket(ticket_key)
            if cmd:
                self.cache[db_name] = cmd
                return cmd
        
        # 4. æœ€çµ‚å‚™ç”¨
        self.logger.warning(f"ç„¡æ³•å¾ JIRA ç²å– {db_name} çš„ source commandï¼Œä½¿ç”¨å‚™ç”¨å‘½ä»¤")
        self.logger.warning("å»ºè­°ï¼šè«‹åœ¨ JIRA ä¸­å»ºç«‹ç›¸é—œ ticket ä¸¦è¨˜éŒ„ source command")
        return None
    
    def _get_from_jira_or_mapping(self, db_info: DBInfo, mapping_df: pd.DataFrame) -> Optional[str]:
        """
        å¾ JIRA æˆ– mapping table ç²å– source command
        å®Œæ•´å¯¦ä½œç‰ˆæœ¬
        """
        try:
            db_name = db_info.db_info
            
            # æ ¹æ“š DB é¡å‹æŸ¥æ‰¾å°æ‡‰çš„æ¬„ä½
            type_column_map = {
                'master': 'DB_Info',
                'premp': 'premp_DB_Info',
                'mp': 'mp_DB_Info',
                'mpbackup': 'mpbackup_DB_Info'
            }
            
            col = type_column_map.get(db_info.db_type)
            if not col or col not in mapping_df.columns:
                return None
            
            # æ‰¾åˆ°å°æ‡‰çš„è¡Œ
            mask = mapping_df[col] == db_name
            if not mask.any():
                return None
            
            row = mapping_df[mask].iloc[0]
            
            # 1. é¦–å…ˆæª¢æŸ¥æ˜¯å¦æœ‰ source_command æ¬„ä½ç›´æ¥è¨˜éŒ„
            source_cmd_columns = ['source_command', 'Source_Command', 'SOURCE_COMMAND', 'SourceCmd']
            for cmd_col in source_cmd_columns:
                if cmd_col in row and pd.notna(row[cmd_col]):
                    cmd = str(row[cmd_col]).strip()
                    if cmd and 'repo init' in cmd:
                        self.logger.info(f"å¾ mapping table çš„ {cmd_col} æ¬„ä½ç²å– source command")
                        return cmd
            
            # 2. æª¢æŸ¥æ˜¯å¦æœ‰ JIRA ticket æ¬„ä½
            jira_columns = ['jira_ticket', 'JIRA_Ticket', 'JiraTicket', 'Jira', 'JIRA', 'ticket', 'Ticket']
            jira_ticket = None
            
            for jira_col in jira_columns:
                if jira_col in row and pd.notna(row[jira_col]):
                    jira_ticket = str(row[jira_col]).strip()
                    if jira_ticket:
                        self.logger.info(f"å¾ mapping table æ‰¾åˆ° JIRA ticket: {jira_ticket}")
                        break
            
            # 3. å¦‚æœæœ‰ JIRA ticketï¼Œå¾ JIRA ç²å–
            if jira_ticket:
                # ç¢ºä¿ JIRA å®¢æˆ¶ç«¯å·²é€£æ¥
                if not self.jira_client._connected:
                    if not self.jira_client.connect():
                        self.logger.error("ç„¡æ³•é€£æ¥åˆ° JIRA")
                        return None
                
                # å¾ JIRA ticket ç²å– source command
                cmd = self.jira_client.get_source_command_from_ticket(jira_ticket)
                if cmd:
                    self.logger.info(f"æˆåŠŸå¾ JIRA ticket {jira_ticket} ç²å– source command")
                    return cmd
                else:
                    self.logger.warning(f"JIRA ticket {jira_ticket} ä¸­æœªæ‰¾åˆ° source command")
            
            # 4. å¦‚æœæ²’æœ‰ JIRA ticketï¼Œå˜—è©¦ç”¨ DB åç¨±æœå°‹ JIRA
            if not jira_ticket:
                self.logger.info(f"mapping table ä¸­æ²’æœ‰ JIRA ticketï¼Œå˜—è©¦æœå°‹ {db_name}")
                
                # ç¢ºä¿ JIRA å®¢æˆ¶ç«¯å·²é€£æ¥
                if not self.jira_client._connected:
                    if not self.jira_client.connect():
                        return None
                
                # æœå°‹ç›¸é—œ ticket
                found_ticket = self.jira_client.search_db_ticket(db_name, db_info.module)
                if found_ticket:
                    cmd = self.jira_client.get_source_command_from_ticket(found_ticket)
                    if cmd:
                        self.logger.info(f"å¾æœå°‹åˆ°çš„ ticket {found_ticket} ç²å– source command")
                        # å¯ä»¥è€ƒæ…®å°‡æ‰¾åˆ°çš„ ticket æ›´æ–°å› mapping table
                        return cmd
            
            return None
            
        except Exception as e:
            self.logger.error(f"_get_from_jira_or_mapping å¤±æ•—: {e}")
            return None
    
    def update_source_command(self, db_name: str, command: str):
        """æ›´æ–°ç‰¹å®š DB çš„ source command å¿«å–"""
        self.cache[db_name] = command
        self.logger.info(f"æ›´æ–° {db_name} çš„ source command å¿«å–")
    
    def clear_cache(self):
        """æ¸…é™¤æ‰€æœ‰å¿«å–"""
        self.cache.clear()
        self.logger.info("å·²æ¸…é™¤æ‰€æœ‰ source command å¿«å–")
    
    def test_jira_connection(self) -> bool:
        """æ¸¬è©¦ JIRA é€£æ¥"""
        try:
            if self.jira_client.connect():
                self.logger.info("JIRA é€£æ¥æ¸¬è©¦æˆåŠŸ")
                return True
            else:
                self.logger.error("JIRA é€£æ¥æ¸¬è©¦å¤±æ•—")
                return False
        except Exception as e:
            self.logger.error(f"JIRA é€£æ¥æ¸¬è©¦ç•°å¸¸: {e}")
            return False
        
# =====================================
# ===== Mapping Table è®€å–å™¨ =====
# =====================================

class MappingTableReader:
    """è®€å–å’Œè§£æ mapping table çš„é¡åˆ¥"""
    
    def __init__(self):
        self.logger = setup_logger(self.__class__.__name__)
        self.df = None
        
    def load_excel(self, file_path: str) -> bool:
        """è¼‰å…¥ Excel æª”æ¡ˆ"""
        try:
            self.df = pd.read_excel(file_path)
            self.logger.info(f"æˆåŠŸè¼‰å…¥ {len(self.df)} ç­†è³‡æ–™")
            
            # æª¢æŸ¥å¿…è¦æ¬„ä½
            required_columns = ['SN', 'Module', 'DB_Type', 'DB_Info']
            missing_columns = [col for col in required_columns if col not in self.df.columns]
            
            if missing_columns:
                self.logger.warning(f"ç¼ºå°‘æ¬„ä½: {missing_columns}")
                
            return True
            
        except Exception as e:
            self.logger.error(f"è¼‰å…¥ Excel å¤±æ•—: {str(e)}")
            return False
    
    def get_db_info_list(self, db_type: str = 'all') -> List[DBInfo]:
        """
        å–å¾— DB è³‡è¨Šåˆ—è¡¨
        
        Args:
            db_type: 'all', 'master', 'premp', 'mp', 'mpbackup'
        """
        db_list = []
        
        if self.df is None:
            return db_list
        
        # è™•ç†ä¸åŒçš„ DB é¡å‹
        type_columns = {
            'master': ('DB_Type', 'DB_Info', 'DB_Folder', 'SftpPath'),
            'premp': ('premp_DB_Type', 'premp_DB_Info', 'premp_DB_Folder', 'premp_SftpPath'),
            'mp': ('mp_DB_Type', 'mp_DB_Info', 'mp_DB_Folder', 'mp_SftpPath'),
            'mpbackup': ('mpbackup_DB_Type', 'mpbackup_DB_Info', 'mpbackup_DB_Folder', 'mpbackup_SftpPath')
        }
        
        # é¸æ“‡è¦è™•ç†çš„é¡å‹
        if db_type == 'all':
            types_to_process = type_columns.keys()
        else:
            types_to_process = [db_type] if db_type in type_columns else []
        
        for idx, row in self.df.iterrows():
            for dtype in types_to_process:
                cols = type_columns[dtype]
                
                # æª¢æŸ¥è©²é¡å‹çš„æ¬„ä½æ˜¯å¦å­˜åœ¨ä¸”æœ‰å€¼
                db_info_col = cols[1]  # DB_Info æ¬„ä½
                if db_info_col in row and pd.notna(row[db_info_col]):
                    db_info = DBInfo(
                        sn=row['SN'] if 'SN' in row else idx + 1,
                        module=row['Module'] if 'Module' in row else '',
                        db_type=dtype,
                        db_info=str(row[db_info_col]),
                        db_folder=str(row[cols[2]]) if cols[2] in row and pd.notna(row[cols[2]]) else '',
                        sftp_path=str(row[cols[3]]) if cols[3] in row and pd.notna(row[cols[3]]) else ''
                    )
                    db_list.append(db_info)
        
        return db_list
    
    def get_db_by_name(self, db_name: str) -> Optional[DBInfo]:
        """æ ¹æ“š DB åç¨±å–å¾—è³‡è¨Š"""
        all_dbs = self.get_db_info_list('all')
        
        for db in all_dbs:
            if db.db_info == db_name:
                return db
        
        return None

# =====================================
# ===== SFTP ç®¡ç†å™¨ï¼ˆæ”¹å–„è·¯å¾‘è™•ç†ï¼‰ =====
# =====================================

class ThreadSafeSFTPManager:
    """åŸ·è¡Œç·’å®‰å…¨çš„ SFTP ç®¡ç†å™¨ï¼ˆå®Œæ•´å¢å¼·ç‰ˆ - è§£æ±ºé€£ç·šå•é¡Œï¼‰"""
    
    def __init__(self, config: Dict = None):
        self.config = config or config_manager.sftp_config
        self.logger = setup_logger(self.__class__.__name__)
        self._local = threading.local()
        self._main_connected = False
        self.progress_callback = None
        
        # é€£ç·šæ± ç®¡ç† - è§£æ±ºä½µç™¼é€£ç·šå•é¡Œ
        self._connection_semaphore = Semaphore(2)  # é™åˆ¶æœ€å¤§ä½µç™¼é€£ç·šæ•¸ç‚º 2
        self._connection_lock = Lock()
        self._failed_connections = 0
        self._last_failure_time = 0
        self._backoff_time = 0
        
        # é€£ç·šé‡è©¦é…ç½®
        self.retry_config = {
            'max_retries': 5,
            'base_delay': 2.0,
            'max_delay': 60.0,
            'exponential_base': 2.0,
            'jitter_range': 0.5
        }
    
    def set_progress_callback(self, callback):
        """è¨­ç½®é€²åº¦å›èª¿å‡½æ•¸"""
        self.progress_callback = callback
    
    def _update_progress(self, db_name: str, status: str, message: str):
        """æ›´æ–°é€²åº¦ï¼ˆå¦‚æœæœ‰å›èª¿å‡½æ•¸ï¼‰"""
        if self.progress_callback:
            self.progress_callback(db_name, status, message)
    
    def _calculate_backoff_delay(self, attempt: int) -> float:
        """è¨ˆç®—é€€é¿å»¶é²æ™‚é–“"""
        base_delay = self.retry_config['base_delay']
        max_delay = self.retry_config['max_delay']
        exponential_base = self.retry_config['exponential_base']
        jitter_range = self.retry_config['jitter_range']
        
        # æŒ‡æ•¸é€€é¿
        delay = base_delay * (exponential_base ** attempt)
        delay = min(delay, max_delay)
        
        # æ·»åŠ éš¨æ©ŸæŠ–å‹•é¿å…é›·ç¾¤æ•ˆæ‡‰
        jitter = random.uniform(-jitter_range, jitter_range) * delay
        delay = max(0.1, delay + jitter)
        
        return delay
    
    def _should_apply_global_backoff(self) -> bool:
        """æª¢æŸ¥æ˜¯å¦éœ€è¦å…¨åŸŸé€€é¿"""
        current_time = time.time()
        
        with self._connection_lock:
            # å¦‚æœæœ€è¿‘å¤±æ•—å¤ªå¤šï¼Œå¯¦æ–½å…¨åŸŸé€€é¿
            if self._failed_connections >= 3:
                time_since_failure = current_time - self._last_failure_time
                if time_since_failure < self._backoff_time:
                    return True
                else:
                    # é‡ç½®å¤±æ•—è¨ˆæ•¸
                    self._failed_connections = 0
                    self._backoff_time = 0
        
        return False
    
    def _record_connection_failure(self):
        """è¨˜éŒ„é€£ç·šå¤±æ•—"""
        current_time = time.time()
        
        with self._connection_lock:
            self._failed_connections += 1
            self._last_failure_time = current_time
            # æ ¹æ“šå¤±æ•—æ¬¡æ•¸å¢åŠ é€€é¿æ™‚é–“
            self._backoff_time = min(30.0, self._failed_connections * 5.0)
            
            self.logger.warning(f"è¨˜éŒ„é€£ç·šå¤±æ•—ï¼Œç¸½å¤±æ•—æ¬¡æ•¸: {self._failed_connections}, é€€é¿æ™‚é–“: {self._backoff_time}s")
    
    def _record_connection_success(self):
        """è¨˜éŒ„é€£ç·šæˆåŠŸ"""
        with self._connection_lock:
            # æˆåŠŸé€£ç·šå¾Œï¼Œé‡ç½®éƒ¨åˆ†å¤±æ•—è¨ˆæ•¸
            if self._failed_connections > 0:
                self._failed_connections = max(0, self._failed_connections - 1)
                self.logger.info(f"é€£ç·šæˆåŠŸï¼Œèª¿æ•´å¤±æ•—è¨ˆæ•¸: {self._failed_connections}")
    
    def connect(self) -> bool:
        """å»ºç«‹ä¸»é€£ç·šï¼ˆç”¨æ–¼æ¸¬è©¦å’Œé©—è­‰ï¼‰- å¢å¼·ç‰ˆ"""
        thread_name = threading.current_thread().name
        
        # æª¢æŸ¥å…¨åŸŸé€€é¿
        if self._should_apply_global_backoff():
            backoff_remaining = self._backoff_time - (time.time() - self._last_failure_time)
            self.logger.warning(f"[{thread_name}] å› å…¨åŸŸé€€é¿è€Œè·³éé€£ç·šæ¸¬è©¦ï¼Œå‰©é¤˜ {backoff_remaining:.1f}s")
            return False
        
        # ç²å–é€£ç·šä¿¡è™Ÿé‡
        if not self._connection_semaphore.acquire(blocking=False):
            self.logger.warning(f"[{thread_name}] é”åˆ°æœ€å¤§ä½µç™¼é€£ç·šæ•¸ï¼Œç­‰å¾…...")
            if not self._connection_semaphore.acquire(timeout=30):
                self.logger.error(f"[{thread_name}] ç²å–é€£ç·šä¿¡è™Ÿé‡è¶…æ™‚")
                return False
        
        try:
            for attempt in range(self.retry_config['max_retries']):
                try:
                    self.logger.info(f"[{thread_name}] å˜—è©¦é€£æ¥åˆ° SFTP: {self.config['host']}:{self.config['port']} (å˜—è©¦ {attempt + 1})")
                    
                    # å»ºç«‹ transport é€£ç·šï¼Œå¢åŠ æ›´è©³ç´°çš„é…ç½®
                    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
                    sock.settimeout(self.config.get('timeout', 30))
                    sock.setsockopt(socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1)
                    
                    try:
                        sock.connect((self.config['host'], self.config['port']))
                        self.logger.debug(f"[{thread_name}] Socket é€£ç·šæˆåŠŸ")
                    except socket.timeout:
                        sock.close()
                        raise Exception("Socket é€£ç·šè¶…æ™‚")
                    except socket.error as e:
                        sock.close()
                        raise Exception(f"Socket é€£ç·šå¤±æ•—: {e}")
                    
                    transport = paramiko.Transport(sock)
                    transport.set_keepalive(30)
                    
                    # è¨­ç½®æ›´å¯¬é¬†çš„é€£ç·šåƒæ•¸
                    transport.banner_timeout = 45
                    transport.handshake_timeout = 45
                    transport.auth_timeout = 30
                    
                    # ä¿®å¾©ï¼šç§»é™¤ timeout åƒæ•¸
                    transport.connect(
                        username=self.config['username'],
                        password=self.config['password']
                    )
                    
                    sftp = paramiko.SFTPClient.from_transport(transport)
                    
                    # æ¸¬è©¦é€£ç·š
                    sftp.listdir('.')
                    
                    # æ¸…ç†æ¸¬è©¦é€£ç·š
                    sftp.close()
                    transport.close()
                    
                    self._main_connected = True
                    self._record_connection_success()
                    self.logger.info(f"[{thread_name}] SFTP é€£ç·šæ¸¬è©¦æˆåŠŸ")
                    return True
                    
                except Exception as e:
                    self.logger.warning(f"[{thread_name}] SFTP é€£ç·šå˜—è©¦ {attempt + 1} å¤±æ•—: {e}")
                    
                    if attempt < self.retry_config['max_retries'] - 1:
                        delay = self._calculate_backoff_delay(attempt)
                        self.logger.info(f"[{thread_name}] ç­‰å¾… {delay:.1f} ç§’å¾Œé‡è©¦...")
                        time.sleep(delay)
                    else:
                        self._record_connection_failure()
                        self.logger.error(f"[{thread_name}] SFTP é€£ç·šå¤±æ•—ï¼Œå·²é”æœ€å¤§é‡è©¦æ¬¡æ•¸")
            
            self._main_connected = False
            return False
            
        finally:
            self._connection_semaphore.release()
    
    def disconnect(self):
        """æ–·é–‹é€£ç·š - å¢å¼·ç‰ˆ"""
        try:
            # æ¸…ç†æœ¬åœ°é€£ç·š
            if hasattr(self._local, 'sftp') and self._local.sftp:
                try:
                    self._local.sftp.close()
                except:
                    pass
            if hasattr(self._local, 'transport') and self._local.transport:
                try:
                    self._local.transport.close()
                except:
                    pass
            if hasattr(self._local, 'connected'):
                self._local.connected = False
                
            self._main_connected = False
            self.logger.info("SFTP é€£ç·šå·²é—œé–‰")
            
        except Exception as e:
            self.logger.warning(f"é—œé–‰ SFTP é€£ç·šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    def _get_connection(self) -> Tuple[Optional[paramiko.SFTPClient], Optional[paramiko.Transport]]:
        """ç‚ºç•¶å‰ç·šç¨‹ç²å–æˆ–å»ºç«‹ SFTP é€£ç·š - å¢å¼·ç‰ˆ"""
        thread_name = threading.current_thread().name
        
        if not hasattr(self._local, 'connected') or not self._local.connected:
            # æª¢æŸ¥å…¨åŸŸé€€é¿
            if self._should_apply_global_backoff():
                backoff_remaining = self._backoff_time - (time.time() - self._last_failure_time)
                self.logger.warning(f"[{thread_name}] å…¨åŸŸé€€é¿ä¸­ï¼Œå‰©é¤˜ {backoff_remaining:.1f} ç§’")
                return None, None
            
            # ç²å–é€£ç·šä¿¡è™Ÿé‡
            if not self._connection_semaphore.acquire(blocking=False):
                self.logger.warning(f"[{thread_name}] ç­‰å¾…é€£ç·šä¿¡è™Ÿé‡...")
                if not self._connection_semaphore.acquire(timeout=60):
                    self.logger.error(f"[{thread_name}] ç²å–é€£ç·šä¿¡è™Ÿé‡è¶…æ™‚")
                    return None, None
            
            try:
                for attempt in range(self.retry_config['max_retries']):
                    try:
                        self.logger.debug(f"[{thread_name}] å»ºç«‹æ–°çš„ SFTP é€£ç·š (å˜—è©¦ {attempt + 1})")
                        
                        # å»ºç«‹ socket é€£ç·š
                        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
                        sock.settimeout(self.config.get('timeout', 30))
                        sock.setsockopt(socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1)
                        sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
                        
                        try:
                            sock.connect((self.config['host'], self.config['port']))
                        except socket.timeout:
                            sock.close()
                            raise Exception("Socket é€£ç·šè¶…æ™‚")
                        except socket.error as e:
                            sock.close()
                            raise Exception(f"Socket é€£ç·šå¤±æ•—: {e}")
                        
                        transport = paramiko.Transport(sock)
                        transport.set_keepalive(30)
                        transport.banner_timeout = 45  # å¢åŠ  banner è¶…æ™‚æ™‚é–“
                        transport.handshake_timeout = 45  # å¢åŠ æ¡æ‰‹è¶…æ™‚æ™‚é–“
                        transport.auth_timeout = 30
                        
                        # ä¿®å¾©ï¼šç§»é™¤ timeout åƒæ•¸
                        transport.connect(
                            username=self.config['username'],
                            password=self.config['password']
                        )
                        
                        sftp = paramiko.SFTPClient.from_transport(transport)
                        
                        self._local.transport = transport
                        self._local.sftp = sftp
                        self._local.connected = True
                        
                        # è¨»å†Šåˆ°è³‡æºç®¡ç†å™¨
                        resource_manager.register_sftp(self)
                        
                        self._record_connection_success()
                        self.logger.debug(f"[{thread_name}] SFTP é€£ç·šå»ºç«‹æˆåŠŸ")
                        break
                        
                    except Exception as e:
                        self.logger.warning(f"[{thread_name}] SFTP é€£ç·šå˜—è©¦ {attempt + 1} å¤±æ•—: {e}")
                        
                        if attempt < self.retry_config['max_retries'] - 1:
                            delay = self._calculate_backoff_delay(attempt)
                            self.logger.info(f"[{thread_name}] ç­‰å¾… {delay:.1f} ç§’å¾Œé‡è©¦...")
                            time.sleep(delay)
                        else:
                            self._record_connection_failure()
                            self._local.connected = False
                            return None, None
                            
            finally:
                self._connection_semaphore.release()
        
        return getattr(self._local, 'sftp', None), getattr(self._local, 'transport', None)
    
    def _is_version_directory(self, dir_name: str) -> bool:
        """æª¢æŸ¥æ˜¯å¦ç‚ºç‰ˆæœ¬ç›®éŒ„ï¼ˆå°ˆé–€æ”¯æ´4ç¨®æ ¼å¼ï¼‰"""
        patterns = [
            # ä¸»è¦æ ¼å¼ï¼šæ•¸å­—_all_12ä½æ™‚é–“æˆ³
            r'^\d+_all_\d{12}$',          # 206_all_202507100000
            r'^\d+_all_\d{12}_.*$',       # 465_all_202502170030_NG_uboot_fail (å¸¶å¾Œç¶´)
            
            # æ¬¡è¦æ ¼å¼ï¼šæ•¸å­—_12ä½æ™‚é–“æˆ³
            r'^\d+_\d{12}$',              # 204_202507081101
            r'^\d+_\d{12}_.*$',           # 466_202502171018_NG_uboot_fail (å¸¶å¾Œç¶´)
            
            # ä¿ç•™ç°¡å–®æ ¼å¼ä»¥é˜²è¬ä¸€
            r'^\d+$',                     # ç´”æ•¸å­—ï¼š206, 204
            r'^v\d+$',                   # v + æ•¸å­—ï¼šv206
        ]
        
        for pattern in patterns:
            if re.match(pattern, dir_name, re.IGNORECASE):
                return True
        return False
    
    def _extract_version_number_flexible(self, dir_name: str) -> Optional[str]:
        """æå–ç‰ˆæœ¬è™Ÿï¼ˆé–‹é ­çš„æ•¸å­—ï¼‰"""
        patterns = [
            r'^(\d+)_all_\d{12}',         # 206_all_202507100000 -> 206
            r'^(\d+)_all_\d{12}_',        # 465_all_202502170030_NG_uboot_fail -> 465
            r'^(\d+)_\d{12}',             # 204_202507081101 -> 204  
            r'^(\d+)_\d{12}_',            # 466_202502171018_NG_uboot_fail -> 466
            r'^(\d+)$',                   # 206 -> 206
            r'^v(\d+)',                   # v206 -> 206
            r'^(\d+)',                    # ä»»ä½•é–‹é ­æ•¸å­—
        ]
        
        for pattern in patterns:
            match = re.search(pattern, dir_name, re.IGNORECASE)
            if match:
                return match.group(1)
        
        return None
    
    def _parse_version_directory(self, dir_name: str, mtime: float) -> Optional[Dict]:
        """è§£æç‰ˆæœ¬ç›®éŒ„çš„è©³ç´°ä¿¡æ¯"""
        try:
            version_info = {
                'dir_name': dir_name,
                'version': self._extract_version_number_flexible(dir_name),
                'version_number': None,
                'timestamp': None,
                'format_type': 'unknown',
                'mtime': mtime,
                'has_suffix': False,
                'suffix': ''
            }
            
            # è­˜åˆ¥å…·é«”æ ¼å¼
            if re.match(r'^\d+_all_\d{12}_.*$', dir_name):
                # æ ¼å¼ï¼š465_all_202502170030_NG_uboot_fail
                parts = dir_name.split('_', 3)  # åˆ†æˆ4éƒ¨åˆ†
                version_info.update({
                    'version_number': parts[0],
                    'timestamp': int(parts[2]) if parts[2].isdigit() else 0,
                    'format_type': 'version_all_timestamp_suffix',
                    'has_suffix': True,
                    'suffix': parts[3] if len(parts) > 3 else ''
                })
                
            elif re.match(r'^\d+_all_\d{12}$', dir_name):
                # æ ¼å¼ï¼š206_all_202507100000
                parts = dir_name.split('_')
                version_info.update({
                    'version_number': parts[0],
                    'timestamp': int(parts[2]) if parts[2].isdigit() else 0,
                    'format_type': 'version_all_timestamp'
                })
                
            elif re.match(r'^\d+_\d{12}_.*$', dir_name):
                # æ ¼å¼ï¼š466_202502171018_NG_uboot_fail
                parts = dir_name.split('_', 2)  # åˆ†æˆ3éƒ¨åˆ†
                version_info.update({
                    'version_number': parts[0],
                    'timestamp': int(parts[1]) if parts[1].isdigit() else 0,
                    'format_type': 'version_timestamp_suffix',
                    'has_suffix': True,
                    'suffix': parts[2] if len(parts) > 2 else ''
                })
                
            elif re.match(r'^\d+_\d{12}$', dir_name):
                # æ ¼å¼ï¼š204_202507081101
                parts = dir_name.split('_')
                version_info.update({
                    'version_number': parts[0],
                    'timestamp': int(parts[1]) if parts[1].isdigit() else 0,
                    'format_type': 'version_timestamp'
                })
                
            elif re.match(r'^\d+$', dir_name):
                # æ ¼å¼ï¼šç´”æ•¸å­—
                version_info.update({
                    'version_number': dir_name,
                    'timestamp': 0,
                    'format_type': 'simple_number'
                })
                
            elif re.match(r'^v\d+$', dir_name):
                # æ ¼å¼ï¼šv206
                version_info.update({
                    'version_number': dir_name[1:],
                    'timestamp': 0,
                    'format_type': 'v_number'
                })
            
            # ç¢ºä¿ç‰ˆæœ¬è™Ÿæ˜¯å­—ç¬¦ä¸²
            if version_info['version_number']:
                version_info['version_number'] = str(version_info['version_number'])
            
            return version_info
            
        except Exception as e:
            self.logger.debug(f"è§£æç‰ˆæœ¬ç›®éŒ„å¤±æ•— {dir_name}: {e}")
            return None
    
    def _parse_and_sort_version_directories(self, items: List) -> List[Dict]:
        """è§£æå’Œæ’åºç‰ˆæœ¬ç›®éŒ„"""
        version_dirs = []
        
        for item in items:
            if item.st_mode & 0o40000:  # æ˜¯ç›®éŒ„
                if self._is_version_directory(item.filename):
                    version_info = self._parse_version_directory(item.filename, item.st_mtime)
                    if version_info:
                        version_dirs.append(version_info)
        
        # æ’åºé‚è¼¯ï¼šç‰ˆæœ¬è™Ÿï¼ˆæ•¸å­—ï¼‰é™åº -> æ™‚é–“æˆ³é™åº -> ä¿®æ”¹æ™‚é–“é™åº
        # å¸¶å¾Œç¶´çš„ç‰ˆæœ¬å„ªå…ˆç´šè¼ƒä½ï¼ˆé€šå¸¸æ˜¯å¤±æ•—çš„å»ºç½®ï¼‰
        def sort_key(x):
            version_num = 0
            try:
                if x['version_number'] and x['version_number'].isdigit():
                    version_num = int(x['version_number'])
            except:
                pass
            
            timestamp = x.get('timestamp', 0) or 0
            mtime = x.get('mtime', 0) or 0
            has_suffix = x.get('has_suffix', False)
            
            # æœ‰å¾Œç¶´çš„ç‰ˆæœ¬æ’åœ¨å¾Œé¢ï¼ˆå„ªå…ˆç´šè¼ƒä½ï¼‰
            suffix_penalty = 1 if has_suffix else 0
            
            return (version_num, -suffix_penalty, timestamp, mtime)
        
        version_dirs.sort(key=sort_key, reverse=True)
        
        return version_dirs
    
    def _calculate_manifest_priority(self, filename: str, version_num: str) -> int:
        """è¨ˆç®— manifest æ–‡ä»¶çš„å„ªå…ˆç´š"""
        priority = 0
        
        # æ–‡ä»¶ååŒ…å« manifest å¾—åˆ†
        if 'manifest' in filename.lower():
            priority += 100
        
        # åŒ…å«ç‰ˆæœ¬è™Ÿå¾—åˆ†
        if version_num and version_num in filename:
            priority += 50
        
        # ç‰¹å®šå‘½åæ¨¡å¼å¾—åˆ†
        if filename.startswith('manifest_'):
            priority += 30
        
        # XML æ–‡ä»¶å¾—åˆ†
        if filename.endswith('.xml'):
            priority += 20
        
        # ç‰¹æ®Šå‘½åæ¨¡å¼çš„å„ªå…ˆç´š
        special_patterns = [
            'atv-google-refplus',  # Android TV Google Reference Plus
            'tv-google',           # TV Google
            'android-tv',          # Android TV
            'refplus',            # Reference Plus
            'master',             # Master manifest
            'default',            # Default manifest
        ]
        
        filename_lower = filename.lower()
        for pattern in special_patterns:
            if pattern in filename_lower:
                priority += 10
        
        return priority
    
    def find_latest_manifest(self, base_path: str, db_name: str = None) -> Optional[Tuple[str, str]]:
        """å°‹æ‰¾æœ€æ–°çš„ manifest æª”æ¡ˆï¼ˆå„ªåŒ–ç‰ˆ - åªæª¢æŸ¥æœ€æ–°ç‰ˆæœ¬ï¼‰"""
        thread_name = threading.current_thread().name
        
        try:
            sftp, client = self._get_connection()
            if not sftp:
                error_msg = "âŒ ç„¡æ³•å»ºç«‹ SFTP é€£ç·š"
                self._update_progress(db_name, "DOWNLOADING_MANIFEST", error_msg)
                raise Exception(error_msg)
            
            # Step 1: å¿«é€Ÿæƒæç›®éŒ„
            # self._update_progress(db_name, "DOWNLOADING_MANIFEST", f"ğŸ” æƒæç›®éŒ„: {os.path.basename(base_path)}")
            self.logger.info(f"[{thread_name}] ğŸ” æœç´¢è·¯å¾‘: {base_path}")
            
            try:
                start_scan = time.time()
                items = sftp.listdir_attr(base_path)
                scan_time = time.time() - start_scan
                
                self._update_progress(
                    db_name, 
                    "DOWNLOADING_MANIFEST", 
                    f"âœ… æ‰¾åˆ° {len(items)} å€‹é …ç›® ({scan_time:.1f}s)"
                )
                self.logger.info(f"[{thread_name}] âœ… æ‰¾åˆ° {len(items)} å€‹é …ç›®")
                
            except FileNotFoundError:
                error_msg = f"âŒ è·¯å¾‘ä¸å­˜åœ¨: {base_path}"
                self._update_progress(db_name, "DOWNLOADING_MANIFEST", error_msg)
                raise Exception(error_msg)
            except PermissionError:
                error_msg = f"ğŸš« æ¬Šé™è¢«æ‹’çµ•: {base_path}"
                self._update_progress(db_name, "DOWNLOADING_MANIFEST", error_msg)
                raise Exception(error_msg)
            except Exception as e:
                error_msg = f"âŒ è¨ªå•è·¯å¾‘å¤±æ•—: {str(e)}"
                self._update_progress(db_name, "DOWNLOADING_MANIFEST", error_msg)
                raise Exception(error_msg)
            
            # Step 2: å¿«é€Ÿè§£æä¸¦æ’åºç‰ˆæœ¬ç›®éŒ„
            self._update_progress(db_name, "DOWNLOADING_MANIFEST", f"ğŸ” è§£æç‰ˆæœ¬ç›®éŒ„...")
            
            version_dirs = self._parse_and_sort_version_directories(items)
            
            if not version_dirs:
                all_dirs = [item.filename for item in items if item.st_mode & 0o40000]
                if all_dirs:
                    sample_dirs = all_dirs[:5]
                    error_msg = f"ğŸ“‚ æ‰¾åˆ° {len(all_dirs)} å€‹ç›®éŒ„ä½†ç„¡æ³•è­˜åˆ¥ç‰ˆæœ¬æ ¼å¼ã€‚æ¨£æœ¬: {', '.join(sample_dirs)}"
                else:
                    error_msg = f"ğŸ“‚ è·¯å¾‘ç‚ºç©ºç›®éŒ„"
                
                self._update_progress(db_name, "DOWNLOADING_MANIFEST", error_msg)
                raise Exception(error_msg)
            
            # Step 3: åªæª¢æŸ¥æœ€æ–°çš„ç‰ˆæœ¬ç›®éŒ„ï¼ˆç¬¬ä¸€å€‹ï¼‰
            latest_version = version_dirs[0]  # å·²ç¶“æŒ‰ç‰ˆæœ¬è™Ÿå’Œæ™‚é–“æ’åºï¼Œç¬¬ä¸€å€‹å°±æ˜¯æœ€æ–°çš„
            version_dir = latest_version['dir_name']
            version_num = latest_version['version_number'] or latest_version['version']
            version_path = f"{base_path}/{version_dir}"
            
            # é¡¯ç¤ºç‰ˆæœ¬ç‹€æ…‹
            status_info = ""
            if latest_version.get('has_suffix'):
                status_info = f" (âš ï¸ {latest_version['suffix']})"
            
            self._update_progress(
                db_name, 
                "DOWNLOADING_MANIFEST", 
                f"ğŸ¯ æª¢æŸ¥æœ€æ–°ç‰ˆæœ¬ {version_num}: {version_dir[:40]}...{status_info}"
            )
            
            self.logger.info(f"[{thread_name}] ğŸ¯ æª¢æŸ¥æœ€æ–°ç‰ˆæœ¬: {version_dir} (ç‰ˆæœ¬è™Ÿ: {version_num})")
            
            try:
                # åˆ—å‡ºç‰ˆæœ¬ç›®éŒ„ä¸­çš„æª”æ¡ˆ
                start_list = time.time()
                version_files = sftp.listdir(version_path)
                list_time = time.time() - start_list
                
                self._update_progress(
                    db_name, 
                    "DOWNLOADING_MANIFEST", 
                    f"ğŸ” æœ€æ–°ç‰ˆæœ¬åŒ…å« {len(version_files)} å€‹æª”æ¡ˆ ({list_time:.1f}s)"
                )
                
                # å°‹æ‰¾æœ€ä½³çš„ manifest æª”æ¡ˆ
                manifest_candidates = []
                
                for filename in version_files:
                    if filename.endswith('.xml') and 'manifest' in filename.lower():
                        full_path = f"{version_path}/{filename}"
                        
                        try:
                            # æª¢æŸ¥æª”æ¡ˆå¤§å°
                            file_stat = sftp.stat(full_path)
                            file_size = file_stat.st_size
                            
                            if file_size > 100000:  # å¤§æ–¼ 100KB æ‰æ˜¯æœ‰æ•ˆçš„ manifest
                                manifest_candidates.append({
                                    'filename': filename,
                                    'path': full_path,
                                    'size': file_size,
                                    'priority': self._calculate_manifest_priority(filename, version_num)
                                })
                                
                                self.logger.info(f"[{thread_name}] ğŸ¯ æ‰¾åˆ°å€™é¸ manifest: {filename} ({file_size} bytes)")
                            
                        except Exception as e:
                            self.logger.debug(f"[{thread_name}] æª¢æŸ¥æª”æ¡ˆå¤±æ•—: {filename}, {e}")
                            continue
                
                # é¸æ“‡æœ€ä½³çš„ manifest
                if manifest_candidates:
                    # æŒ‰å„ªå…ˆç´šæ’åº
                    manifest_candidates.sort(key=lambda x: x['priority'], reverse=True)
                    best_manifest = manifest_candidates[0]
                    
                    self._update_progress(
                        db_name, 
                        "DOWNLOADING_MANIFEST", 
                        f"ğŸ¯ é¸å®š: {best_manifest['filename']} ({best_manifest['size']//1024} KB)"
                    )
                    
                    self.logger.info(f"[{thread_name}] âœ… é¸æ“‡æœ€ä½³ manifest: {best_manifest['filename']}")
                    return best_manifest['path'], best_manifest['filename']
                else:
                    error_msg = f"âŒ æœ€æ–°ç‰ˆæœ¬ {version_num} ä¸­æ²’æœ‰æœ‰æ•ˆçš„ manifest"
                    self._update_progress(db_name, "DOWNLOADING_MANIFEST", error_msg)
                    raise Exception(error_msg)
                    
            except FileNotFoundError:
                error_msg = f"ğŸ” ç‰ˆæœ¬ç›®éŒ„ä¸å­˜åœ¨: {version_path}"
                self._update_progress(db_name, "DOWNLOADING_MANIFEST", error_msg)
                raise Exception(error_msg)
            except PermissionError:
                error_msg = f"ğŸ” ç„¡æ¬Šé™è¨ªå•ç‰ˆæœ¬ç›®éŒ„: {version_path}"
                self._update_progress(db_name, "DOWNLOADING_MANIFEST", error_msg)
                raise Exception(error_msg)
            except Exception as e:
                error_msg = f"âŒ æª¢æŸ¥ç‰ˆæœ¬ç›®éŒ„å¤±æ•—: {str(e)}"
                self._update_progress(db_name, "DOWNLOADING_MANIFEST", error_msg)
                raise Exception(error_msg)
            
        except Exception as e:
            # æœ€çµ‚éŒ¯èª¤è™•ç†
            final_error = str(e)
            if not any(prefix in final_error for prefix in ["âŒ", "ğŸš«", "ğŸ”", "ğŸ”", "â°", "ğŸ“‚", "ğŸ“‹", "ğŸ”Œ", "â“"]):
                final_error = f"â“ æœªé æœŸçš„éŒ¯èª¤: {final_error}"
            
            self._update_progress(db_name, "DOWNLOADING_MANIFEST", final_error)
            self.logger.error(f"[{thread_name}] âŒ æœç´¢å¤±æ•—: {final_error}")
            return None
    
    def find_specific_manifest(self, base_path: str, version: str) -> Optional[Tuple[str, str]]:
        """å°‹æ‰¾ç‰¹å®šç‰ˆæœ¬çš„ manifest æ–‡ä»¶"""
        thread_name = threading.current_thread().name
        
        try:
            sftp, client = self._get_connection()
            if not sftp:
                raise Exception("ç„¡æ³•å»ºç«‹ SFTP é€£ç·š")
            
            self.logger.info(f"[{thread_name}] å°‹æ‰¾ç‰ˆæœ¬ {version} çš„ manifest: {base_path}")
            
            # å˜—è©¦ç›´æ¥åœ¨ç‰ˆæœ¬ç›®éŒ„ä¸­å°‹æ‰¾
            version_patterns = [
                f"{version}_all_*",
                f"{version}_*",
                version,
                f"v{version}",
                f"version_{version}"
            ]
            
            items = sftp.listdir_attr(base_path)
            
            for item in items:
                if item.st_mode & 0o40000:  # æ˜¯ç›®éŒ„
                    # æª¢æŸ¥æ˜¯å¦ç¬¦åˆç‰ˆæœ¬æ¨¡å¼
                    extracted_version = self._extract_version_number_flexible(item.filename)
                    if extracted_version == version:
                        version_path = f"{base_path}/{item.filename}"
                        
                        try:
                            # åœ¨ç‰ˆæœ¬ç›®éŒ„ä¸­å°‹æ‰¾ manifest
                            version_files = sftp.listdir(version_path)
                            
                            for filename in version_files:
                                if filename.endswith('.xml') and 'manifest' in filename.lower():
                                    full_path = f"{version_path}/{filename}"
                                    
                                    # æª¢æŸ¥æ–‡ä»¶å¤§å°
                                    file_stat = sftp.stat(full_path)
                                    if file_stat.st_size > 100000:  # å¤§æ–¼ 100KB
                                        self.logger.info(f"[{thread_name}] æ‰¾åˆ°æŒ‡å®šç‰ˆæœ¬çš„ manifest: {filename}")
                                        return full_path, filename
                        
                        except Exception as e:
                            self.logger.debug(f"[{thread_name}] æª¢æŸ¥ç‰ˆæœ¬ç›®éŒ„å¤±æ•—: {item.filename}, {e}")
                            continue
            
            raise Exception(f"æœªæ‰¾åˆ°ç‰ˆæœ¬ {version} çš„ manifest")
            
        except Exception as e:
            self.logger.error(f"[{thread_name}] å°‹æ‰¾ç‰¹å®šç‰ˆæœ¬ manifest å¤±æ•—: {e}")
            return None
    
    def download_file_with_progress(self, remote_file: str, local_file: str, db_name: str = None) -> bool:
        """ä¸‹è¼‰æª”æ¡ˆä¸¦é¡¯ç¤ºé€²åº¦"""
        thread_name = threading.current_thread().name
        
        try:
            sftp, client = self._get_connection()
            if not sftp:
                return False
            
            os.makedirs(os.path.dirname(local_file), exist_ok=True)
            filename = os.path.basename(remote_file)
            
            # ç²å–æª”æ¡ˆå¤§å°
            try:
                file_stat = sftp.stat(remote_file)
                file_size = file_stat.st_size
                file_size_mb = file_size / (1024 * 1024)
                
                self._update_progress(
                    db_name, 
                    "DOWNLOADING_MANIFEST", 
                    f"â¬‡ï¸ é–‹å§‹ä¸‹è¼‰: {filename} ({file_size_mb:.1f} MB)"
                )
            except:
                file_size = 0
                self._update_progress(
                    db_name, 
                    "DOWNLOADING_MANIFEST", 
                    f"â¬‡ï¸ é–‹å§‹ä¸‹è¼‰: {filename}"
                )
            
            self.logger.info(f"[{thread_name}] â¬‡ï¸ ä¸‹è¼‰: {filename}")
            
            # é–‹å§‹ä¸‹è¼‰
            start_download = time.time()
            
            # ä½¿ç”¨å›èª¿å‡½æ•¸é¡¯ç¤ºä¸‹è¼‰é€²åº¦ï¼ˆå¦‚æœæª”æ¡ˆè¼ƒå¤§ï¼‰
            if file_size > 1024 * 1024:  # å¤§æ–¼ 1MB çš„æª”æ¡ˆé¡¯ç¤ºé€²åº¦
                downloaded = 0
                last_update = 0
                
                def progress_callback(transferred, total):
                    nonlocal downloaded, last_update
                    downloaded = transferred
                    current_time = time.time()
                    
                    # æ¯ 2 ç§’æ›´æ–°ä¸€æ¬¡é€²åº¦ï¼Œé¿å…éæ–¼é »ç¹
                    if current_time - last_update >= 2.0:
                        if total > 0:
                            progress_percent = (transferred / total) * 100
                            elapsed = current_time - start_download
                            speed_mbps = (transferred / (1024 * 1024)) / max(elapsed, 0.1)
                            
                            self._update_progress(
                                db_name, 
                                "DOWNLOADING_MANIFEST", 
                                f"â¬‡ï¸ {filename}: {progress_percent:.1f}% ({speed_mbps:.1f} MB/s)"
                            )
                        last_update = current_time
                
                # è¨»ï¼šparamiko çš„ get æ–¹æ³•æ”¯æ´ callback åƒæ•¸
                try:
                    sftp.get(remote_file, local_file, callback=progress_callback)
                except TypeError:
                    # å¦‚æœä¸æ”¯æ´ callbackï¼Œä½¿ç”¨æ™®é€šä¸‹è¼‰
                    sftp.get(remote_file, local_file)
            else:
                # å°æª”æ¡ˆç›´æ¥ä¸‹è¼‰
                sftp.get(remote_file, local_file)
            
            download_time = time.time() - start_download
            
            # é©—è­‰ä¸‹è¼‰çš„æª”æ¡ˆ
            if os.path.exists(local_file) and os.path.getsize(local_file) > 0:
                actual_size = os.path.getsize(local_file)
                speed_mbps = (actual_size / (1024 * 1024)) / max(download_time, 0.1)
                
                self._update_progress(
                    db_name, 
                    "DOWNLOADING_MANIFEST", 
                    f"âœ… ä¸‹è¼‰å®Œæˆ: {filename} ({actual_size//1024} KB, {speed_mbps:.1f} MB/s)"
                )
                
                self.logger.info(f"[{thread_name}] âœ… ä¸‹è¼‰å®Œæˆ: {filename} ({download_time:.1f}s)")
                return True
            else:
                self._update_progress(
                    db_name, 
                    "DOWNLOADING_MANIFEST", 
                    f"âŒ ä¸‹è¼‰å¤±æ•—: {filename} (æª”æ¡ˆç„¡æ•ˆ)"
                )
                self.logger.error(f"[{thread_name}] ä¸‹è¼‰çš„æª”æ¡ˆç„¡æ•ˆæˆ–ç‚ºç©º")
                return False
                
        except Exception as e:
            self._update_progress(
                db_name, 
                "DOWNLOADING_MANIFEST", 
                f"âŒ ä¸‹è¼‰å¤±æ•—: {os.path.basename(remote_file)} - {str(e)[:30]}..."
            )
            self.logger.error(f"[{thread_name}] ä¸‹è¼‰å¤±æ•—: {str(e)}")
            return False
    
    def detect_version_directory_patterns(self, base_path: str, db_name: str = None) -> Dict[str, List[str]]:
        """æª¢æ¸¬ç›®éŒ„ä¸­çš„ç‰ˆæœ¬ç›®éŒ„å‘½åæ¨¡å¼"""
        try:
            sftp, client = self._get_connection()
            if not sftp:
                return {}
            
            items = sftp.listdir_attr(base_path)
            patterns = {
                'version_all_timestamp': [],         # 206_all_202507100000
                'version_all_timestamp_suffix': [],  # 465_all_202502170030_NG_uboot_fail
                'version_timestamp': [],             # 204_202507081101
                'version_timestamp_suffix': [],      # 466_202502171018_NG_uboot_fail
                'simple_number': [],                 # 206, 204
                'v_number': [],                      # v206, v204
                'unknown': []                        # å…¶ä»–æ ¼å¼
            }
            
            for item in items:
                if item.st_mode & 0o40000:  # æ˜¯ç›®éŒ„
                    dir_name = item.filename
                    
                    if re.match(r'^\d+_all_\d{12}_.*$', dir_name):
                        patterns['version_all_timestamp_suffix'].append(dir_name)
                    elif re.match(r'^\d+_all_\d{12}$', dir_name):
                        patterns['version_all_timestamp'].append(dir_name)
                    elif re.match(r'^\d+_\d{12}_.*$', dir_name):
                        patterns['version_timestamp_suffix'].append(dir_name)
                    elif re.match(r'^\d+_\d{12}$', dir_name):
                        patterns['version_timestamp'].append(dir_name)
                    elif re.match(r'^\d+$', dir_name):
                        patterns['simple_number'].append(dir_name)
                    elif re.match(r'^v\d+$', dir_name):
                        patterns['v_number'].append(dir_name)
                    elif any(char.isdigit() for char in dir_name):
                        patterns['unknown'].append(dir_name)
            
            # åªè¿”å›æœ‰å…§å®¹çš„æ¨¡å¼
            return {k: v for k, v in patterns.items() if v}
            
        except Exception as e:
            self.logger.error(f"æª¢æ¸¬ç‰ˆæœ¬ç›®éŒ„æ¨¡å¼å¤±æ•—: {e}")
            return {}

# =====================================
# ===== Repo ç®¡ç†å™¨ï¼ˆæ”¹å–„ä¸¦ç™¼å®‰å…¨ï¼‰ =====
# =====================================

class RepoSyncProgress:
    """Repo sync é€²åº¦è§£æå™¨ï¼ˆå¢å¼·ç‰ˆ - åŒ…å«ç£ç¢Ÿç©ºé–“éŒ¯èª¤æª¢æ¸¬ï¼‰"""
    
    def parse_sync_log(self, log_file: str) -> Dict[str, Any]:
        """è§£æ repo sync æ—¥èªŒï¼Œæå–é€²åº¦ä¿¡æ¯ï¼ˆå¢å¼·ç‰ˆï¼‰"""
        if not os.path.exists(log_file):
            return self._default_progress()
        
        try:
            with open(log_file, 'r', encoding='utf-8', errors='ignore') as f:
                lines = f.readlines()
            
            if not lines:
                return self._default_progress()
            
            # è§£ææœ€å¾Œ 100 è¡Œ
            recent_lines = lines[-100:] if len(lines) > 100 else lines
            
            progress_info = {
                'status': 'syncing',
                'overall_progress': '0%',
                'current_projects': 0,
                'total_projects': 0,
                'current_repo': '',
                'last_activity': '',
                'speed': '',
                'errors': [],
                'error_type': '',
                'disk_space_error': False  # æ–°å¢ï¼šç£ç¢Ÿç©ºé–“éŒ¯èª¤æ¨™è¨˜
            }
            
            for line in recent_lines:
                line = line.strip()
                if not line:
                    continue
                
                # è§£ææ•´é«”é€²åº¦
                progress_match = re.search(r'Fetching projects:\s*(\d+)%\s*\((\d+)/(\d+)\)', line)
                if progress_match:
                    progress_info['overall_progress'] = f"{progress_match.group(1)}%"
                    progress_info['current_projects'] = int(progress_match.group(2))
                    progress_info['total_projects'] = int(progress_match.group(3))
                    continue
                
                # è§£æç•¶å‰è™•ç†çš„ repository
                repo_patterns = [
                    r'Fetching project (.+)',
                    r'Fetching (.+?)\.\.\.', 
                    r'remote: Counting objects.*?(\S+)',
                    r'Receiving objects.*?(\S+)'
                ]
                
                for pattern in repo_patterns:
                    repo_match = re.search(pattern, line)
                    if repo_match:
                        progress_info['current_repo'] = repo_match.group(1).strip()
                        break
                
                # è§£æä¸‹è¼‰é€Ÿåº¦
                speed_patterns = [
                    r'(\d+(?:\.\d+)?\s*[KM]B/s)',
                    r'(\d+(?:\.\d+)?\s*[KM]iB/s)'
                ]
                
                for pattern in speed_patterns:
                    speed_match = re.search(pattern, line)
                    if speed_match:
                        progress_info['speed'] = speed_match.group(1)
                        break
                
                # æª¢æŸ¥å®Œæˆç‹€æ…‹
                completion_keywords = ['repo sync has finished', 'sync completed', 'success']
                if any(keyword in line.lower() for keyword in completion_keywords):
                    progress_info['status'] = 'completed'
                    progress_info['overall_progress'] = '100%'
                    continue
                
                # æª¢æŸ¥éŒ¯èª¤ä¸¦åˆ†æé¡å‹
                error_keywords = ['error', 'failed', 'fatal', 'cannot']
                if any(keyword in line.lower() for keyword in error_keywords):
                    if len(progress_info['errors']) < 3:
                        progress_info['errors'].append(line[:120])
                    
                    line_lower = line.lower()
                    
                    # ç£ç¢Ÿç©ºé–“ç›¸é—œéŒ¯èª¤
                    disk_keywords = ['no space left', 'disk full', 'out of space', 'enospc']
                    if any(keyword in line_lower for keyword in disk_keywords):
                        progress_info['error_type'] = 'disk_space_error'
                        progress_info['disk_space_error'] = True
                        progress_info['status'] = 'failed'
                        
                        # åœ¨ console é¡¯ç¤ºç£ç¢Ÿç©ºé–“éŒ¯èª¤
                        print("\n" + "ğŸš¨" * 50)
                        print("âš ï¸  æª¢æ¸¬åˆ°ç£ç¢Ÿç©ºé–“ä¸è¶³éŒ¯èª¤ï¼")
                        print("ğŸš¨" * 50)
                        print(f"éŒ¯èª¤è©³æƒ…: {line[:100]}")
                        print("ğŸ’¡ è«‹ç«‹å³æ¸…ç†ç£ç¢Ÿç©ºé–“å¾Œé‡æ–°åŸ·è¡Œ")
                        print("ğŸš¨" * 50 + "\n")
                        
                    # å…¶ä»–éŒ¯èª¤é¡å‹
                    elif 'cannot checkout' in line_lower:
                        progress_info['error_type'] = 'checkout_error'
                        progress_info['status'] = 'failed'
                    elif 'cannot initialize' in line_lower:
                        progress_info['error_type'] = 'init_error'
                        progress_info['status'] = 'failed'
                    elif any(net_keyword in line_lower for net_keyword in ['network', 'connection', 'timeout', 'unreachable']):
                        progress_info['error_type'] = 'network_error'
                    elif 'permission' in line_lower:
                        progress_info['error_type'] = 'permission_error'
                        progress_info['status'] = 'failed'
                
                # æ›´æ–°æœ€å¾Œæ´»å‹•æ™‚é–“
                time_patterns = [
                    r'(\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2})',
                    r'(\d{2}:\d{2}:\d{2})'
                ]
                
                for pattern in time_patterns:
                    time_match = re.search(pattern, line)
                    if time_match:
                        progress_info['last_activity'] = time_match.group(1)
                        break
            
            return progress_info
            
        except Exception as e:
            self.logger.error(f"è§£æ sync æ—¥èªŒå¤±æ•—: {e}")
            return self._default_progress()
 
class RepoManager:
    """Repo æŒ‡ä»¤ç®¡ç†å™¨ï¼ˆå®Œæ•´ç‰ˆï¼‰"""
    
    def __init__(self):
        self.logger = setup_logger(self.__class__.__name__)
        self.lock = threading.Lock()
        self.source_cmd_manager = SourceCommandManager()
    
    def check_repo_exists(self, work_dir: str) -> bool:
        """æª¢æŸ¥ .repo ç›®éŒ„æ˜¯å¦å­˜åœ¨"""
        repo_dir = os.path.join(work_dir, '.repo')
        exists = os.path.exists(repo_dir)
        self.logger.info(f"æª¢æŸ¥ .repo æ˜¯å¦å­˜åœ¨æ–¼ {work_dir}: {exists}")
        return exists
    
    def run_command(self, cmd: str, cwd: str = None, timeout: int = None) -> Tuple[bool, str]:
        """åŒæ­¥åŸ·è¡ŒæŒ‡ä»¤"""
        try:
            self.logger.debug(f"åŸ·è¡Œ: {cmd}")
            result = subprocess.run(
                cmd,
                shell=True,
                cwd=cwd,
                capture_output=True,
                text=True,
                timeout=timeout
            )
            
            if result.returncode == 0:
                return True, result.stdout
            else:
                return False, result.stderr
                
        except subprocess.TimeoutExpired:
            return False, "Command timeout"
        except Exception as e:
            return False, str(e)
    
    def repo_init(self, work_dir: str, init_cmd: str) -> bool:
        """åŸ·è¡Œ repo init"""
        # æ¸…ç†å¯èƒ½å­˜åœ¨çš„èˆŠ .repo ç›®éŒ„
        repo_dir = os.path.join(work_dir, '.repo')
        if os.path.exists(repo_dir):
            self.logger.info(f"æ¸…ç†èˆŠçš„ .repo ç›®éŒ„: {repo_dir}")
            import shutil
            try:
                shutil.rmtree(repo_dir)
            except Exception as e:
                self.logger.warning(f"æ¸…ç† .repo å¤±æ•—: {e}")
        
        success, output = self.run_command(
            init_cmd,
            cwd=work_dir,
            timeout=config_manager.repo_config['init_timeout']
        )
        
        if success:
            self.logger.info(f"Repo init æˆåŠŸ: {work_dir}")
        else:
            self.logger.error(f"Repo init å¤±æ•—: {output}")
        
        return success
    
    def apply_manifest(self, work_dir: str, manifest_file: str) -> bool:
        """
        æ‡‰ç”¨ manifest æª”æ¡ˆï¼ˆæ”¹å–„ç‰ˆ - è™•ç†ç‰ˆæœ¬åˆ‡æ›å’Œæ¸…ç†å•é¡Œï¼‰
        """
        try:
            manifest_name = os.path.basename(manifest_file)
            self.logger.info(f"æº–å‚™æ‡‰ç”¨ manifest: {manifest_name}")
            
            # 1. æª¢æŸ¥ .repo ç›®éŒ„ç‹€æ…‹
            repo_dir = os.path.join(work_dir, '.repo')
            manifests_dir = os.path.join(repo_dir, 'manifests')
            
            if not os.path.exists(manifests_dir):
                self.logger.error(f"Manifests ç›®éŒ„ä¸å­˜åœ¨: {manifests_dir}")
                return False
            
            # 2. æ¸…ç†å¯èƒ½çš„æ®˜ç•™ç‹€æ…‹ï¼ˆé‡è¦ï¼šè™•ç†æœ¬åœ°ä¿®æ”¹å’Œè¡çªï¼‰
            if not self._cleanup_repo_state(work_dir):
                self.logger.warning("æ¸…ç† repo ç‹€æ…‹æ™‚é‡åˆ°å•é¡Œï¼Œä½†ç¹¼çºŒè™•ç†")
            
            # 3. è¤‡è£½æ–°çš„ manifest æ–‡ä»¶
            dest_file = os.path.join(manifests_dir, manifest_name)
            
            # å¦‚æœç›®æ¨™æ–‡ä»¶å·²å­˜åœ¨ä¸”å…§å®¹ç›¸åŒï¼Œè·³éè¤‡è£½
            if os.path.exists(dest_file):
                if self._compare_files(manifest_file, dest_file):
                    self.logger.info(f"Manifest æ–‡ä»¶å·²å­˜åœ¨ä¸”ç›¸åŒ: {manifest_name}")
                else:
                    self.logger.info(f"æ›´æ–° manifest æ–‡ä»¶: {manifest_name}")
                    import shutil
                    shutil.copy2(manifest_file, dest_file)
            else:
                import shutil
                shutil.copy2(manifest_file, dest_file)
                self.logger.info(f"è¤‡è£½ manifest: {manifest_file} -> {dest_file}")
            
            # 4. æª¢æŸ¥ä¸¦è™•ç† repo ç‰ˆæœ¬å…¼å®¹æ€§
            if not self._check_repo_compatibility(work_dir, manifest_name):
                self.logger.warning("Repo ç‰ˆæœ¬å¯èƒ½éèˆŠï¼Œå˜—è©¦æ›´æ–°...")
                self._update_repo_metadata(work_dir)
            
            # 5. åˆ‡æ›åˆ°æŒ‡å®šçš„ manifest
            success = self._switch_to_manifest(work_dir, manifest_name)
            
            if success:
                self.logger.info(f"æˆåŠŸåˆ‡æ›åˆ° manifest: {manifest_name}")
                
                # 6. é©—è­‰åˆ‡æ›çµæœ
                if self._verify_manifest_switch(work_dir, manifest_name):
                    return True
                else:
                    self.logger.error("Manifest åˆ‡æ›é©—è­‰å¤±æ•—")
                    return False
            else:
                self.logger.error(f"åˆ‡æ› manifest å¤±æ•—")
                return False
                
        except Exception as e:
            self.logger.error(f"æ‡‰ç”¨ manifest å¤±æ•—: {str(e)}")
            return False
    
    def _cleanup_repo_state(self, work_dir: str) -> bool:
        """
        æ¸…ç† repo ç‹€æ…‹ - è™•ç†æ®˜ç•™ diff å’Œæœ¬åœ°ä¿®æ”¹
        """
        try:
            self.logger.info("æ¸…ç† repo ç‹€æ…‹ä¸­...")
            
            # 1. é‡ç½®æ‰€æœ‰æœ¬åœ°ä¿®æ”¹ï¼ˆè™•ç†æ®˜ç•™ diffï¼‰
            reset_cmd = "repo forall -c 'git reset --hard HEAD 2>/dev/null || true'"
            success, output = self.run_command(reset_cmd, cwd=work_dir, timeout=120)
            if not success:
                self.logger.warning(f"é‡ç½®æœ¬åœ°ä¿®æ”¹è­¦å‘Š: {output}")
            
            # 2. æ¸…ç†æœªè¿½è¹¤çš„æ–‡ä»¶
            clean_cmd = "repo forall -c 'git clean -fd 2>/dev/null || true'"
            success, output = self.run_command(clean_cmd, cwd=work_dir, timeout=120)
            if not success:
                self.logger.warning(f"æ¸…ç†æœªè¿½è¹¤æ–‡ä»¶è­¦å‘Š: {output}")
            
            # 3. æ¸…ç†å¯èƒ½æå£çš„ git ç‹€æ…‹
            stash_cmd = "repo forall -c 'git stash clear 2>/dev/null || true'"
            self.run_command(stash_cmd, cwd=work_dir, timeout=60)
            
            # 4. æª¢æŸ¥ä¸¦æ¸…ç†æå£çš„ .repo/project-objects
            project_objects_dir = os.path.join(work_dir, '.repo', 'project-objects')
            if os.path.exists(project_objects_dir):
                # æª¢æŸ¥æ˜¯å¦æœ‰æå£çš„ç‰©ä»¶
                self._check_and_repair_git_objects(project_objects_dir)
            
            self.logger.info("Repo ç‹€æ…‹æ¸…ç†å®Œæˆ")
            return True
            
        except Exception as e:
            self.logger.error(f"æ¸…ç† repo ç‹€æ…‹å¤±æ•—: {e}")
            return False
    
    def _check_repo_compatibility(self, work_dir: str, manifest_name: str) -> bool:
        """
        æª¢æŸ¥ repo ç‰ˆæœ¬å…¼å®¹æ€§ï¼ˆè™•ç†æœ¬åœ° repo å¤ªèˆŠçš„å•é¡Œï¼‰
        """
        try:
            # 1. æª¢æŸ¥ repo ç‰ˆæœ¬
            version_cmd = f"{config_manager.repo_config['repo_command']} version"
            success, output = self.run_command(version_cmd, cwd=work_dir, timeout=30)
            
            if success:
                self.logger.debug(f"Repo ç‰ˆæœ¬ä¿¡æ¯: {output}")
                
                # æª¢æŸ¥æ˜¯å¦ç‚ºèˆŠç‰ˆæœ¬ï¼ˆç°¡å–®æª¢æŸ¥ï¼‰
                if "repo launcher version" in output.lower():
                    version_line = [line for line in output.split('\n') if 'repo launcher version' in line.lower()]
                    if version_line:
                        self.logger.info(f"ç•¶å‰ repo ç‰ˆæœ¬: {version_line[0]}")
            
            # 2. æª¢æŸ¥ .repo/repo ç›®éŒ„çš„ç‹€æ…‹
            repo_repo_dir = os.path.join(work_dir, '.repo', 'repo')
            if os.path.exists(repo_repo_dir):
                # æª¢æŸ¥ repo å·¥å…·æ˜¯å¦å¤ªèˆŠ
                repo_git_cmd = "git log --oneline -1"
                success, output = self.run_command(repo_git_cmd, cwd=repo_repo_dir, timeout=30)
                if success:
                    self.logger.debug(f"Repo å·¥å…·æœ€æ–°æäº¤: {output}")
                else:
                    self.logger.warning("ç„¡æ³•ç²å– repo å·¥å…·ç‰ˆæœ¬ä¿¡æ¯")
                    return False
            
            # 3. æª¢æŸ¥ manifests ç›®éŒ„çš„ git ç‹€æ…‹
            manifests_dir = os.path.join(work_dir, '.repo', 'manifests')
            if os.path.exists(manifests_dir):
                status_cmd = "git status --porcelain"
                success, output = self.run_command(status_cmd, cwd=manifests_dir, timeout=30)
                if success and output.strip():
                    self.logger.warning(f"Manifests ç›®éŒ„æœ‰æœªæäº¤çš„ä¿®æ”¹: {output}")
                    # æ¸…ç† manifests ç›®éŒ„çš„ä¿®æ”¹
                    self.run_command("git reset --hard HEAD", cwd=manifests_dir, timeout=30)
                    self.run_command("git clean -fd", cwd=manifests_dir, timeout=30)
            
            return True
            
        except Exception as e:
            self.logger.warning(f"æª¢æŸ¥ repo å…¼å®¹æ€§å¤±æ•—: {e}")
            return False
    
    def _update_repo_metadata(self, work_dir: str) -> bool:
        """
        æ›´æ–° repo å…ƒæ•¸æ“šï¼ˆè™•ç†èˆŠç‰ˆæœ¬å•é¡Œï¼‰
        """
        try:
            self.logger.info("æ›´æ–° repo å…ƒæ•¸æ“š...")
            
            # 1. æ›´æ–° repo å·¥å…·æœ¬èº«
            repo_sync_cmd = f"{config_manager.repo_config['repo_command']} selfupdate"
            success, output = self.run_command(repo_sync_cmd, cwd=work_dir, timeout=120)
            
            if success:
                self.logger.info("Repo å·¥å…·æ›´æ–°æˆåŠŸ")
            else:
                self.logger.warning(f"Repo å·¥å…·æ›´æ–°å¤±æ•—ï¼Œä½†ç¹¼çºŒè™•ç†: {output}")
            
            # 2. åŒæ­¥ manifests å€‰åº«
            manifests_dir = os.path.join(work_dir, '.repo', 'manifests')
            if os.path.exists(manifests_dir):
                fetch_cmd = "git fetch origin"
                success, output = self.run_command(fetch_cmd, cwd=manifests_dir, timeout=120)
                if success:
                    self.logger.info("Manifests å€‰åº«æ›´æ–°æˆåŠŸ")
                else:
                    self.logger.warning(f"Manifests å€‰åº«æ›´æ–°å¤±æ•—: {output}")
            
            return True
            
        except Exception as e:
            self.logger.error(f"æ›´æ–° repo å…ƒæ•¸æ“šå¤±æ•—: {e}")
            return False
    
    def _switch_to_manifest(self, work_dir: str, manifest_name: str) -> bool:
        """
        åˆ‡æ›åˆ°æŒ‡å®šçš„ manifestï¼ˆæ”¹é€²ç‰ˆæœ¬ï¼‰
        """
        try:
            # 1. é¦–å…ˆå˜—è©¦ç°¡å–®çš„åˆ‡æ›
            simple_cmd = f"{config_manager.repo_config['repo_command']} init -m {manifest_name}"
            success, output = self.run_command(
                simple_cmd,
                cwd=work_dir,
                timeout=config_manager.repo_config['init_timeout']
            )
            
            if success:
                self.logger.info(f"ç°¡å–®åˆ‡æ›æˆåŠŸ: {manifest_name}")
                return True
            
            # 2. å¦‚æœç°¡å–®åˆ‡æ›å¤±æ•—ï¼Œå˜—è©¦æ›´å®Œæ•´çš„æ–¹æ³•
            self.logger.warning(f"ç°¡å–®åˆ‡æ›å¤±æ•—ï¼Œå˜—è©¦å®Œæ•´é‡æ–°åˆå§‹åŒ–: {output}")
            
            # ç²å–åŸå§‹çš„ repo init åƒæ•¸
            repo_dir = os.path.join(work_dir, '.repo')
            manifest_xml = os.path.join(repo_dir, 'manifest.xml')
            
            if os.path.exists(manifest_xml):
                # è®€å–ç•¶å‰çš„ repo é…ç½®
                manifest_repo_dir = os.path.join(repo_dir, 'manifests')
                if os.path.exists(manifest_repo_dir):
                    # ç²å– remote URL
                    remote_cmd = "git remote get-url origin"
                    success, remote_url = self.run_command(remote_cmd, cwd=manifest_repo_dir, timeout=30)
                    
                    if success and remote_url.strip():
                        # ç²å–ç•¶å‰åˆ†æ”¯
                        branch_cmd = "git rev-parse --abbrev-ref HEAD"
                        success, branch = self.run_command(branch_cmd, cwd=manifest_repo_dir, timeout=30)
                        
                        if success and branch.strip():
                            # é‡æ–°åˆå§‹åŒ–
                            full_cmd = f"{config_manager.repo_config['repo_command']} init -u {remote_url.strip()} -b {branch.strip()} -m {manifest_name}"
                            success, output = self.run_command(
                                full_cmd,
                                cwd=work_dir,
                                timeout=config_manager.repo_config['init_timeout']
                            )
                            
                            if success:
                                self.logger.info(f"å®Œæ•´é‡æ–°åˆå§‹åŒ–æˆåŠŸ: {manifest_name}")
                                return True
                            else:
                                self.logger.error(f"å®Œæ•´é‡æ–°åˆå§‹åŒ–å¤±æ•—: {full_cmd}")
            
            return False
            
        except Exception as e:
            self.logger.error(f"åˆ‡æ› manifest å¤±æ•—: {e}")
            return False
    
    def _verify_manifest_switch(self, work_dir: str, expected_manifest: str) -> bool:
        """
        é©—è­‰ manifest åˆ‡æ›æ˜¯å¦æˆåŠŸ
        """
        try:
            # æª¢æŸ¥ç•¶å‰ä½¿ç”¨çš„ manifest
            manifest_link = os.path.join(work_dir, '.repo', 'manifest.xml')
            
            if os.path.islink(manifest_link):
                # å¦‚æœæ˜¯ç¬¦è™Ÿé€£çµï¼Œæª¢æŸ¥æŒ‡å‘çš„æ–‡ä»¶
                target = os.readlink(manifest_link)
                if expected_manifest in target:
                    self.logger.info(f"Manifest åˆ‡æ›é©—è­‰æˆåŠŸ: {target}")
                    return True
                else:
                    self.logger.error(f"Manifest åˆ‡æ›é©—è­‰å¤±æ•—: æœŸæœ› {expected_manifest}, å¯¦éš› {target}")
                    return False
            elif os.path.exists(manifest_link):
                # å¦‚æœæ˜¯å¯¦éš›æ–‡ä»¶ï¼Œæª¢æŸ¥å…§å®¹æˆ–æ–‡ä»¶å
                self.logger.info("Manifest æ–‡ä»¶å­˜åœ¨ï¼Œåˆ‡æ›å¯èƒ½æˆåŠŸ")
                return True
            else:
                self.logger.error("Manifest æ–‡ä»¶ä¸å­˜åœ¨")
                return False
            
        except Exception as e:
            self.logger.warning(f"é©—è­‰ manifest åˆ‡æ›å¤±æ•—: {e}")
            return True  # é©—è­‰å¤±æ•—æ™‚å‡è¨­æˆåŠŸï¼Œè®“å¾ŒçºŒæµç¨‹ç¹¼çºŒ
    
    def _check_and_repair_git_objects(self, objects_dir: str):
        """
        æª¢æŸ¥ä¸¦ä¿®å¾©æå£çš„ git ç‰©ä»¶
        """
        try:
            # ç°¡å–®æª¢æŸ¥ï¼šéæ­·æ‰€æœ‰ .git ç›®éŒ„ä¸¦é‹è¡Œ git fsck
            for root, dirs, files in os.walk(objects_dir):
                if '.git' in dirs:
                    git_dir = os.path.join(root, '.git')
                    parent_dir = root
                    
                    # é‹è¡Œ git fsck æª¢æŸ¥
                    fsck_cmd = "git fsck --full 2>/dev/null || true"
                    self.run_command(fsck_cmd, cwd=parent_dir, timeout=60)
                    
                    # å¦‚æœæœ‰å•é¡Œï¼Œå˜—è©¦ä¿®å¾©
                    gc_cmd = "git gc --aggressive 2>/dev/null || true"
                    self.run_command(gc_cmd, cwd=parent_dir, timeout=120)
                    
        except Exception as e:
            self.logger.warning(f"æª¢æŸ¥ git ç‰©ä»¶æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    def _compare_files(self, file1: str, file2: str) -> bool:
        """
        æ¯”è¼ƒå…©å€‹æ–‡ä»¶æ˜¯å¦ç›¸åŒ
        """
        try:
            import filecmp
            return filecmp.cmp(file1, file2, shallow=False)
        except Exception:
            return False
    
    def start_repo_sync_async(self, work_dir: str, db_name: str, force_sync: bool = False) -> subprocess.Popen:
        """å•Ÿå‹•ç•°æ­¥ repo syncï¼ˆåŸºç¤ç‰ˆï¼‰"""
        try:
            # æ§‹å»º sync å‘½ä»¤
            sync_cmd_parts = [
                config_manager.repo_config['repo_command'],
                'sync'
            ]
            
            # ä¸¦è¡Œæ•¸
            sync_cmd_parts.extend(['-j', str(config_manager.repo_config['sync_jobs'])])
            
            # é‡è©¦æ¬¡æ•¸
            if config_manager.repo_config['sync_retry'] > 0:
                sync_cmd_parts.extend(['--retry-fetches', str(config_manager.repo_config['sync_retry'])])
            
            # å¦‚æœæ˜¯ä¿®å¾©æ¨¡å¼ï¼ŒåŠ å…¥æ›´å¼·åŠ›çš„åƒæ•¸
            if force_sync:
                sync_cmd_parts.extend([
                    '--force-sync',      # å¼·åˆ¶åŒæ­¥
                    '--force-remove-dirty',  # å¼·åˆ¶ç§»é™¤é«’æ•¸æ“š
                    '--no-clone-bundle'  # ä¸ä½¿ç”¨ clone bundleï¼ˆæœ‰æ™‚æœƒæœ‰å•é¡Œï¼‰
                ])
                self.logger.info(f"{db_name} ä½¿ç”¨å¼·åˆ¶åŒæ­¥æ¨¡å¼")
            
            cmd = ' '.join(sync_cmd_parts)
            
            self.logger.info(f"{db_name} å•Ÿå‹•ç•°æ­¥å‘½ä»¤: {cmd}")
            
            # å»ºç«‹æ—¥èªŒæª”æ¡ˆ
            log_dir = os.path.join(work_dir, 'logs')
            os.makedirs(log_dir, exist_ok=True)
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            retry_suffix = "_retry" if force_sync else ""
            log_file = os.path.join(log_dir, f'repo_sync_{timestamp}{retry_suffix}.log')
            
            with open(log_file, 'w') as f:
                f.write(f"é–‹å§‹æ™‚é–“: {datetime.now()}\n")
                f.write(f"å‘½ä»¤: {cmd}\n")
                f.write(f"å·¥ä½œç›®éŒ„: {work_dir}\n")
                f.write("="*50 + "\n")
                f.flush()
                
                process = subprocess.Popen(
                    cmd,
                    shell=True,
                    cwd=work_dir,
                    stdout=f,
                    stderr=subprocess.STDOUT,
                    text=True
                )
            
            # è¨»å†Šåˆ°è³‡æºç®¡ç†å™¨
            resource_manager.register_process(db_name, process)
            
            self.logger.info(f"{db_name} ç•°æ­¥é€²ç¨‹å·²å•Ÿå‹• (PID: {process.pid}), æ—¥èªŒ: {log_file}")
            return process
            
        except Exception as e:
            self.logger.error(f"{db_name} å•Ÿå‹•ç•°æ­¥æŒ‡ä»¤å¤±æ•—: {str(e)}")
            return None
    
    def start_repo_sync_async_with_retry(self, work_dir: str, db_name: str, max_retries: int = 3) -> subprocess.Popen:
        """å•Ÿå‹•ç•°æ­¥ repo sync ä¸¦åŒ…å«é‡è©¦æ©Ÿåˆ¶ï¼ˆå¢å¼·ç‰ˆï¼‰"""
        try:
            # é¦–å…ˆæª¢æŸ¥ç£ç¢Ÿç©ºé–“
            if not self._check_disk_space_with_alert(work_dir, db_name, min_gb=15.0):
                self.logger.error(f"{db_name} å› ç£ç¢Ÿç©ºé–“ä¸è¶³è€Œåœæ­¢")
                return None
            
            # ç¬¬ä¸€æ¬¡å˜—è©¦æ­£å¸¸ sync
            process = self.start_repo_sync_async(work_dir, db_name)
            if process:
                return process
            
            # å¦‚æœç¬¬ä¸€æ¬¡å¤±æ•—ï¼Œå˜—è©¦ä¿®å¾©å¾Œé‡æ–° sync
            print(f"âš ï¸  {db_name} åˆå§‹ sync å¤±æ•—ï¼Œå˜—è©¦ä¿®å¾©...")
            self.logger.warning(f"{db_name} åˆå§‹ sync å¤±æ•—ï¼Œå˜—è©¦ä¿®å¾©...")
            
            for retry in range(max_retries):
                print(f"ğŸ”„ {db_name} é‡è©¦ sync (ç¬¬ {retry + 1}/{max_retries} æ¬¡)")
                self.logger.info(f"{db_name} é‡è©¦ sync (ç¬¬ {retry + 1}/{max_retries} æ¬¡)")
                
                # å†æ¬¡æª¢æŸ¥ç£ç¢Ÿç©ºé–“
                if not self._check_disk_space_with_alert(work_dir, db_name, min_gb=10.0):
                    print(f"âŒ {db_name} é‡è©¦å¤±æ•—ï¼šç£ç¢Ÿç©ºé–“ä¸è¶³")
                    return None
                
                # å˜—è©¦ä¿®å¾©
                if self._repair_repo(work_dir, db_name):
                    # ä¿®å¾©æˆåŠŸå¾Œé‡æ–° sync
                    process = self.start_repo_sync_async(work_dir, db_name, force_sync=True)
                    if process:
                        print(f"âœ… {db_name} é‡è©¦æˆåŠŸï¼Œç¹¼çºŒåŒæ­¥...")
                        return process
                
                time.sleep(5 * (retry + 1))  # é€æ¼¸å¢åŠ å»¶é²
            
            print(f"âŒ {db_name} æ‰€æœ‰é‡è©¦éƒ½å¤±æ•—")
            self.logger.error(f"{db_name} æ‰€æœ‰é‡è©¦éƒ½å¤±æ•—")
            return None
            
        except Exception as e:
            print(f"âŒ {db_name} sync é‡è©¦æ©Ÿåˆ¶å¤±æ•—: {e}")
            self.logger.error(f"{db_name} sync é‡è©¦æ©Ÿåˆ¶å¤±æ•—: {e}")
            return None
    
    def check_process_status(self, db_name: str, process: subprocess.Popen) -> Optional[int]:
        """æª¢æŸ¥é€²ç¨‹ç‹€æ…‹ï¼ˆç·šç¨‹å®‰å…¨ï¼‰"""
        with self.lock:
            if process:
                poll = process.poll()
                if poll is not None:
                    # é€²ç¨‹å·²çµæŸï¼Œå¾è³‡æºç®¡ç†å™¨ç§»é™¤
                    resource_manager.unregister_process(db_name)
                return poll
        return None
    
    def export_manifest(self, work_dir: str, output_file: str = "vp_manifest.xml") -> bool:
        """å°å‡º manifest"""
        cmd = f"{config_manager.repo_config['repo_command']} manifest -r -o {output_file}"
        success, output = self.run_command(cmd, cwd=work_dir, timeout=60)
        
        if success:
            output_path = os.path.join(work_dir, output_file)
            if os.path.exists(output_path):
                self.logger.info(f"æˆåŠŸå°å‡º manifest: {output_path}")
                return True
            else:
                self.logger.error(f"å°å‡ºçš„ manifest æª”æ¡ˆä¸å­˜åœ¨")
                return False
        else:
            self.logger.error(f"å°å‡º manifest å¤±æ•—: {output}")
            return False
    
    def _check_disk_space_with_alert(self, path: str, db_name: str, min_gb: float = 10.0) -> bool:
        """æª¢æŸ¥ç£ç¢Ÿç©ºé–“ä¸¦åœ¨ console é¡¯ç¤ºè­¦å‘Š"""
        try:
            import shutil
            total, used, free = shutil.disk_usage(path)
            free_gb = free / (1024**3)
            total_gb = total / (1024**3)
            used_gb = used / (1024**3)
            
            self.logger.info(f"{db_name} ç£ç¢Ÿç©ºé–“æª¢æŸ¥:")
            self.logger.info(f"  ç¸½ç©ºé–“: {total_gb:.2f} GB")
            self.logger.info(f"  å·²ä½¿ç”¨: {used_gb:.2f} GB")
            self.logger.info(f"  å¯ç”¨ç©ºé–“: {free_gb:.2f} GB")
            
            if free_gb < min_gb:
                # åœ¨ console é¡¯ç¤ºé†’ç›®çš„è­¦å‘Š
                print("\n" + "ğŸš¨" * 50)
                print("âš ï¸  ç£ç¢Ÿç©ºé–“ä¸è¶³è­¦å‘Šï¼")
                print("ğŸš¨" * 50)
                print(f"ğŸ“ è·¯å¾‘: {path}")
                print(f"ğŸ’¾ å¯ç”¨ç©ºé–“: {free_gb:.2f} GB")
                print(f"ğŸ“‹ éœ€è¦ç©ºé–“: {min_gb} GB")
                print(f"âŒ ä¸è¶³: {min_gb - free_gb:.2f} GB")
                print()
                print("ğŸ’¡ å»ºè­°è§£æ±ºæ–¹æ¡ˆ:")
                print("   1. æ¸…ç†ä¸éœ€è¦çš„æª”æ¡ˆ")
                print("   2. ç§»å‹•å…¶ä»–å¤§æª”æ¡ˆåˆ°åˆ¥è™•")
                print("   3. ä½¿ç”¨ 'du -sh * | sort -hr' æŸ¥çœ‹å¤§æª”æ¡ˆ")
                print("   4. è€ƒæ…®ä½¿ç”¨å¤–æ¥ç¡¬ç¢Ÿæˆ–æ›´å¤§çš„ç£ç¢Ÿ")
                print("ğŸš¨" * 50)
                print()
                
                self.logger.error(f"{db_name} ç£ç¢Ÿç©ºé–“ä¸è¶³ï¼šéœ€è¦ {min_gb} GBï¼Œåªæœ‰ {free_gb:.2f} GB")
                return False
            
            # å¦‚æœç©ºé–“å……è¶³ä½†æ¥è¿‘è­¦å‘Šç·šï¼ˆ< 20GBï¼‰ï¼Œçµ¦äºˆæé†’
            elif free_gb < 20.0:
                print(f"âš ï¸  {db_name} ç£ç¢Ÿç©ºé–“è­¦å‘Šï¼šå‰©é¤˜ {free_gb:.2f} GB ï¼ˆå»ºè­°ä¿æŒ 20GB ä»¥ä¸Šï¼‰")
                self.logger.warning(f"{db_name} ç£ç¢Ÿç©ºé–“åä½: {free_gb:.2f} GB")
            
            return True
            
        except Exception as e:
            self.logger.warning(f"{db_name} æª¢æŸ¥ç£ç¢Ÿç©ºé–“å¤±æ•—: {e}")
            return True  # æª¢æŸ¥å¤±æ•—æ™‚å‡è¨­ç©ºé–“è¶³å¤  
    
    def _repair_repo(self, work_dir: str, db_name: str) -> bool:
        """å˜—è©¦ä¿®å¾©æå£çš„ repoï¼ˆå¢å¼·ç‰ˆï¼‰"""
        try:
            print(f"ğŸ”§ {db_name} é–‹å§‹ä¿®å¾© repo...")
            self.logger.info(f"{db_name} é–‹å§‹ä¿®å¾© repo...")
            
            # 1. å†æ¬¡æª¢æŸ¥ç£ç¢Ÿç©ºé–“
            if not self._check_disk_space_with_alert(work_dir, db_name, min_gb=5.0):
                return False
            
            # 2. æ¸…ç†å¯èƒ½æå£çš„æª”æ¡ˆ
            cleanup_paths = [
                os.path.join(work_dir, '.repo', 'project-objects'),
                os.path.join(work_dir, '.repo', 'projects'),
            ]
            
            for cleanup_path in cleanup_paths:
                if os.path.exists(cleanup_path):
                    print(f"ğŸ—‘ï¸  {db_name} æ¸…ç† {os.path.basename(cleanup_path)}...")
                    self.logger.info(f"{db_name} æ¸…ç† {cleanup_path}...")
                    import shutil
                    try:
                        shutil.rmtree(cleanup_path)
                        print(f"âœ… {db_name} {os.path.basename(cleanup_path)} æ¸…ç†å®Œæˆ")
                    except Exception as e:
                        print(f"âš ï¸  {db_name} æ¸…ç† {os.path.basename(cleanup_path)} å¤±æ•—: {e}")
                        self.logger.warning(f"{db_name} æ¸…ç† {cleanup_path} å¤±æ•—: {e}")
            
            # 3. åŸ·è¡Œ repo forall æ¸…ç†
            print(f"ğŸ§¹ {db_name} åŸ·è¡Œ Git æ¸…ç†...")
            cleanup_cmd = "repo forall -c 'git reset --hard HEAD; git clean -fd' 2>/dev/null || true"
            self.logger.info(f"{db_name} åŸ·è¡Œæ¸…ç†å‘½ä»¤...")
            
            result = subprocess.run(
                cleanup_cmd,
                shell=True,
                cwd=work_dir,
                capture_output=True,
                text=True,
                timeout=300  # 5åˆ†é˜è¶…æ™‚
            )
            
            if result.returncode == 0:
                print(f"âœ… {db_name} repo æ¸…ç†æˆåŠŸ")
                self.logger.info(f"{db_name} repo æ¸…ç†æˆåŠŸ")
                return True
            else:
                print(f"âš ï¸  {db_name} repo æ¸…ç†æœ‰è­¦å‘Šï¼Œä½†ç¹¼çºŒå˜—è©¦")
                self.logger.warning(f"{db_name} repo æ¸…ç†è­¦å‘Š: {result.stderr}")
                return True  # å³ä½¿æœ‰è­¦å‘Šä¹Ÿç¹¼çºŒ
                
        except subprocess.TimeoutExpired:
            print(f"âŒ {db_name} repo æ¸…ç†è¶…æ™‚")
            self.logger.error(f"{db_name} repo æ¸…ç†è¶…æ™‚")
            return False
        except Exception as e:
            print(f"âŒ {db_name} repo ä¿®å¾©å¤±æ•—: {e}")
            self.logger.error(f"{db_name} repo ä¿®å¾©å¤±æ•—: {e}")
            return False

# =====================================
# ===== ä¸»è¦è™•ç†é¡åˆ¥ï¼ˆæ”¹å–„ç‰ˆï¼‰ =====
# =====================================

class ManifestPinningTool:
    """Manifest å®šç‰ˆå·¥å…·ï¼ˆæ”¹å–„ç‰ˆï¼‰"""

    def __init__(self):
        self.logger = setup_logger(self.__class__.__name__)
        self.sftp_manager = ThreadSafeSFTPManager()
        self.repo_manager = RepoManager()
        self.mapping_reader = MappingTableReader()
        self.progress_manager = ProgressManager()  # ç¢ºä¿é€™è¡Œå­˜åœ¨
        self.source_cmd_manager = SourceCommandManager()
        self.report = PinningReport()
        self.output_dir = config_manager.path_config['default_output_dir']
        self.dry_run = False

    def process_db_phase1(self, db_info: DBInfo) -> DBInfo:
        """è™•ç† DB çš„ç¬¬ä¸€éšæ®µï¼šæº–å‚™å·¥ä½œï¼ˆè©³ç´°é€²åº¦ç‰ˆï¼‰"""
        db_info.start_time = datetime.now()
        
        try:
            # è¨­ç½® SFTP ç®¡ç†å™¨çš„é€²åº¦å›èª¿
            def progress_callback(db_name, status, message):
                if hasattr(DBStatus, status):
                    status_enum = getattr(DBStatus, status)
                    self.progress_manager.update_status(db_name, status_enum, message)
            
            self.sftp_manager.set_progress_callback(progress_callback)
            
            # åˆå§‹ç‹€æ…‹é¡¯ç¤º SFTP è·¯å¾‘
            self.progress_manager.update_status(
                db_info.db_info, 
                DBStatus.DOWNLOADING_MANIFEST,
                f"ğŸ” æº–å‚™æœå°‹: {os.path.basename(db_info.sftp_path)}"
            )
            
            # å»ºç«‹æœ¬åœ°ç›®éŒ„
            local_path = os.path.join(self.output_dir, db_info.module, db_info.db_info)
            os.makedirs(local_path, exist_ok=True)
            db_info.local_path = local_path
            
            # Step 1: å¾ SFTP å°‹æ‰¾ä¸¦ä¸‹è¼‰ manifest
            start_search = time.time()
            
            if db_info.version:
                self.progress_manager.update_status(
                    db_info.db_info,
                    DBStatus.DOWNLOADING_MANIFEST,
                    f"ğŸ¯ å°‹æ‰¾æŒ‡å®šç‰ˆæœ¬ {db_info.version}"
                )
                result = self.sftp_manager.find_specific_manifest(db_info.sftp_path, db_info.version)
            else:
                result = self.sftp_manager.find_latest_manifest(db_info.sftp_path, db_info.db_info)
            
            search_time = time.time() - start_search
            
            if not result:
                raise Exception(f"åœ¨ {db_info.sftp_path} æ‰¾ä¸åˆ° manifest æª”æ¡ˆ (æœå°‹æ™‚é–“: {search_time:.1f}s)")
            
            manifest_full_path, manifest_name = result
            db_info.manifest_full_path = manifest_full_path
            db_info.manifest_file = manifest_name
            
            # æå–ç‰ˆæœ¬è™Ÿ
            match = re.match(config_manager.path_config['manifest_pattern'], manifest_name)
            if match:
                db_info.version = match.group(1)
            
            # ä¸‹è¼‰ manifest åˆ°æœ¬åœ°
            local_manifest = os.path.join(local_path, manifest_name)
            
            if not self.sftp_manager.download_file_with_progress(
                manifest_full_path, 
                local_manifest, 
                db_info.db_info
            ):
                raise Exception(f"ä¸‹è¼‰ manifest å¤±æ•—: {manifest_full_path}")
            
            download_time = time.time() - start_search
            file_size = os.path.getsize(local_manifest) if os.path.exists(local_manifest) else 0
            
            # ä¸‹è¼‰å®Œæˆå¾Œæ›´æ–°ç‹€æ…‹
            self.progress_manager.update_status(
                db_info.db_info,
                DBStatus.DOWNLOADING_MANIFEST,
                f"âœ… {manifest_name} (v{db_info.version or 'æœ€æ–°'}, {file_size//1024} KB, {download_time:.1f}s)"
            )
            
            # Step 2: æª¢æŸ¥æ˜¯å¦å·²æœ‰ .repo
            self.progress_manager.update_status(
                db_info.db_info,
                DBStatus.CHECKING_REPO,
                f"ğŸ” æª¢æŸ¥ {local_path}/.repo"
            )
            
            db_info.has_existing_repo = self.repo_manager.check_repo_exists(local_path)
            
            if db_info.has_existing_repo:
                self.progress_manager.update_status(
                    db_info.db_info,
                    DBStatus.CHECKING_REPO,
                    f"âœ… æ‰¾åˆ°ç¾æœ‰ .repo ç›®éŒ„"
                )
            else:
                self.progress_manager.update_status(
                    db_info.db_info,
                    DBStatus.CHECKING_REPO,
                    f"ğŸ“ éœ€è¦åˆå§‹åŒ–æ–°çš„ repo"
                )
            
            # Step 3: è™•ç† repo initï¼ˆæ”¹å–„ç‰ˆï¼‰
            if not db_info.has_existing_repo:
                self.progress_manager.update_status(
                    db_info.db_info,
                    DBStatus.REPO_INIT,
                    f"ğŸ” ç²å– source command from JIRA..."
                )
                
                # ç²å– source commandï¼ˆä½¿ç”¨æ”¹å–„çš„ç®¡ç†å™¨ï¼‰
                start_jira = time.time()
                source_cmd = self.source_cmd_manager.get_source_command(
                    db_info, 
                    self.mapping_reader.df
                )
                jira_time = time.time() - start_jira
                
                if not source_cmd:
                    raise Exception(f"ç„¡æ³•å–å¾— source command (JIRA æŸ¥è©¢æ™‚é–“: {jira_time:.1f}s)")
                
                db_info.actual_source_cmd = source_cmd
                
                # é¡¯ç¤ºå°‡è¦åŸ·è¡Œçš„å‘½ä»¤
                cmd_display = source_cmd[:80] + "..." if len(source_cmd) > 80 else source_cmd
                self.progress_manager.update_status(
                    db_info.db_info,
                    DBStatus.REPO_INIT,
                    f"âš™ï¸ åˆå§‹åŒ– repo: {cmd_display}"
                )
                
                # åŸ·è¡Œåˆå§‹ repo init
                start_init = time.time()
                if not self.repo_manager.repo_init(local_path, source_cmd):
                    raise Exception("Repo init å¤±æ•—")
                init_time = time.time() - start_init
                
                # æ‡‰ç”¨ manifestï¼ˆä¸é‡è¤‡ initï¼‰
                self.progress_manager.update_status(
                    db_info.db_info,
                    DBStatus.REPO_INIT,
                    f"ğŸ“„ å¥—ç”¨ {manifest_name} (init: {init_time:.1f}s)"
                )
                
                start_apply = time.time()
                if not self.repo_manager.apply_manifest(local_path, local_manifest):
                    raise Exception("å¥—ç”¨ manifest å¤±æ•—")
                apply_time = time.time() - start_apply
                
                self.progress_manager.update_status(
                    db_info.db_info,
                    DBStatus.REPO_INIT,
                    f"âœ… Repo åˆå§‹åŒ–å®Œæˆ (å¥—ç”¨: {apply_time:.1f}s)"
                )
                
            else:
                # å¦‚æœå·²æœ‰ .repoï¼Œåªéœ€åˆ‡æ› manifest
                self.progress_manager.update_status(
                    db_info.db_info,
                    DBStatus.REPO_INIT,
                    f"ğŸ”„ åˆ‡æ›åˆ° {manifest_name}"
                )
                
                start_apply = time.time()
                if not self.repo_manager.apply_manifest(local_path, local_manifest):
                    raise Exception("åˆ‡æ› manifest å¤±æ•—")
                apply_time = time.time() - start_apply
                
                self.progress_manager.update_status(
                    db_info.db_info,
                    DBStatus.REPO_INIT,
                    f"âœ… Manifest åˆ‡æ›å®Œæˆ ({apply_time:.1f}s)"
                )
                
            # Step 4: å•Ÿå‹•ç•°æ­¥ repo syncï¼ˆä½¿ç”¨å¢å¼·çš„é‡è©¦æ©Ÿåˆ¶ï¼‰
            if not self.dry_run:
                self.progress_manager.update_status(
                    db_info.db_info,
                    DBStatus.REPO_SYNC,
                    f"ğŸš€ æª¢æŸ¥ç£ç¢Ÿç©ºé–“ä¸¦æº–å‚™åŒæ­¥..."
                )
                
                start_sync_init = time.time()
                
                # ä½¿ç”¨å¢å¼·çš„ sync æ–¹æ³•ï¼ˆåŒ…å«ç£ç¢Ÿç©ºé–“æª¢æŸ¥ï¼‰
                process = self.repo_manager.start_repo_sync_async_with_retry(
                    local_path, 
                    db_info.db_info,
                    max_retries=2
                )
                
                if not process:
                    # æª¢æŸ¥æ˜¯å¦ç‚ºç£ç¢Ÿç©ºé–“å•é¡Œ
                    if not self.repo_manager._check_disk_space_with_alert(local_path, db_info.db_info, 5.0):
                        raise Exception("âŒ ç£ç¢Ÿç©ºé–“ä¸è¶³ï¼è«‹æ¸…ç†ç©ºé–“å¾Œé‡è©¦")
                    else:
                        raise Exception("å•Ÿå‹• repo sync å¤±æ•—ï¼ˆåŒ…å«é‡è©¦ï¼‰")
                
                sync_init_time = time.time() - start_sync_init
                db_info.sync_process = process
                
                # è¨˜éŒ„ sync æ—¥èªŒè·¯å¾‘
                log_dir = os.path.join(local_path, 'logs')
                if os.path.exists(log_dir):
                    log_files = sorted([f for f in os.listdir(log_dir) if f.startswith('repo_sync_')])
                    if log_files:
                        db_info.sync_log_path = os.path.join(log_dir, log_files[-1])
                
                # æ›´æ–°ç‹€æ…‹é¡¯ç¤º sync é€²è¡Œä¸­
                self.progress_manager.update_status(
                    db_info.db_info,
                    DBStatus.REPO_SYNC,
                    f"ğŸ”„ åŒæ­¥ä¸­... (PID: {process.pid})"
                )
            else:
                self.logger.info(f"[Dry Run] è·³é repo sync for {db_info.db_info}")
                db_info.status = DBStatus.SKIPPED
                self.progress_manager.update_status(
                    db_info.db_info,
                    DBStatus.SKIPPED,
                    f"ğŸ§ª æ¸¬è©¦æ¨¡å¼ - å·²è·³é sync"
                )
            
            total_time = time.time() - db_info.start_time.timestamp()
            self.logger.info(f"âœ… {db_info.db_info} ç¬¬ä¸€éšæ®µå®Œæˆï¼Œç¸½æ™‚é–“: {total_time:.1f}s")
            
        except Exception as e:
            total_time = time.time() - db_info.start_time.timestamp() if db_info.start_time else 0
            db_info.status = DBStatus.FAILED
            db_info.error_message = str(e)
            
            # å¦‚æœæ˜¯ç£ç¢Ÿç©ºé–“éŒ¯èª¤ï¼Œåœ¨ç‹€æ…‹ä¸­ç‰¹åˆ¥æ¨™è¨˜
            if "ç£ç¢Ÿç©ºé–“" in str(e) or "disk" in str(e).lower():
                status_msg = f"ğŸ’¾ {str(e)}"
            else:
                status_msg = f"âŒ {str(e)}"
            
            self.progress_manager.update_status(
                db_info.db_info,
                DBStatus.FAILED,
                f"{status_msg} (ç¸½æ™‚é–“: {total_time:.1f}s)"
            )
            self.logger.error(f"âŒ {db_info.db_info} è™•ç†å¤±æ•—: {str(e)}")
        
        return db_info  

    def find_specific_manifest(self, base_path: str, version: str) -> Optional[Tuple[str, str]]:
        """å°‹æ‰¾ç‰¹å®šç‰ˆæœ¬çš„ manifest æ–‡ä»¶"""
        try:
            sftp, client = self._get_connection()
            if not sftp:
                raise Exception("ç„¡æ³•å»ºç«‹ SFTP é€£ç·š")
            
            self.logger.info(f"å°‹æ‰¾ç‰ˆæœ¬ {version} çš„ manifest: {base_path}")
            
            # å˜—è©¦ç›´æ¥åœ¨ç‰ˆæœ¬ç›®éŒ„ä¸­å°‹æ‰¾
            version_patterns = [
                version,
                f"v{version}",
                f"version_{version}",
                f"ver{version}"
            ]
            
            items = sftp.listdir_attr(base_path)
            
            for pattern in version_patterns:
                version_path = f"{base_path}/{pattern}"
                
                try:
                    # æª¢æŸ¥ç‰ˆæœ¬ç›®éŒ„æ˜¯å¦å­˜åœ¨
                    version_files = sftp.listdir(version_path)
                    
                    # åœ¨ç‰ˆæœ¬ç›®éŒ„ä¸­å°‹æ‰¾ manifest
                    for filename in version_files:
                        if filename.endswith('.xml') and 'manifest' in filename.lower():
                            full_path = f"{version_path}/{filename}"
                            
                            # æª¢æŸ¥æ–‡ä»¶å¤§å°
                            file_stat = sftp.stat(full_path)
                            if file_stat.st_size > 100000:  # å¤§æ–¼ 100KB
                                self.logger.info(f"æ‰¾åˆ°æŒ‡å®šç‰ˆæœ¬çš„ manifest: {filename}")
                                return full_path, filename
                
                except Exception as e:
                    self.logger.debug(f"æª¢æŸ¥ç‰ˆæœ¬ç›®éŒ„å¤±æ•—: {pattern}, {e}")
                    continue
            
            raise Exception(f"æœªæ‰¾åˆ°ç‰ˆæœ¬ {version} çš„ manifest")
            
        except Exception as e:
            self.logger.error(f"å°‹æ‰¾ç‰¹å®šç‰ˆæœ¬ manifest å¤±æ•—: {e}")
            return None
        
    def process_db_phase2(self, db_info: DBInfo) -> DBInfo:
        """
        è™•ç† DB çš„ç¬¬äºŒéšæ®µï¼šå®Œæˆå·¥ä½œï¼ˆæ”¹å–„ç‰ˆï¼‰
        """
        try:
            if self.dry_run:
                db_info.status = DBStatus.SKIPPED
                db_info.end_time = datetime.now()
                return db_info
            
            # æª¢æŸ¥ sync é€²ç¨‹ç‹€æ…‹ï¼ˆç·šç¨‹å®‰å…¨ï¼‰
            if db_info.sync_process:
                poll = self.repo_manager.check_process_status(
                    db_info.db_info, 
                    db_info.sync_process
                )
                
                if poll is None:
                    # é‚„åœ¨åŸ·è¡Œä¸­
                    return db_info
                elif poll != 0:
                    # sync å¤±æ•—ï¼Œå˜—è©¦è®€å–éŒ¯èª¤æ—¥èªŒ
                    error_msg = f"Repo sync å¤±æ•— (è¿”å›ç¢¼: {poll})"
                    if db_info.sync_log_path and os.path.exists(db_info.sync_log_path):
                        try:
                            with open(db_info.sync_log_path, 'r', encoding='utf-8', errors='ignore') as f:
                                lines = f.readlines()
                                # å–æœ€å¾Œ 10 è¡Œä½œç‚ºéŒ¯èª¤è¨Šæ¯
                                last_lines = lines[-10:] if len(lines) > 10 else lines
                                error_detail = ''.join(last_lines)
                                error_msg += f"\næœ€å¾Œæ—¥èªŒ:\n{error_detail}"
                        except:
                            pass
                    raise Exception(error_msg)
            
            # å°å‡º manifest
            self.progress_manager.update_status(
                db_info.db_info,
                DBStatus.EXPORTING,
                "å°å‡ºç‰ˆæœ¬è³‡è¨Š"
            )
            
            if not self.repo_manager.export_manifest(db_info.local_path):
                raise Exception("å°å‡º manifest å¤±æ•—")
            
            # å®Œæˆ
            db_info.status = DBStatus.SUCCESS
            db_info.end_time = datetime.now()
            
            self.progress_manager.update_status(
                db_info.db_info,
                DBStatus.SUCCESS,
                f"ç‰ˆæœ¬ {db_info.version}"
            )
            
            self.logger.info(f"âœ… {db_info.db_info} å®šç‰ˆå®Œæˆ")
            
        except Exception as e:
            db_info.status = DBStatus.FAILED
            db_info.error_message = str(e)
            db_info.end_time = datetime.now()
            
            self.progress_manager.update_status(
                db_info.db_info,
                DBStatus.FAILED,
                str(e)
            )
            
            self.logger.error(f"âŒ {db_info.db_info} ç¬¬äºŒéšæ®µå¤±æ•—: {str(e)}")
        
        return db_info

    def process_dbs_async(self, db_list: List[str], db_versions: Dict[str, str] = None):
        """ç•°æ­¥è™•ç†å¤šå€‹ DBï¼ˆå®Œæ•´ç‰ˆ - åŒ…å«è©³ç´°é€²åº¦ç›£æ§ï¼‰"""
        db_versions = db_versions or {}
        db_infos = []
        
        # æº–å‚™ DB è³‡è¨Š
        all_db_infos = self.get_all_dbs('all')
        
        for db_name in db_list:
            # è§£æç‰ˆæœ¬
            if '#' in db_name:
                db_name, version = db_name.split('#', 1)
            else:
                version = db_versions.get(db_name)
            
            # æ‰¾åˆ°å°æ‡‰çš„ DB è³‡è¨Š
            for db_info in all_db_infos:
                if db_info.db_info == db_name:
                    db_info.version = version
                    db_infos.append(db_info)
                    self.progress_manager.init_db(db_name, db_info)  # å‚³é db_info
                    break
        
        if not db_infos:
            self.logger.error("æ²’æœ‰æ‰¾åˆ°è¦è™•ç†çš„ DB")
            return

        self.logger.info(f"é–‹å§‹ç•°æ­¥è™•ç† {len(db_infos)} å€‹ DB")
        
        # å»ºç«‹é€²åº¦é¡¯ç¤ºåŸ·è¡Œç·’
        stop_progress = threading.Event()
        
        def display_progress_thread():
            while not stop_progress.is_set():
                try:
                    self.progress_manager.display_progress()
                    time.sleep(config_manager.path_config['progress_update_interval'])
                except Exception as e:
                    self.logger.debug(f"é€²åº¦é¡¯ç¤ºéŒ¯èª¤: {e}")

        # å»ºç«‹ sync é€²åº¦ç›£æ§åŸ·è¡Œç·’
        def sync_monitor_thread():
            self.logger.info("å•Ÿå‹• sync é€²åº¦ç›£æ§ç·šç¨‹")
            while not stop_progress.is_set():
                try:
                    for db_info in db_infos:
                        # æª¢æŸ¥æ˜¯å¦æœ‰ sync æ—¥èªŒæª”æ¡ˆä¸”æ­£åœ¨ sync
                        current_status = self.progress_manager.db_status.get(db_info.db_info, (None, ""))[0]
                        
                        if (current_status == DBStatus.REPO_SYNC and 
                            db_info.sync_log_path and 
                            os.path.exists(db_info.sync_log_path)):
                            
                            # æª¢æŸ¥æ—¥èªŒæª”æ¡ˆæ˜¯å¦æœ‰æ–°å…§å®¹
                            try:
                                file_size = os.path.getsize(db_info.sync_log_path)
                                if file_size > 0:
                                    self.progress_manager.update_sync_progress(
                                        db_info.db_info, 
                                        db_info.sync_log_path
                                    )
                            except Exception as e:
                                self.logger.debug(f"æª¢æŸ¥æ—¥èªŒæª”æ¡ˆ {db_info.sync_log_path} å¤±æ•—: {e}")
                    
                    time.sleep(3)  # æ¯ 3 ç§’æ›´æ–°ä¸€æ¬¡ sync é€²åº¦
                except Exception as e:
                    self.logger.debug(f"Sync ç›£æ§éŒ¯èª¤: {e}")
                    time.sleep(3)
        
        progress_thread = threading.Thread(target=display_progress_thread, daemon=True)
        sync_monitor_thread_obj = threading.Thread(target=sync_monitor_thread, daemon=True)
        
        progress_thread.start()
        sync_monitor_thread_obj.start()
        
        try:
            # Phase 1: æº–å‚™å’Œå•Ÿå‹• sync
            with ThreadPoolExecutor(
                max_workers=config_manager.parallel_config['max_workers']
            ) as executor:
                futures = {
                    executor.submit(self.process_db_phase1, db_info): db_info 
                    for db_info in db_infos
                }
                
                phase1_results = []
                for future in as_completed(futures):
                    try:
                        result = future.result(timeout=300)
                        phase1_results.append(result)
                        
                        # ç¢ºä¿ progress_manager æœ‰æœ€æ–°çš„ db_info
                        self.progress_manager.db_info_cache[result.db_info] = result
                        
                    except Exception as e:
                        db_info = futures[future]
                        self.logger.error(f"Phase 1 ç•°å¸¸ ({db_info.db_info}): {str(e)}")
                        db_info.status = DBStatus.FAILED
                        db_info.error_message = str(e)
                        phase1_results.append(db_info)
            
            # ç­‰å¾…æ‰€æœ‰ sync å®Œæˆ
            self.logger.info("ç­‰å¾…æ‰€æœ‰ repo sync å®Œæˆ...")
            
            max_wait_time = config_manager.repo_config['sync_timeout']
            start_wait = time.time()
            
            while True:
                all_complete = True
                
                for db_info in phase1_results:
                    if db_info.status == DBStatus.FAILED:
                        continue
                    
                    if db_info.sync_process:
                        poll = self.repo_manager.check_process_status(
                            db_info.db_info,
                            db_info.sync_process
                        )
                        if poll is None:
                            # é‚„åœ¨åŸ·è¡Œ
                            all_complete = False
                            
                            # æª¢æŸ¥æ˜¯å¦è¶…æ™‚
                            elapsed = time.time() - start_wait
                            if elapsed > max_wait_time:
                                self.logger.warning(f"{db_info.db_info} sync è¶…æ™‚ï¼Œå¼·åˆ¶çµ‚æ­¢")
                                try:
                                    db_info.sync_process.terminate()
                                    db_info.sync_process.wait(timeout=5)
                                except:
                                    db_info.sync_process.kill()
                                db_info.status = DBStatus.FAILED
                                db_info.error_message = "Sync è¶…æ™‚"
                                self.progress_manager.update_status(
                                    db_info.db_info,
                                    DBStatus.FAILED,
                                    "âŒ Sync è¶…æ™‚"
                                )
                        elif poll == 0:
                            # æˆåŠŸå®Œæˆ
                            self.progress_manager.update_status(
                                db_info.db_info,
                                DBStatus.REPO_SYNC,
                                "âœ… åŒæ­¥å®Œæˆï¼Œæº–å‚™å°å‡º"
                            )
                        else:
                            # å¤±æ•—
                            db_info.status = DBStatus.FAILED
                            db_info.error_message = f"Sync å¤±æ•— (è¿”å›ç¢¼: {poll})"
                            self.progress_manager.update_status(
                                db_info.db_info,
                                DBStatus.FAILED,
                                f"âŒ Sync å¤±æ•— (è¿”å›ç¢¼: {poll})"
                            )
                
                if all_complete or (time.time() - start_wait) > max_wait_time:
                    break
                
                time.sleep(5)
            
            # Phase 2: å®Œæˆè™•ç†
            self.logger.info("åŸ·è¡Œç¬¬äºŒéšæ®µè™•ç†...")
            
            with ThreadPoolExecutor(
                max_workers=config_manager.parallel_config['max_workers']
            ) as executor:
                futures = {
                    executor.submit(self.process_db_phase2, db_info): db_info 
                    for db_info in phase1_results
                }
                
                for future in as_completed(futures):
                    try:
                        result = future.result(timeout=60)
                        self.report.add_db(result)
                    except Exception as e:
                        db_info = futures[future]
                        self.logger.error(f"Phase 2 ç•°å¸¸ ({db_info.db_info}): {str(e)}")
                        db_info.status = DBStatus.FAILED
                        db_info.error_message = str(e)
                        self.report.add_db(db_info)
            
        finally:
            # åœæ­¢é€²åº¦é¡¯ç¤º
            stop_progress.set()
            progress_thread.join(timeout=2)
            sync_monitor_thread_obj.join(timeout=2)
            
            # é¡¯ç¤ºæœ€çµ‚çµæœ
            self.progress_manager.display_progress(clear_screen=False)

    def load_mapping_table(self, file_path: str) -> bool:
        """è¼‰å…¥ mapping table"""
        return self.mapping_reader.load_excel(file_path)

    def get_all_dbs(self, db_type: str = 'all') -> List[DBInfo]:
        """å–å¾—æ‰€æœ‰ DB è³‡è¨Š"""
        return self.mapping_reader.get_db_info_list(db_type)

    def process_selected_dbs(self, db_list: List[str], db_versions: Dict[str, str] = None):
        """è™•ç†é¸å®šçš„ DB"""
        if config_manager.repo_config['async_sync'] and not self.dry_run:
            self.process_dbs_async(db_list, db_versions)
        else:
            # åŒæ­¥è™•ç†æˆ– dry run æ¨¡å¼
            self.logger.info("ä½¿ç”¨åŒæ­¥è™•ç†æ¨¡å¼")
            for db_name in db_list:
                if '#' in db_name:
                    db_name, version = db_name.split('#', 1)
                else:
                    version = db_versions.get(db_name) if db_versions else None
                
                # æ‰¾åˆ°å°æ‡‰çš„ DB è³‡è¨Š
                for db_info in self.get_all_dbs('all'):
                    if db_info.db_info == db_name:
                        db_info.version = version
                        self.progress_manager.init_db(db_name)
                        
                        # Phase 1
                        db_info = self.process_db_phase1(db_info)
                        
                        if not self.dry_run and db_info.sync_process:
                            # ç­‰å¾… sync å®Œæˆ
                            self.logger.info(f"ç­‰å¾… {db_name} sync å®Œæˆ...")
                            db_info.sync_process.wait()
                        
                        # Phase 2
                        db_info = self.process_db_phase2(db_info)
                        self.report.add_db(db_info)
                        break

    def generate_report(self, output_file: str = None):
        """ç”¢ç”Ÿå ±å‘Šï¼ˆå¢å¼·ç‰ˆï¼‰"""
        self.report.finalize()
        
        if not output_file:
            output_file = os.path.join(
                self.output_dir, 
                config_manager.path_config['report_filename']
            )
        
        try:
            report_data = []
            for db in self.report.db_details:
                db_dict = db.to_dict()
                # ç¢ºä¿åŒ…å«æ‰€æœ‰é‡è¦è³‡è¨Š
                db_dict['source_command'] = db.actual_source_cmd or 'æœªè¨˜éŒ„'
                db_dict['manifest_version'] = db.version or 'æœªæŒ‡å®š'
                db_dict['manifest_file'] = db.manifest_file or 'æœªä¸‹è¼‰'
                report_data.append(db_dict)
            
            df = pd.DataFrame(report_data)
            
            # å»ºç«‹æ‘˜è¦
            summary = {
                'é …ç›®': ['ç¸½ DB æ•¸', 'æˆåŠŸ', 'å¤±æ•—', 'è·³é', 'åŸ·è¡Œæ™‚é–“'],
                'æ•¸å€¼': [
                    self.report.total_dbs,
                    self.report.successful_dbs,
                    self.report.failed_dbs,
                    self.report.skipped_dbs,
                    str(self.report.end_time - self.report.start_time) if self.report.end_time else 'N/A'
                ]
            }
            summary_df = pd.DataFrame(summary)
            
            # å¯«å…¥ Excelï¼ŒåŒ…å«æ›´å¤šè³‡è¨Š
            with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
                summary_df.to_excel(writer, sheet_name='æ‘˜è¦', index=False)
                df.to_excel(writer, sheet_name='è©³ç´°è³‡è¨Š', index=False)
                
                # æ–°å¢è™•ç†è¨˜éŒ„è¡¨
                process_log = []
                for db in self.report.db_details:
                    process_log.append({
                        'DBåç¨±': db.db_info,
                        'æ¨¡çµ„': db.module,
                        'é¡å‹': db.db_type,
                        'Source Command': db.actual_source_cmd or 'æœªè¨˜éŒ„',
                        'Manifestç‰ˆæœ¬': db.version or 'æœ€æ–°',
                        'Manifestæª”æ¡ˆ': db.manifest_file or 'æœªä¸‹è¼‰',
                        'ç‹€æ…‹': db.status.value if isinstance(db.status, DBStatus) else db.status,
                        'é–‹å§‹æ™‚é–“': db.start_time.strftime('%Y-%m-%d %H:%M:%S') if db.start_time else '',
                        'çµæŸæ™‚é–“': db.end_time.strftime('%Y-%m-%d %H:%M:%S') if db.end_time else '',
                        'éŒ¯èª¤è¨Šæ¯': db.error_message or ''
                    })
                
                process_df = pd.DataFrame(process_log)
                process_df.to_excel(writer, sheet_name='è™•ç†è¨˜éŒ„', index=False)
            
            self.logger.info(f"å ±å‘Šå·²ç”¢ç”Ÿ: {output_file}")
            
        except Exception as e:
            self.logger.error(f"ç”¢ç”Ÿå ±å‘Šå¤±æ•—: {str(e)}")

# =====================================
# ===== äº’å‹•å¼ä»‹é¢ï¼ˆæ”¹å–„ç‰ˆï¼‰ =====
# =====================================

class InteractiveUI:
    """äº’å‹•å¼ä½¿ç”¨è€…ä»‹é¢ï¼ˆæ”¹å–„ç‰ˆï¼‰"""
    
    def __init__(self):
        self.tool = ManifestPinningTool()
        self.logger = setup_logger(self.__class__.__name__)
        self.selected_dbs = []
        self.db_versions = {}
        self.selected_db_type = 'all'
        
        # è¼‰å…¥é è¨­é…ç½®
        self._load_default_config()
    
    def _load_default_config(self):
        """è¼‰å…¥é è¨­é…ç½®"""
        # å¦‚æœæœ‰é è¨­çš„ SFTP è¨­å®šï¼Œè¦†è“‹å…¨åŸŸè¨­å®š
        if config_manager.default_execution_config.get('sftp_override'):
            config_manager.apply_overrides(
                config_manager.default_execution_config['sftp_override'],
                source='default_config'
            )
        
        # å¦‚æœæœ‰é è¨­çš„è¼¸å‡ºç›®éŒ„
        if config_manager.default_execution_config.get('output_dir'):
            self.tool.output_dir = config_manager.default_execution_config['output_dir']
    
    def setup_sftp(self):
        """è¨­å®š SFTP é€£ç·šè³‡è¨Š"""
        print("\nç›®å‰ SFTP è¨­å®š:")
        print(f"  Host: {config_manager.sftp_config['host']}")
        print(f"  Port: {config_manager.sftp_config['port']}")
        print(f"  Username: {config_manager.sftp_config['username']}")
        
        if input("\næ˜¯å¦è¦ä¿®æ”¹è¨­å®š? (y/N): ").strip().lower() == 'y':
            host = input(f"Host [{config_manager.sftp_config['host']}]: ").strip()
            if host:
                config_manager.sftp_config['host'] = host
                
            port = input(f"Port [{config_manager.sftp_config['port']}]: ").strip()
            if port:
                config_manager.sftp_config['port'] = int(port)
                
            username = input(f"Username [{config_manager.sftp_config['username']}]: ").strip()
            if username:
                config_manager.sftp_config['username'] = username
                
            password = input("Password (ç•™ç©ºä¿æŒåŸå€¼): ").strip()
            if password:
                config_manager.sftp_config['password'] = password
            
            print("âœ… SFTP è¨­å®šå·²æ›´æ–°")
            
            # é‡æ–°å»ºç«‹ SFTP ç®¡ç†å™¨
            self.tool.sftp_manager = ThreadSafeSFTPManager()
    
    def display_current_settings(self):
        """é¡¯ç¤ºç›®å‰è¨­å®š"""
        print("\nç›®å‰è¨­å®š:")
        print(f"  Mapping table: {'å·²è¼‰å…¥' if self.tool.mapping_reader.df is not None else 'æœªè¼‰å…¥'}")
        print(f"  DB é¡å‹: {self.selected_db_type}")
        print(f"  é¸æ“‡çš„ DB: {len(self.selected_dbs)} å€‹")
        print(f"  è¨­å®šç‰ˆæœ¬çš„ DB: {len(self.db_versions)} å€‹")
        print(f"  è¼¸å‡ºç›®éŒ„: {self.tool.output_dir}")
        print(f"  å¹³è¡Œè™•ç†: {'å•Ÿç”¨' if config_manager.parallel_config['enable_parallel'] else 'é—œé–‰'}")
        print(f"  Worker æ•¸é‡: {config_manager.parallel_config['max_workers']}")
    
    def load_mapping_table(self):
        """è¼‰å…¥ mapping tableï¼ˆæ”¯æ´é è¨­å€¼ï¼‰"""
        default_mapping = config_manager.default_execution_config.get('mapping_table')
        
        if default_mapping and os.path.exists(default_mapping):
            print(f"\nğŸ“Œ æ‰¾åˆ°é è¨­ mapping table: {default_mapping}")
            if input("æ˜¯å¦ä½¿ç”¨é è¨­æª”æ¡ˆ? (Y/n): ").strip().lower() != 'n':
                file_path = default_mapping
            else:
                file_path = input(
                    f"è«‹è¼¸å…¥ mapping table è·¯å¾‘ [{config_manager.path_config['default_mapping_table']}]: "
                ).strip()
                if not file_path:
                    file_path = config_manager.path_config['default_mapping_table']
        else:
            default_path = config_manager.path_config['default_mapping_table']
            file_path = input(f"è«‹è¼¸å…¥ mapping table è·¯å¾‘ [{default_path}]: ").strip()
            if not file_path:
                file_path = default_path
        
        if not os.path.exists(file_path):
            print(f"âŒ æª”æ¡ˆä¸å­˜åœ¨: {file_path}")
            return
        
        if self.tool.load_mapping_table(file_path):
            print(f"âœ… æˆåŠŸè¼‰å…¥ mapping tableï¼Œå…± {len(self.tool.mapping_reader.df)} ç­†è³‡æ–™")
            all_dbs = self.tool.get_all_dbs()
            unique_db_names = list(set([db.db_info for db in all_dbs]))
            print(f"   æ‰¾åˆ° {len(unique_db_names)} å€‹ä¸é‡è¤‡çš„ DB")
            
            # å¦‚æœæœ‰é è¨­çš„ DB é¡å‹ï¼Œè‡ªå‹•è¨­å®š
            if config_manager.default_execution_config.get('db_type'):
                self.selected_db_type = config_manager.default_execution_config['db_type']
                print(f"   ğŸ“Œ ä½¿ç”¨é è¨­ DB é¡å‹: {self.selected_db_type}")
        else:
            print("âŒ è¼‰å…¥å¤±æ•—")
    
    def select_db_type(self):
        """é¸æ“‡ DB é¡å‹ï¼ˆæ”¯æ´é è¨­å€¼ï¼‰"""
        default_type = config_manager.default_execution_config.get('db_type')
        
        if default_type and default_type in ['all', 'master', 'premp', 'mp', 'mpbackup']:
            print(f"\nğŸ“Œ æ‰¾åˆ°é è¨­ DB é¡å‹: {default_type}")
            if input("æ˜¯å¦ä½¿ç”¨é è¨­å€¼? (Y/n): ").strip().lower() != 'n':
                self.selected_db_type = default_type
                print(f"âœ… å·²é¸æ“‡ DB é¡å‹: {self.selected_db_type}")
                return self.selected_db_type
        
        print("\né¸æ“‡ DB é¡å‹:")
        print("1. All (æ‰€æœ‰é¡å‹)")
        print("2. Master")
        print("3. PreMP")
        print("4. MP")
        print("5. MP Backup")
        
        choice = input("è«‹é¸æ“‡: ").strip()
        
        type_map = {
            '1': 'all',
            '2': 'master',
            '3': 'premp',
            '4': 'mp',
            '5': 'mpbackup'
        }
        
        self.selected_db_type = type_map.get(choice, 'all')
        print(f"âœ… å·²é¸æ“‡ DB é¡å‹: {self.selected_db_type}")
        return self.selected_db_type
    
    def select_dbs(self):
        """é¸æ“‡è¦å®šç‰ˆçš„ DBï¼ˆæ”¯æ´é è¨­å€¼ï¼‰"""
        if not self.tool.mapping_reader or self.tool.mapping_reader.df is None:
            print("âŒ è«‹å…ˆè¼‰å…¥ mapping table")
            return []
        
        all_db_infos = self.tool.get_all_dbs(self.selected_db_type)
        if not all_db_infos:
            print(f"âŒ æ²’æœ‰æ‰¾åˆ° {self.selected_db_type} é¡å‹çš„ DB")
            return []
        
        # å–å¾—ä¸é‡è¤‡çš„ DB åˆ—è¡¨
        unique_dbs = {}
        for db_info in all_db_infos:
            if db_info.db_info not in unique_dbs:
                unique_dbs[db_info.db_info] = db_info
        
        db_list = list(unique_dbs.keys())
        db_list.sort()
        
        # æª¢æŸ¥æ˜¯å¦æœ‰é è¨­çš„ DB åˆ—è¡¨
        default_dbs = config_manager.default_execution_config.get('selected_dbs')
        
        if default_dbs:
            if default_dbs in ['all', '*']:
                print(f"\nğŸ“Œ é è¨­é…ç½®ç‚ºé¸æ“‡æ‰€æœ‰ {self.selected_db_type} é¡å‹çš„ DB")
                if input(f"æ˜¯å¦é¸æ“‡å…¨éƒ¨ {len(db_list)} å€‹ DB? (Y/n): ").strip().lower() != 'n':
                    self.selected_dbs = db_list
                    print(f"âœ… å·²é¸æ“‡æ‰€æœ‰ {len(db_list)} å€‹ DB")
                    return db_list
            
            elif isinstance(default_dbs, list) and len(default_dbs) > 0:
                parsed_dbs = []
                for db_spec in default_dbs:
                    if '#' in db_spec:
                        db_name, version = db_spec.split('#', 1)
                        if db_name in db_list:
                            parsed_dbs.append(db_name)
                            self.db_versions[db_name] = version
                    else:
                        if db_spec in db_list:
                            parsed_dbs.append(db_spec)
                
                if parsed_dbs:
                    print(f"\nğŸ“Œ æ‰¾åˆ°é è¨­ DB åˆ—è¡¨: {', '.join(default_dbs)}")
                    print(f"   å…¶ä¸­ {len(parsed_dbs)} å€‹ DB å­˜åœ¨æ–¼ç•¶å‰ mapping table")
                    if input("æ˜¯å¦ä½¿ç”¨é è¨­ DB åˆ—è¡¨? (Y/n): ").strip().lower() != 'n':
                        self.selected_dbs = parsed_dbs
                        print(f"âœ… å·²é¸æ“‡ {len(parsed_dbs)} å€‹ DB")
                        return parsed_dbs
        
        # é¡¯ç¤º DB åˆ—è¡¨å’ŒåŸæœ¬çš„é¸æ“‡é‚è¼¯
        print(f"\næ‰¾åˆ° {len(db_list)} å€‹ä¸é‡è¤‡çš„ DB (é¡å‹: {self.selected_db_type})")
        
        # é¡¯ç¤º DB åˆ—è¡¨
        print("\nDB åˆ—è¡¨:")
        for i, db in enumerate(db_list, 1):
            db_info = unique_dbs[db]
            print(f"{i:3d}. {db:10s} - {db_info.module:10s} ({db_info.db_type})")
        
        print("\né¸æ“‡æ–¹å¼:")
        print("1. å…¨é¸")
        print("2. è¼¸å…¥ç·¨è™Ÿç¯„åœ (å¦‚: 1-5,7,9-12)")
        print("3. è¼¸å…¥ DB åç¨±åˆ—è¡¨ (é€—è™Ÿåˆ†éš”)")
        
        choice = input("è«‹é¸æ“‡: ").strip()
        
        selected = []
        
        if choice == '1':
            selected = db_list
        elif choice == '2':
            indices_input = input("è«‹è¼¸å…¥ç·¨è™Ÿç¯„åœ: ").strip()
            try:
                indices = self._parse_number_range(indices_input, len(db_list))
                selected = [db_list[i-1] for i in indices if 1 <= i <= len(db_list)]
            except Exception as e:
                print(f"âŒ ç„¡æ•ˆçš„ç·¨è™Ÿç¯„åœ: {e}")
                return []
        elif choice == '3':
            db_names = input("è«‹è¼¸å…¥ DB åç¨± (å¦‚: DB2302,DB2575): ").strip()
            input_dbs = [db.strip() for db in db_names.split(',')]
            for db in input_dbs:
                if db in db_list:
                    selected.append(db)
                else:
                    print(f"âš ï¸ DB {db} ä¸å­˜åœ¨ï¼Œå·²è·³é")
        
        self.selected_dbs = selected
        print(f"âœ… å·²é¸æ“‡ {len(selected)} å€‹ DB")
        return selected
    
    def _parse_number_range(self, range_str: str, max_num: int) -> List[int]:
        """è§£ææ•¸å­—ç¯„åœå­—ä¸²"""
        result = []
        parts = range_str.split(',')
        
        for part in parts:
            part = part.strip()
            if '-' in part:
                start, end = part.split('-', 1)
                start = int(start.strip())
                end = int(end.strip())
                
                if start > end:
                    start, end = end, start
                
                for i in range(start, min(end + 1, max_num + 1)):
                    if i > 0:
                        result.append(i)
            else:
                num = int(part)
                if 1 <= num <= max_num:
                    result.append(num)
        
        return sorted(list(set(result)))
    
    def setup_db_versions(self):
        """è¨­å®š DB ç‰ˆæœ¬ï¼ˆæ”¯æ´é è¨­å€¼ï¼‰"""
        if not self.selected_dbs:
            print("âŒ è«‹å…ˆé¸æ“‡ DB")
            return
        
        default_versions = config_manager.default_execution_config.get('db_versions', {})
        
        if default_versions:
            applicable_versions = {
                db: ver for db, ver in default_versions.items() 
                if db in self.selected_dbs
            }
            
            if applicable_versions:
                print(f"\nğŸ“Œ æ‰¾åˆ°é è¨­ç‰ˆæœ¬è¨­å®š:")
                for db, ver in applicable_versions.items():
                    print(f"   {db}: ç‰ˆæœ¬ {ver}")
                
                if input("æ˜¯å¦ä½¿ç”¨é è¨­ç‰ˆæœ¬è¨­å®š? (Y/n): ").strip().lower() != 'n':
                    self.db_versions.update(applicable_versions)
                    print(f"âœ… å·²å¥—ç”¨ {len(applicable_versions)} å€‹ DB çš„é è¨­ç‰ˆæœ¬")
                    
                    unset_dbs = [db for db in self.selected_dbs if db not in self.db_versions]
                    if unset_dbs:
                        print(f"\né‚„æœ‰ {len(unset_dbs)} å€‹ DB æœªè¨­å®šç‰ˆæœ¬:")
                        for db in unset_dbs:
                            version = input(f"{db} çš„ç‰ˆæœ¬ [æœ€æ–°]: ").strip()
                            if version:
                                self.db_versions[db] = version
                    return
        
        print("\nè¨­å®š DB ç‰ˆæœ¬ (ç•™ç©ºä½¿ç”¨æœ€æ–°ç‰ˆæœ¬)")
        print("æç¤º: å¯ä»¥è¼¸å…¥å…·é«”ç‰ˆæœ¬è™Ÿï¼Œå¦‚ 206, 204 ç­‰")
        print("æ”¯æ´æ ¼å¼:")
        print("  âœ… 206_all_202507100000  (version_all_timestamp)")
        print("  âœ… 204_202507081101      (version_timestamp)")
        print("  âœ… 465_all_202502170030_NG_uboot_fail (å¸¶å¾Œç¶´)")
        print("  âœ… 466_202502171018_NG_uboot_fail (å¸¶å¾Œç¶´)")
        
        for db in self.selected_dbs:
            if db in self.db_versions:
                print(f"{db}: å·²è¨­å®šç‰ˆæœ¬ {self.db_versions[db]}")
                continue
            
            version = input(f"{db} çš„ç‰ˆæœ¬ [æœ€æ–°]: ").strip()
            if version:
                self.db_versions[db] = version
        
        if self.db_versions:
            print(f"âœ… å·²è¨­å®š {len(self.db_versions)} å€‹ DB çš„ç‰ˆæœ¬")
    
    def execute_pinning(self):
        """åŸ·è¡Œå®šç‰ˆï¼ˆæ”¯æ´é è¨­é…ç½®ï¼‰"""
        if not self.selected_dbs:
            print("âŒ è«‹å…ˆé¸æ“‡è¦å®šç‰ˆçš„ DB")
            return
        
        if not self.tool.mapping_reader or self.tool.mapping_reader.df is None:
            print("âŒ è«‹å…ˆè¼‰å…¥ mapping table")
            return
        
        print("\n" + "="*60)
        print("æº–å‚™åŸ·è¡Œå®šç‰ˆ")
        print("="*60)
        print(f"ğŸ“Œ DB æ•¸é‡: {len(self.selected_dbs)}")
        print(f"ğŸ” è¼¸å‡ºç›®éŒ„: {self.tool.output_dir}")
        
        # è©¢å•è¼¸å‡ºç›®éŒ„ï¼ˆæª¢æŸ¥é è¨­å€¼ï¼‰
        default_output = config_manager.default_execution_config.get('output_dir')
        if default_output:
            print(f"ğŸ“Œ æ‰¾åˆ°é è¨­è¼¸å‡ºç›®éŒ„: {default_output}")
            if input("æ˜¯å¦ä½¿ç”¨é è¨­è¼¸å‡ºç›®éŒ„? (Y/n): ").strip().lower() != 'n':
                self.tool.output_dir = default_output
            else:
                output_dir = input(f"è¼¸å‡ºç›®éŒ„ [{self.tool.output_dir}]: ").strip()
                if output_dir:
                    self.tool.output_dir = output_dir
        else:
            output_dir = input(f"è¼¸å‡ºç›®éŒ„ [{self.tool.output_dir}]: ").strip()
            if output_dir:
                self.tool.output_dir = output_dir
        
        # ç¢ºèªåŸ·è¡Œï¼ˆæª¢æŸ¥è‡ªå‹•ç¢ºèªè¨­å®šï¼‰
        if config_manager.default_execution_config.get('auto_confirm'):
            print("ğŸ“Œ è‡ªå‹•ç¢ºèªåŸ·è¡Œï¼ˆæ ¹æ“šé è¨­é…ç½®ï¼‰")
        else:
            if input("\nç¢ºèªé–‹å§‹åŸ·è¡Œ? (Y/n): ").strip().lower() == 'n':
                print("âŒ ä½¿ç”¨è€…å–æ¶ˆæ“ä½œ")
                return
        
        print("\nğŸš€ é–‹å§‹åŸ·è¡Œå®šç‰ˆ...")
        
        # é€£ç·š SFTP
        print("ğŸŒ é€£ç·šåˆ° SFTP ä¼ºæœå™¨...")
        if not self.tool.sftp_manager.connect():
            print("âŒ SFTP é€£ç·šå¤±æ•—")
            return
        
        try:
            # åŸ·è¡Œå®šç‰ˆ
            self.tool.process_selected_dbs(self.selected_dbs, self.db_versions)
            
            # ç”¢ç”Ÿå ±å‘Š
            print("\nğŸ“Š ç”¢ç”Ÿå ±å‘Š...")
            report_path = os.path.join(
                self.tool.output_dir, 
                config_manager.path_config['report_filename']
            )
            self.tool.generate_report(report_path)
            
            print("\nâœ¨ å®šç‰ˆå®Œæˆï¼")
            
        finally:
            # é—œé–‰ SFTP é€£ç·š
            self.tool.sftp_manager.disconnect()
            # æ¸…ç†æ‰€æœ‰è³‡æº
            resource_manager.cleanup_all()
    
    def display_menu(self) -> str:
        """é¡¯ç¤ºä¸»é¸å–®ï¼ˆé¡¯ç¤ºé è¨­é…ç½®ç‹€æ…‹ï¼‰"""
        print("\n" + "="*60)
        print("Manifest å®šç‰ˆå·¥å…· - ä¸»é¸å–®")
        
        # å¦‚æœæœ‰é è¨­é…ç½®ï¼Œé¡¯ç¤ºæç¤º
        has_defaults = any([
            config_manager.default_execution_config.get('mapping_table'),
            config_manager.default_execution_config.get('db_type'),
            config_manager.default_execution_config.get('selected_dbs'),
            config_manager.default_execution_config.get('db_versions'),
            config_manager.default_execution_config.get('output_dir')
        ])
        
        if has_defaults:
            print("(ğŸ“Œ å·²è¼‰å…¥é è¨­é…ç½®)")
        
        print("="*60)
        print("1. è¼‰å…¥ mapping table")
        print("2. è¨­å®š SFTP é€£ç·šè³‡è¨Š")
        print("3. é¸æ“‡ DB é¡å‹ (master/premp/mp/mpbackup/all)")
        print("4. é¸æ“‡è¦å®šç‰ˆçš„ DB")
        print("5. è¨­å®š DB ç‰ˆæœ¬")
        print("6. é–‹å§‹åŸ·è¡Œå®šç‰ˆ")
        print("7. é¡¯ç¤ºç›®å‰è¨­å®š")
        print("8. å¿«é€ŸåŸ·è¡Œï¼ˆä½¿ç”¨æ‰€æœ‰é è¨­å€¼ï¼‰")
        print("9. è¨­å®šé€²éšé¸é …")
        print("10. æ¸¬è©¦ JIRA é€£ç·š")
        print("11. æ¸¬è©¦ SFTP é€£ç·šå’Œè·¯å¾‘")
        print("12. æ¸¬è©¦ç‰ˆæœ¬ç›®éŒ„è­˜åˆ¥")
        print("0. çµæŸç¨‹å¼")
        print("="*60)
        
        return input("è«‹é¸æ“‡åŠŸèƒ½: ").strip()
    
    def setup_advanced_options(self):
        """è¨­å®šé€²éšé¸é …"""
        print("\né€²éšé¸é …è¨­å®š:")
        print("1. å¹³è¡Œè™•ç†è¨­å®š")
        print("2. Repo è¨­å®š")
        print("3. æ—¥èªŒç­‰ç´šè¨­å®š")
        print("4. JIRA è¨­å®š")
        print("5. è¿”å›ä¸»é¸å–®")
        
        choice = input("è«‹é¸æ“‡: ").strip()
        
        if choice == '1':
            # å¹³è¡Œè™•ç†è¨­å®š
            enable = input(f"å•Ÿç”¨å¹³è¡Œè™•ç†? (Y/n) [{config_manager.parallel_config['enable_parallel']}]: ").strip().lower()
            if enable == 'n':
                config_manager.parallel_config['enable_parallel'] = False
            elif enable == 'y':
                config_manager.parallel_config['enable_parallel'] = True
            
            if config_manager.parallel_config['enable_parallel']:
                workers = input(f"Worker æ•¸é‡ [{config_manager.parallel_config['max_workers']}]: ").strip()
                if workers.isdigit():
                    config_manager.parallel_config['max_workers'] = int(workers)
            
            print("âœ… å¹³è¡Œè™•ç†è¨­å®šå·²æ›´æ–°")
            
        elif choice == '2':
            # Repo è¨­å®š
            sync_jobs = input(f"Repo sync ä¸¦è¡Œæ•¸ [{config_manager.repo_config['sync_jobs']}]: ").strip()
            if sync_jobs.isdigit():
                config_manager.repo_config['sync_jobs'] = int(sync_jobs)
            
            sync_retry = input(f"Sync é‡è©¦æ¬¡æ•¸ [{config_manager.repo_config['sync_retry']}]: ").strip()
            if sync_retry.isdigit():
                config_manager.repo_config['sync_retry'] = int(sync_retry)
            
            sync_timeout = input(f"Sync è¶…æ™‚ç§’æ•¸ [{config_manager.repo_config['sync_timeout']}]: ").strip()
            if sync_timeout.isdigit():
                config_manager.repo_config['sync_timeout'] = int(sync_timeout)
            
            print("âœ… Repo è¨­å®šå·²æ›´æ–°")
            
        elif choice == '3':
            # æ—¥èªŒç­‰ç´šè¨­å®š
            print("æ—¥èªŒç­‰ç´š:")
            print("1. DEBUG")
            print("2. INFO")
            print("3. WARNING")
            print("4. ERROR")
            
            level_choice = input("è«‹é¸æ“‡: ").strip()
            level_map = {
                '1': logging.DEBUG,
                '2': logging.INFO,
                '3': logging.WARNING,
                '4': logging.ERROR
            }
            
            if level_choice in level_map:
                config_manager.log_config['level'] = level_map[level_choice]
                # æ›´æ–°æ‰€æœ‰ logger
                for handler in logging.getLogger().handlers:
                    handler.setLevel(config_manager.log_config['level'])
                print("âœ… æ—¥èªŒç­‰ç´šå·²æ›´æ–°")
                
        elif choice == '4':
            # JIRA è¨­å®š
            print("\nç›®å‰ JIRA è¨­å®š:")
            print(f"  ç¶²å€: https://{config_manager.jira_config['site']}")
            print(f"  ç”¨æˆ¶: {config_manager.jira_config['username']}")
            print(f"  API URL: {config_manager.jira_config['api_url']}")
            
            if input("\næ˜¯å¦è¦ä¿®æ”¹è¨­å®š? (y/N): ").strip().lower() == 'y':
                site = input(f"JIRA ç¶²ç«™ [{config_manager.jira_config['site']}]: ").strip()
                if site:
                    config_manager.jira_config['site'] = site
                    config_manager.jira_config['api_url'] = f"https://{site}/rest/api/2"
                
                username = input(f"ç”¨æˆ¶å [{config_manager.jira_config['username']}]: ").strip()
                if username:
                    config_manager.jira_config['username'] = username
                
                password = input("å¯†ç¢¼ (ç•™ç©ºä¿æŒåŸå€¼): ").strip()
                if password:
                    config_manager.jira_config['password'] = password
                
                print("âœ… JIRA è¨­å®šå·²æ›´æ–°")
                
                # æ¸…é™¤å¿«å–
                if hasattr(self.tool, 'source_cmd_manager'):
                    self.tool.source_cmd_manager.clear_cache()
    
    def quick_execute_with_defaults(self):
        """ä½¿ç”¨é è¨­é…ç½®å¿«é€ŸåŸ·è¡Œ"""
        print("\n" + "="*60)
        print("å¿«é€ŸåŸ·è¡Œæ¨¡å¼ - ä½¿ç”¨é è¨­é…ç½®")
        print("="*60)
        
        # è‡ªå‹•è¼‰å…¥ mapping table
        if config_manager.default_execution_config.get('mapping_table'):
            file_path = config_manager.default_execution_config['mapping_table']
            if os.path.exists(file_path):
                print(f"ğŸ“Œ è¼‰å…¥é è¨­ mapping table: {file_path}")
                if self.tool.load_mapping_table(file_path):
                    print(f"âœ… æˆåŠŸè¼‰å…¥")
                else:
                    print("âŒ è¼‰å…¥å¤±æ•—")
                    return
            else:
                print(f"âŒ é è¨­ mapping table ä¸å­˜åœ¨: {file_path}")
                return
        else:
            print("âŒ æœªè¨­å®šé è¨­ mapping table")
            return
        
        # è¨­å®š DB é¡å‹
        if config_manager.default_execution_config.get('db_type'):
            self.selected_db_type = config_manager.default_execution_config['db_type']
            print(f"ğŸ“Œ ä½¿ç”¨é è¨­ DB é¡å‹: {self.selected_db_type}")
        
        # é¸æ“‡ DB
        default_dbs = config_manager.default_execution_config.get('selected_dbs')
        all_db_infos = self.tool.get_all_dbs(self.selected_db_type)
        
        if default_dbs:
            if default_dbs in ['all', '*']:
                unique_dbs = list(set([db.db_info for db in all_db_infos]))
                self.selected_dbs = unique_dbs
                print(f"ğŸ“Œ é¸æ“‡æ‰€æœ‰ {self.selected_db_type} é¡å‹çš„ DB: {len(unique_dbs)} å€‹")
            
            elif isinstance(default_dbs, list) and len(default_dbs) > 0:
                parsed_dbs = []
                for db_spec in default_dbs:
                    if '#' in db_spec:
                        db_name, version = db_spec.split('#', 1)
                        parsed_dbs.append(db_name)
                        self.db_versions[db_name] = version
                    else:
                        parsed_dbs.append(db_spec)
                self.selected_dbs = parsed_dbs
                print(f"ğŸ“Œ ä½¿ç”¨é è¨­ DB åˆ—è¡¨: {len(parsed_dbs)} å€‹")
        else:
            print("âš ï¸ é è¨­é…ç½®æœªæŒ‡å®š DB åˆ—è¡¨ï¼Œç„¡æ³•è‡ªå‹•åŸ·è¡Œ")
            return
        
        # è¨­å®šç‰ˆæœ¬
        if config_manager.default_execution_config.get('db_versions'):
            self.db_versions.update(config_manager.default_execution_config['db_versions'])
            print(f"ğŸ“Œ å¥—ç”¨é è¨­ç‰ˆæœ¬è¨­å®š: {len(self.db_versions)} å€‹")
        
        # è¨­å®šè¼¸å‡ºç›®éŒ„
        if config_manager.default_execution_config.get('output_dir'):
            self.tool.output_dir = config_manager.default_execution_config['output_dir']
            print(f"ğŸ“Œ ä½¿ç”¨é è¨­è¼¸å‡ºç›®éŒ„: {self.tool.output_dir}")
        
        # é¡¯ç¤ºæ‘˜è¦
        print("\nåŸ·è¡Œæ‘˜è¦:")
        print(f"  DB é¡å‹: {self.selected_db_type}")
        print(f"  DB æ•¸é‡: {len(self.selected_dbs)}")
        print(f"  è¨­å®šç‰ˆæœ¬: {len(self.db_versions)} å€‹")
        print(f"  è¼¸å‡ºç›®éŒ„: {self.tool.output_dir}")
        
        # ç¢ºèªåŸ·è¡Œ
        if not config_manager.default_execution_config.get('auto_confirm'):
            if input("\nç¢ºèªåŸ·è¡Œ? (Y/n): ").strip().lower() == 'n':
                print("âŒ ä½¿ç”¨è€…å–æ¶ˆ")
                return
        
        # åŸ·è¡Œå®šç‰ˆ
        self.execute_pinning()
    
    def test_jira_connection(self):
        """æ¸¬è©¦ JIRA é€£ç·šä¸¦é¡¯ç¤ºç¯„ä¾‹æŸ¥è©¢"""
        print("\næ¸¬è©¦ JIRA é€£ç·š...")
        
        # å»ºç«‹ source command ç®¡ç†å™¨ï¼ˆå¦‚æœé‚„æ²’æœ‰ï¼‰
        if not hasattr(self.tool, 'source_cmd_manager'):
            self.tool.source_cmd_manager = SourceCommandManager()
        
        # æ¸¬è©¦é€£ç·š
        if self.tool.source_cmd_manager.test_jira_connection():
            print("âœ… JIRA é€£ç·šæˆåŠŸï¼")
            
            # è©¢å•æ˜¯å¦è¦æ¸¬è©¦æŸ¥è©¢
            if input("\næ˜¯å¦è¦æ¸¬è©¦æŸ¥è©¢ DB çš„ source command? (y/N): ").strip().lower() == 'y':
                db_name = input("è«‹è¼¸å…¥ DB åç¨± (ä¾‹å¦‚: DB2302): ").strip()
                if db_name:
                    print(f"\næŸ¥è©¢ {db_name} çš„ source command...")
                    
                    # å»ºç«‹è‡¨æ™‚ DBInfo
                    test_db_info = DBInfo(
                        sn=0,
                        module="Test",
                        db_type="master",
                        db_info=db_name,
                        db_folder="",
                        sftp_path=""
                    )
                    
                    # æŸ¥è©¢
                    cmd = self.tool.source_cmd_manager.get_source_command(
                        test_db_info,
                        self.tool.mapping_reader.df if self.tool.mapping_reader else None
                    )
                    
                    if cmd:
                        print(f"\næ‰¾åˆ°çš„ source command:")
                        print(f"  {cmd}")
                    else:
                        print(f"\næœªæ‰¾åˆ° {db_name} çš„ source command")
        else:
            print("âŒ JIRA é€£ç·šå¤±æ•—ï¼")
            print("\nè«‹æª¢æŸ¥ï¼š")
            print("1. JIRA ç¶²å€æ˜¯å¦æ­£ç¢º")
            print("2. ç”¨æˆ¶åå’Œå¯†ç¢¼æ˜¯å¦æ­£ç¢º")
            print("3. ç¶²è·¯é€£ç·šæ˜¯å¦æ­£å¸¸")
            print("4. æ˜¯å¦éœ€è¦ VPN é€£ç·š")
    
    def test_sftp_connection(self):
        """æ¸¬è©¦ SFTP é€£ç·šå’Œè·¯å¾‘è¨ºæ–·"""
        print("\nğŸ” SFTP é€£ç·šå’Œè·¯å¾‘æ¸¬è©¦")
        print("="*50)
        
        # é¦–å…ˆæ¸¬è©¦åŸºæœ¬é€£ç·š
        print("ğŸŒ æ¸¬è©¦ SFTP åŸºæœ¬é€£ç·š...")
        print(f"   ä¼ºæœå™¨: {config_manager.sftp_config['host']}:{config_manager.sftp_config['port']}")
        print(f"   ç”¨æˆ¶: {config_manager.sftp_config['username']}")
        
        if not self.tool.sftp_manager.connect():
            print("âŒ SFTP åŸºæœ¬é€£ç·šå¤±æ•—")
            print("\nå¯èƒ½çš„åŸå› :")
            print("1. ç¶²è·¯é€£ç·šå•é¡Œ")
            print("2. SFTP ä¼ºæœå™¨ç„¡æ³•è¨ªå•") 
            print("3. ç”¨æˆ¶åæˆ–å¯†ç¢¼éŒ¯èª¤")
            print("4. é˜²ç«ç‰†é˜»æ“‹é€£ç·š")
            return
        
        print("âœ… SFTP åŸºæœ¬é€£ç·šæˆåŠŸï¼")
        
        # è©¢å•æ¸¬è©¦æ¨¡å¼
        print("\né¸æ“‡æ¸¬è©¦æ¨¡å¼:")
        print("1. æ¸¬è©¦å–®å€‹è·¯å¾‘ (æ‰‹å‹•è¼¸å…¥)")
        print("2. æ¸¬è©¦ mapping table ä¸­çš„ DB è·¯å¾‘")
        print("3. æ¸¬è©¦å¤±æ•—çš„ DB è·¯å¾‘ (DB2858, DB2575, DB2919)")
        print("4. å¿«é€Ÿæ¸¬è©¦å¸¸ç”¨è·¯å¾‘")
        
        choice = input("è«‹é¸æ“‡ (1-4): ").strip()
        
        try:
            if choice == '1':
                self._test_single_path()
            elif choice == '2':
                self._test_mapping_table_paths()
            elif choice == '3':
                self._test_failed_db_paths()
            elif choice == '4':
                self._test_common_paths()
            else:
                print("âŒ ç„¡æ•ˆé¸æ“‡")
        
        finally:
            self.tool.sftp_manager.disconnect()
            print("\nğŸ”Œ SFTP é€£ç·šå·²é—œé–‰")
    
    def _test_single_path(self):
        """æ¸¬è©¦å–®å€‹è·¯å¾‘"""
        path = input("\nè«‹è¼¸å…¥è¦æ¸¬è©¦çš„ SFTP è·¯å¾‘: ").strip()
        if not path:
            print("âŒ æœªè¼¸å…¥è·¯å¾‘")
            return
        
        db_name = input("è«‹è¼¸å…¥ DB åç¨± (å¯é¸): ").strip() or "Manual_Test"
        
        print(f"\nğŸ” æ¸¬è©¦è·¯å¾‘: {path}")
        self._diagnose_sftp_path(path, db_name)
    
    def _test_mapping_table_paths(self):
        """æ¸¬è©¦ mapping table ä¸­çš„è·¯å¾‘"""
        if not self.tool.mapping_reader or self.tool.mapping_reader.df is None:
            print("âŒ è«‹å…ˆè¼‰å…¥ mapping table")
            return
        
        all_db_infos = self.tool.get_all_dbs('all')
        if not all_db_infos:
            print("âŒ mapping table ä¸­æ²’æœ‰æ‰¾åˆ° DB è³‡æ–™")
            return
        
        # é¡¯ç¤ºå¯ç”¨çš„ DB
        unique_dbs = {}
        for db_info in all_db_infos:
            if db_info.db_info not in unique_dbs:
                unique_dbs[db_info.db_info] = db_info
        
        db_list = list(unique_dbs.keys())[:10]  # åªé¡¯ç¤ºå‰ 10 å€‹
        
        print(f"\nğŸ“‹ å¯æ¸¬è©¦çš„ DB (å‰10å€‹):")
        for i, db_name in enumerate(db_list, 1):
            db_info = unique_dbs[db_name]
            print(f"  {i:2d}. {db_name:12s} - {db_info.module:15s} ({db_info.db_type})")
        
        try:
            selection = input(f"\nè«‹é¸æ“‡è¦æ¸¬è©¦çš„ DB (1-{len(db_list)}) æˆ–è¼¸å…¥ DB åç¨±: ").strip()
            
            if selection.isdigit():
                idx = int(selection) - 1
                if 0 <= idx < len(db_list):
                    db_name = db_list[idx]
                    db_info = unique_dbs[db_name]
                else:
                    print("âŒ ç„¡æ•ˆçš„ç·¨è™Ÿ")
                    return
            else:
                db_name = selection
                db_info = unique_dbs.get(db_name)
                if not db_info:
                    print(f"âŒ æ‰¾ä¸åˆ° DB: {db_name}")
                    return
            
            print(f"\nğŸ¯ æ¸¬è©¦ {db_info.db_info}")
            print(f"   è·¯å¾‘: {db_info.sftp_path}")
            print(f"   æ¨¡çµ„: {db_info.module}")
            print(f"   é¡å‹: {db_info.db_type}")
            
            self._diagnose_sftp_path(db_info.sftp_path, db_info.db_info)
            
        except ValueError:
            print("âŒ ç„¡æ•ˆçš„è¼¸å…¥")
    
    def _test_failed_db_paths(self):
        """æ¸¬è©¦å¤±æ•—çš„ DB è·¯å¾‘"""
        failed_dbs = {
            'DB2858': '/DailyBuild/Merlin8/DB2858_Merlin8_FW_Android14_Ref_Plus_PreMP_GoogleGMS',
            'DB2575': '/DailyBuild/Merlin8/DB2575_Merlin8_FW_Android14_Google_Refplus_Wave_GoogleGMS',
            'DB2919': '/DailyBuild/Merlin8/DB2919_Merlin8_64Bit_Android14_Ref_Plus_Wave_Backup_GoogleGMS'
        }
        
        print(f"\nğŸ” æ¸¬è©¦å¤±æ•—çš„ DB è·¯å¾‘")
        
        for db_name, path in failed_dbs.items():
            print(f"\n{'='*60}")
            print(f"ğŸ¯ æ¸¬è©¦ {db_name}")
            print(f"ğŸ“ è·¯å¾‘: {path}")
            print(f"{'='*60}")
            
            self._diagnose_sftp_path(path, db_name)
            
            # è©¢å•æ˜¯å¦ç¹¼çºŒä¸‹ä¸€å€‹
            if db_name != list(failed_dbs.keys())[-1]:  # ä¸æ˜¯æœ€å¾Œä¸€å€‹
                if input(f"\nç¹¼çºŒæ¸¬è©¦ä¸‹ä¸€å€‹ DB? (Y/n): ").strip().lower() == 'n':
                    break
    
    def _test_common_paths(self):
        """æ¸¬è©¦å¸¸ç”¨è·¯å¾‘"""
        common_paths = [
            ('/DailyBuild/Merlin8/', 'Merlin8 å»ºç½®æ ¹ç›®éŒ„'),
            ('/DailyBuild/', 'å»ºç½®æ ¹ç›®éŒ„'),
            ('/DailyBuild/Merlin8/DB2145_Merlin8_FW_Android14_Ref_Plus_GoogleGMS', 'DB2145 (å·²çŸ¥å¯ç”¨)'),
        ]
        
        print(f"\nğŸ” æ¸¬è©¦å¸¸ç”¨è·¯å¾‘")
        
        for path, description in common_paths:
            print(f"\n{'='*60}")
            print(f"ğŸ¯ æ¸¬è©¦: {description}")
            print(f"ğŸ“ è·¯å¾‘: {path}")
            print(f"{'='*60}")
            
            self._diagnose_sftp_path(path, description.split()[0])
    
    def _diagnose_sftp_path(self, path: str, db_name: str):
        """è¨ºæ–·å–®å€‹ SFTP è·¯å¾‘çš„è©³ç´°å‡½æ•¸"""
        try:
            sftp = self.tool.sftp_manager._get_connection()[0]
            if not sftp:
                print("âŒ ç„¡æ³•ç²å– SFTP é€£ç·š")
                return
            
            # æª¢æŸ¥è·¯å¾‘æ˜¯å¦å­˜åœ¨
            try:
                print(f"ğŸ“ æª¢æŸ¥è·¯å¾‘æ˜¯å¦å¯è¨ªå•...")
                items = sftp.listdir_attr(path)
                print(f"âœ… è·¯å¾‘å¯è¨ªå•ï¼ŒåŒ…å« {len(items)} å€‹é …ç›®")
                
                # åˆ†æå…§å®¹
                directories = []
                files = []
                
                for item in items:
                    if item.st_mode & 0o40000:  # æ˜¯ç›®éŒ„
                        directories.append({
                            'name': item.filename,
                            'modified': datetime.fromtimestamp(item.st_mtime).strftime('%Y-%m-%d %H:%M:%S')
                        })
                    else:
                        files.append({
                            'name': item.filename,
                            'size': item.st_size,
                            'modified': datetime.fromtimestamp(item.st_mtime).strftime('%Y-%m-%d %H:%M:%S')
                        })
                
                print(f"ğŸ“Š å…§å®¹çµ±è¨ˆ: {len(directories)} å€‹ç›®éŒ„, {len(files)} å€‹æª”æ¡ˆ")
                
                # é¡¯ç¤ºç›®éŒ„
                if directories:
                    print(f"\nğŸ“‚ ç›®éŒ„åˆ—è¡¨ (å‰10å€‹):")
                    for i, dir_info in enumerate(directories[:10]):
                        # æª¢æŸ¥æ˜¯å¦ç¬¦åˆç‰ˆæœ¬æ ¼å¼
                        is_version = self.tool.sftp_manager._is_version_directory(dir_info['name'])
                        status = "âœ…" if is_version else "âŒ"
                        print(f"  {status} {i+1:2d}. {dir_info['name']:<40} ({dir_info['modified']})")
                    if len(directories) > 10:
                        print(f"      ... é‚„æœ‰ {len(directories)-10} å€‹ç›®éŒ„")
                
                # æª¢æŸ¥ç‰ˆæœ¬ç›®éŒ„
                version_dirs = []
                for dir_info in directories:
                    if self.tool.sftp_manager._is_version_directory(dir_info['name']):
                        version_dirs.append(dir_info)
                
                if version_dirs:
                    print(f"\nğŸ¯ æ‰¾åˆ° {len(version_dirs)} å€‹ç‰ˆæœ¬ç›®éŒ„:")
                    for i, ver_dir in enumerate(version_dirs[:5]):
                        version_num = self.tool.sftp_manager._extract_version_number_flexible(ver_dir['name'])
                        print(f"  {i+1:2d}. {ver_dir['name']:<30} (ç‰ˆæœ¬: {version_num}, {ver_dir['modified']})")
                        
                        # æª¢æŸ¥ç‰ˆæœ¬ç›®éŒ„å…§å®¹
                        try:
                            version_path = f"{path.rstrip('/')}/{ver_dir['name']}"
                            version_files = sftp.listdir(version_path)
                            
                            # æ‰¾ manifest æª”æ¡ˆ
                            manifest_files = [f for f in version_files 
                                            if f.endswith('.xml') and 'manifest' in f.lower()]
                            xml_files = [f for f in version_files if f.endswith('.xml')]
                            
                            if manifest_files:
                                print(f"      âœ… åŒ…å« {len(manifest_files)} å€‹ manifest æª”æ¡ˆ:")
                                for mf in manifest_files[:3]:  # æœ€å¤šé¡¯ç¤º3å€‹
                                    try:
                                        manifest_path = f"{version_path}/{mf}"
                                        file_stat = sftp.stat(manifest_path)
                                        size_kb = file_stat.st_size / 1024
                                        valid = "âœ…" if file_stat.st_size > 100000 else "âš ï¸"
                                        print(f"         {valid} {mf} ({size_kb:.1f} KB)")
                                    except:
                                        print(f"         â“ {mf} (ç„¡æ³•å–å¾—å¤§å°)")
                            elif xml_files:
                                print(f"      âš ï¸  æœ‰ {len(xml_files)} å€‹ XML æª”æ¡ˆä½†æ²’æœ‰ manifest:")
                                for xf in xml_files[:3]:
                                    print(f"         - {xf}")
                            else:
                                print(f"      âŒ æ²’æœ‰ XML æª”æ¡ˆ (å…± {len(version_files)} å€‹æª”æ¡ˆ)")
                                # é¡¯ç¤ºä¸€äº›æª”æ¡ˆæ¨£æœ¬
                                sample_files = version_files[:5]
                                if sample_files:
                                    print(f"         æª”æ¡ˆæ¨£æœ¬: {', '.join(sample_files)}")
                        
                        except PermissionError:
                            print(f"      ğŸš« ç„¡æ¬Šé™è¨ªå•ç‰ˆæœ¬ç›®éŒ„")
                        except Exception as e:
                            print(f"      âŒ æª¢æŸ¥ç‰ˆæœ¬ç›®éŒ„å¤±æ•—: {e}")
                else:
                    print(f"\nâŒ æ²’æœ‰æ‰¾åˆ°ç‰ˆæœ¬ç›®éŒ„")
                    if directories:
                        print(f"   æç¤º: æ‰¾åˆ°çš„ç›®éŒ„ä¼¼ä¹ä¸ç¬¦åˆç‰ˆæœ¬ç›®éŒ„çš„å‘½åæ¨¡å¼")
                        print(f"   æ”¯æ´çš„æ ¼å¼: 206_all_202507100000, 204_202507081101")
                        print(f"   å‰5å€‹ç›®éŒ„: {', '.join([d['name'] for d in directories[:5]])}")
                
                # é¡¯ç¤ºæª”æ¡ˆï¼ˆå¦‚æœæœ‰ï¼‰
                if files:
                    print(f"\nğŸ“„ æª”æ¡ˆåˆ—è¡¨ (å‰5å€‹):")
                    for i, file_info in enumerate(files[:5]):
                        size_mb = file_info['size'] / (1024*1024)
                        print(f"  {i+1:2d}. {file_info['name']:<30} ({size_mb:.1f} MB)")
            
            except FileNotFoundError:
                print(f"âŒ è·¯å¾‘ä¸å­˜åœ¨: {path}")
                self._suggest_alternative_paths(sftp, path, db_name)
            
            except PermissionError:
                print(f"ğŸš« æ¬Šé™è¢«æ‹’çµ•: {path}")
            
            except Exception as e:
                error_type = type(e).__name__
                print(f"âŒ æª¢æŸ¥è·¯å¾‘æ™‚ç™¼ç”ŸéŒ¯èª¤ ({error_type}): {e}")
        
        except Exception as e:
            print(f"âŒ è¨ºæ–·éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    def _suggest_alternative_paths(self, sftp, original_path: str, db_name: str):
        """å»ºè­°æ›¿ä»£è·¯å¾‘"""
        print(f"\nğŸ” æœå°‹æ›¿ä»£è·¯å¾‘...")
        
        try:
            # æª¢æŸ¥çˆ¶ç›®éŒ„
            parent_path = os.path.dirname(original_path.rstrip('/'))
            print(f"   æª¢æŸ¥çˆ¶ç›®éŒ„: {parent_path}")
            
            parent_items = sftp.listdir_attr(parent_path)
            similar_dirs = []
            
            # æå– DB åç¨±é€²è¡Œæ¨¡ç³ŠåŒ¹é…
            db_base = db_name.replace('DB', '').lower() if 'DB' in db_name else db_name.lower()
            
            for item in parent_items:
                if item.st_mode & 0o40000:  # æ˜¯ç›®éŒ„
                    dir_name_lower = item.filename.lower()
                    if (db_name.lower() in dir_name_lower or 
                        db_base in dir_name_lower):
                        similar_dirs.append({
                            'name': item.filename,
                            'modified': datetime.fromtimestamp(item.st_mtime).strftime('%Y-%m-%d %H:%M:%S')
                        })
            
            if similar_dirs:
                print(f"ğŸ¯ åœ¨çˆ¶ç›®éŒ„ä¸­æ‰¾åˆ° {len(similar_dirs)} å€‹å¯èƒ½çš„æ›¿ä»£è·¯å¾‘:")
                for i, dir_info in enumerate(similar_dirs[:5]):
                    full_path = f"{parent_path}/{dir_info['name']}"
                    print(f"  {i+1}. {full_path}")
                    print(f"     (ä¿®æ”¹æ™‚é–“: {dir_info['modified']})")
            else:
                print(f"âŒ åœ¨çˆ¶ç›®éŒ„ä¸­æ²’æœ‰æ‰¾åˆ°é¡ä¼¼çš„è·¯å¾‘")
                
                # é¡¯ç¤ºçˆ¶ç›®éŒ„ä¸­çš„æ‰€æœ‰ç›®éŒ„ä¾›åƒè€ƒ
                all_dirs = [item.filename for item in parent_items if item.st_mode & 0o40000]
                if all_dirs:
                    print(f"   çˆ¶ç›®éŒ„åŒ…å«çš„æ‰€æœ‰ç›®éŒ„ (å‰10å€‹):")
                    for dir_name in all_dirs[:10]:
                        print(f"     - {dir_name}")
                    if len(all_dirs) > 10:
                        print(f"     ... é‚„æœ‰ {len(all_dirs)-10} å€‹ç›®éŒ„")
        
        except Exception as e:
            print(f"âŒ æœå°‹æ›¿ä»£è·¯å¾‘æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    def test_version_detection(self):
        """æ¸¬è©¦ç‰ˆæœ¬ç›®éŒ„è­˜åˆ¥åŠŸèƒ½"""
        print("\nğŸ” ç‰ˆæœ¬ç›®éŒ„è­˜åˆ¥æ¸¬è©¦ (æ”¯æ´æ–°æ ¼å¼)")
        print("="*60)
        print("æ”¯æ´çš„æ ¼å¼:")
        print("  âœ… 206_all_202507100000  (version_all_timestamp)")
        print("  âœ… 204_202507081101      (version_timestamp)")
        print("  âœ… 465_all_202502170030_NG_uboot_fail (å¸¶å¾Œç¶´)")
        print("  âœ… 466_202502171018_NG_uboot_fail (å¸¶å¾Œç¶´)")
        print("="*60)
        
        # æ¸¬è©¦æ¨¡å¼é¸æ“‡
        print("\né¸æ“‡æ¸¬è©¦æ¨¡å¼:")
        print("1. æ¸¬è©¦å–®å€‹è·¯å¾‘çš„ç‰ˆæœ¬ç›®éŒ„")
        print("2. æ¸¬è©¦å¤±æ•— DB çš„ç‰ˆæœ¬ç›®éŒ„è­˜åˆ¥")
        print("3. æ¸¬è©¦ç‰ˆæœ¬ç›®éŒ„æ ¼å¼æª¢æ¸¬")
        print("4. æ¸¬è©¦ç‰ˆæœ¬è™Ÿæå–é‚è¼¯")
        
        choice = input("è«‹é¸æ“‡ (1-4): ").strip()
        
        if choice == '1':
            self._test_single_path_versions()
        elif choice == '2':
            self._test_failed_db_versions()
        elif choice == '3':
            self._test_version_pattern_detection()
        elif choice == '4':
            self._test_version_extraction_logic()
        else:
            print("âŒ ç„¡æ•ˆé¸æ“‡")
    
    def _test_single_path_versions(self):
        """æ¸¬è©¦å–®å€‹è·¯å¾‘çš„ç‰ˆæœ¬ç›®éŒ„"""
        path = input("\nè«‹è¼¸å…¥è¦æ¸¬è©¦çš„ SFTP è·¯å¾‘: ").strip()
        if not path:
            # ä½¿ç”¨å¤±æ•—çš„ DB ä½œç‚ºé è¨­
            path = "/DailyBuild/Merlin8/DB2575_Merlin8_FW_Android14_Google_Refplus_Wave_GoogleGMS"
            print(f"ä½¿ç”¨é è¨­è·¯å¾‘: {path}")
        
        print(f"\nğŸ” æ¸¬è©¦è·¯å¾‘: {path}")
        
        # é€£ç·šåˆ° SFTP
        if not self.tool.sftp_manager.connect():
            print("âŒ SFTP é€£ç·šå¤±æ•—")
            return
        
        try:
            self._analyze_version_directories(path)
        finally:
            self.tool.sftp_manager.disconnect()
    
    def _test_failed_db_versions(self):
        """æ¸¬è©¦å¤±æ•— DB çš„ç‰ˆæœ¬ç›®éŒ„è­˜åˆ¥"""
        failed_dbs = {
            'DB2575': '/DailyBuild/Merlin8/DB2575_Merlin8_FW_Android14_Google_Refplus_Wave_GoogleGMS',
            'DB2858': '/DailyBuild/Merlin8/DB2858_Merlin8_FW_Android14_Ref_Plus_PreMP_GoogleGMS',
            'DB2919': '/DailyBuild/Merlin8/DB2919_Merlin8_64Bit_Android14_Ref_Plus_Wave_Backup_GoogleGMS'
        }
        
        print(f"\nğŸ” æ¸¬è©¦å¤±æ•— DB çš„ç‰ˆæœ¬ç›®éŒ„è­˜åˆ¥")
        
        # é€£ç·šåˆ° SFTP
        if not self.tool.sftp_manager.connect():
            print("âŒ SFTP é€£ç·šå¤±æ•—")
            return
        
        try:
            for db_name, path in failed_dbs.items():
                print(f"\n{'='*60}")
                print(f"ğŸ¯ æ¸¬è©¦ {db_name}")
                print(f"ğŸ“ è·¯å¾‘: {path}")
                print(f"{'='*60}")
                
                self._analyze_version_directories(path)
                
                # è©¢å•æ˜¯å¦ç¹¼çºŒ
                if db_name != list(failed_dbs.keys())[-1]:
                    if input(f"\nç¹¼çºŒæ¸¬è©¦ä¸‹ä¸€å€‹ DB? (Y/n): ").strip().lower() == 'n':
                        break
        finally:
            self.tool.sftp_manager.disconnect()
    
    def _test_version_pattern_detection(self):
        """æ¸¬è©¦ç‰ˆæœ¬ç›®éŒ„æ ¼å¼æª¢æ¸¬"""
        path = input("\nè«‹è¼¸å…¥è¦æª¢æ¸¬çš„ SFTP è·¯å¾‘: ").strip()
        if not path:
            path = "/DailyBuild/Merlin8/DB2575_Merlin8_FW_Android14_Google_Refplus_Wave_GoogleGMS"
            print(f"ä½¿ç”¨é è¨­è·¯å¾‘: {path}")
        
        # é€£ç·šåˆ° SFTP
        if not self.tool.sftp_manager.connect():
            print("âŒ SFTP é€£ç·šå¤±æ•—")
            return
        
        try:
            patterns = self.tool.sftp_manager.detect_version_directory_patterns(path)
            
            print(f"\nğŸ“Š ç‰ˆæœ¬ç›®éŒ„æ ¼å¼æª¢æ¸¬çµæœ:")
            if patterns:
                for pattern_type, directories in patterns.items():
                    print(f"\nğŸ¯ {pattern_type} æ ¼å¼ ({len(directories)} å€‹):")
                    for i, dir_name in enumerate(directories[:10]):  # æœ€å¤šé¡¯ç¤º10å€‹
                        version_num = self.tool.sftp_manager._extract_version_number_flexible(dir_name)
                        print(f"  {i+1:2d}. {dir_name:<30} (ç‰ˆæœ¬: {version_num})")
                    if len(directories) > 10:
                        print(f"      ... é‚„æœ‰ {len(directories)-10} å€‹")
            else:
                print("âŒ æ²’æœ‰æª¢æ¸¬åˆ°ç‰ˆæœ¬ç›®éŒ„æ ¼å¼")
        
        except Exception as e:
            print(f"âŒ æª¢æ¸¬å¤±æ•—: {e}")
        finally:
            self.tool.sftp_manager.disconnect()
    
    def _test_version_extraction_logic(self):
        """æ¸¬è©¦ç‰ˆæœ¬è™Ÿæå–é‚è¼¯"""
        print(f"\nğŸ” æ¸¬è©¦ç‰ˆæœ¬è™Ÿæå–é‚è¼¯ï¼ˆå°ˆç”¨æ ¼å¼ï¼‰")
        
        # æ¸¬è©¦æ¡ˆä¾‹ï¼ˆå°ˆé–€é‡å°ä½ æåˆ°çš„æ ¼å¼ï¼‰
        test_cases = [
            # ä¸»è¦çš„å¯¦éš›æ ¼å¼
            "206_all_202507100000",           # æ ¼å¼1ï¼šversion_all_timestamp
            "204_202507081101",               # æ ¼å¼2ï¼šversion_timestamp
            "465_all_202502170030_NG_uboot_fail",  # æ ¼å¼1 + å¾Œç¶´
            "466_202502171018_NG_uboot_fail",      # æ ¼å¼2 + å¾Œç¶´
            
            # å…¶ä»–å¯èƒ½çš„è®Šé«”
            "150_all_202501150000",
            "99_202412251030",
            "300_all_202508200000_FAIL",
            "101_202507050900_SUCCESS",
            
            # ç°¡å–®æ ¼å¼
            "206",                            # ç´”æ•¸å­—
            "v204",                           # v + æ•¸å­—
            
            # æ‡‰è©²å¤±æ•—çš„æ¡ˆä¾‹
            "invalid_206",                    # å­—æ¯é–‹é ­
            "206_invalid",                    # ä¸ç¬¦åˆæ™‚é–“æˆ³æ ¼å¼
            "abc_def_ghi",                    # ç„¡æ•¸å­—
        ]
        
        print(f"\nğŸ“‹ æ¸¬è©¦æ¡ˆä¾‹ (å°ˆé–€é‡å°æ‚¨çš„æ ¼å¼):")
        
        sftp_manager = self.tool.sftp_manager
        
        success_count = 0
        total_count = len(test_cases)
        
        for i, test_case in enumerate(test_cases, 1):
            is_version = sftp_manager._is_version_directory(test_case)
            version_num = sftp_manager._extract_version_number_flexible(test_case)
            
            if is_version and version_num:
                status = "âœ…"
                success_count += 1
            elif "invalid" in test_case.lower():
                status = "âœ…"  # é€™å€‹æ‡‰è©²è¦å¤±æ•—
                success_count += 1
            else:
                status = "âŒ"
            
            version_str = f"ç‰ˆæœ¬è™Ÿ: {version_num}" if version_num else "ç„¡æ³•æå–"
            expected = "(æ‡‰è©²å¤±æ•—)" if "invalid" in test_case.lower() else ""
            
            print(f"  {i:2d}. {status} {test_case:<35} â†’ {version_str} {expected}")
        
        print(f"\nğŸ“Š æ¸¬è©¦çµæœ: {success_count}/{total_count} é€šé")
        
        if success_count == total_count:
            print("ğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼ç‰ˆæœ¬è­˜åˆ¥é‚è¼¯æ­£å¸¸é‹ä½œ")
        else:
            print("âš ï¸ éƒ¨åˆ†æ¸¬è©¦å¤±æ•—ï¼Œå¯èƒ½éœ€è¦èª¿æ•´è­˜åˆ¥é‚è¼¯")
        
        # æ¸¬è©¦ç‰ˆæœ¬è§£æ
        print(f"\nğŸ” æ¸¬è©¦ç‰ˆæœ¬ç›®éŒ„è©³ç´°è§£æ:")
        detailed_test_cases = [
            ("206_all_202507100000", 1720627200),
            ("204_202507081101", 1720430460), 
            ("465_all_202502170030_NG_uboot_fail", 1739235000),
            ("466_202502171018_NG_uboot_fail", 1739239080),
            ("150", 1720000000),
        ]
        
        for dir_name, mtime in detailed_test_cases:
            parsed = sftp_manager._parse_version_directory(dir_name, mtime)
            if parsed:
                print(f"  âœ… {dir_name}:")
                print(f"     ç‰ˆæœ¬è™Ÿ: {parsed['version_number']}")
                print(f"     æ™‚é–“æˆ³: {parsed.get('timestamp', 'N/A')}")
                print(f"     æ ¼å¼é¡å‹: {parsed['format_type']}")
                if parsed.get('has_suffix'):
                    print(f"     å¾Œç¶´: {parsed.get('suffix', 'N/A')}")
            else:
                print(f"  âŒ {dir_name}: è§£æå¤±æ•—")
    
    def _analyze_version_directories(self, path: str):
        """åˆ†æè·¯å¾‘ä¸­çš„ç‰ˆæœ¬ç›®éŒ„"""
        try:
            sftp = self.tool.sftp_manager._get_connection()[0]
            if not sftp:
                print("âŒ ç„¡æ³•ç²å– SFTP é€£ç·š")
                return
            
            # æª¢æŸ¥è·¯å¾‘æ˜¯å¦å­˜åœ¨
            try:
                items = sftp.listdir_attr(path)
                print(f"âœ… è·¯å¾‘å¯è¨ªå•ï¼ŒåŒ…å« {len(items)} å€‹é …ç›®")
            except FileNotFoundError:
                print(f"âŒ è·¯å¾‘ä¸å­˜åœ¨: {path}")
                return
            except Exception as e:
                print(f"âŒ è¨ªå•è·¯å¾‘å¤±æ•—: {e}")
                return
            
            # æ‰¾å‡ºæ‰€æœ‰ç›®éŒ„
            all_dirs = [item for item in items if item.st_mode & 0o40000]
            print(f"ğŸ“‚ åŒ…å« {len(all_dirs)} å€‹ç›®éŒ„")
            
            if not all_dirs:
                print("âŒ æ²’æœ‰æ‰¾åˆ°ä»»ä½•ç›®éŒ„")
                return
            
            # é¡¯ç¤ºæ‰€æœ‰ç›®éŒ„ï¼ˆå‰10å€‹ï¼‰
            print(f"\nğŸ“‹ æ‰€æœ‰ç›®éŒ„ (å‰10å€‹):")
            for i, item in enumerate(all_dirs[:10]):
                modified = datetime.fromtimestamp(item.st_mtime).strftime('%Y-%m-%d %H:%M:%S')
                # æª¢æŸ¥æ˜¯å¦ç¬¦åˆç‰ˆæœ¬æ ¼å¼
                is_version = self.tool.sftp_manager._is_version_directory(item.filename)
                status = "âœ…" if is_version else "âŒ"
                print(f"  {status} {i+1:2d}. {item.filename:<40} ({modified})")
            
            if len(all_dirs) > 10:
                print(f"      ... é‚„æœ‰ {len(all_dirs)-10} å€‹ç›®éŒ„")
            
            # ä½¿ç”¨æ”¹é€²çš„ç‰ˆæœ¬è­˜åˆ¥é‚è¼¯
            sftp_manager = self.tool.sftp_manager
            version_dirs = sftp_manager._parse_and_sort_version_directories(items)
            
            if version_dirs:
                print(f"\nğŸ¯ è­˜åˆ¥åˆ° {len(version_dirs)} å€‹ç‰ˆæœ¬ç›®éŒ„ (æŒ‰ç‰ˆæœ¬è™Ÿå’Œæ™‚é–“æ’åº):")
                for i, ver_info in enumerate(version_dirs):
                    suffix_info = f" (âš ï¸ {ver_info['suffix']})" if ver_info.get('has_suffix') else ""
                    print(f"  {i+1:2d}. {ver_info['dir_name']:<40}{suffix_info}")
                    print(f"      ç‰ˆæœ¬è™Ÿ: {ver_info['version_number']}")
                    print(f"      æ ¼å¼é¡å‹: {ver_info['format_type']}")
                    if ver_info.get('timestamp'):
                        print(f"      æ™‚é–“æˆ³: {ver_info['timestamp']}")
                    modified = datetime.fromtimestamp(ver_info['mtime']).strftime('%Y-%m-%d %H:%M:%S')
                    print(f"      ä¿®æ”¹æ™‚é–“: {modified}")
                    print()
                
                # æ¸¬è©¦ manifest æœå°‹ - æª¢æŸ¥å‰3å€‹ç‰ˆæœ¬
                print(f"ğŸ” æ¸¬è©¦å‰3å€‹ç‰ˆæœ¬çš„ manifest æœå°‹:")
                for idx, ver_info in enumerate(version_dirs[:3]):
                    suffix_note = f" (âš ï¸ æ³¨æ„: {ver_info['suffix']})" if ver_info.get('has_suffix') else ""
                    print(f"\n   ç‰ˆæœ¬ {idx+1}: {ver_info['dir_name']} (ç‰ˆæœ¬è™Ÿ: {ver_info['version_number']}){suffix_note}")
                    
                    version_path = f"{path}/{ver_info['dir_name']}"
                    try:
                        version_files = sftp.listdir(version_path)
                        manifest_files = [f for f in version_files if f.endswith('.xml') and 'manifest' in f.lower()]
                        
                        print(f"     ç‰ˆæœ¬ç›®éŒ„åŒ…å« {len(version_files)} å€‹æª”æ¡ˆ")
                        if manifest_files:
                            print(f"     âœ… æ‰¾åˆ° {len(manifest_files)} å€‹ manifest æª”æ¡ˆ:")
                            for mf in manifest_files:
                                try:
                                    manifest_path = f"{version_path}/{mf}"
                                    file_stat = sftp.stat(manifest_path)
                                    size_kb = file_stat.st_size / 1024
                                    valid = "âœ…" if file_stat.st_size > 100000 else "âš ï¸"
                                    print(f"        {valid} {mf} ({size_kb:.1f} KB)")
                                except:
                                    print(f"        â“ {mf} (ç„¡æ³•å–å¾—å¤§å°)")
                        else:
                            xml_files = [f for f in version_files if f.endswith('.xml')]
                            if xml_files:
                                print(f"     âš ï¸ æœ‰ {len(xml_files)} å€‹ XML æª”æ¡ˆä½†æ²’æœ‰ manifest")
                            else:
                                print(f"     âŒ æ²’æœ‰æ‰¾åˆ° XML æª”æ¡ˆ")
                    
                    except Exception as e:
                        print(f"     âŒ æª¢æŸ¥ç‰ˆæœ¬ç›®éŒ„å…§å®¹å¤±æ•—: {e}")
            
            else:
                print(f"\nâŒ æ²’æœ‰è­˜åˆ¥åˆ°ç‰ˆæœ¬ç›®éŒ„")
                print(f"   æ”¯æ´çš„æ ¼å¼:")
                print(f"   - 206_all_202507100000 (version_all_timestamp)")
                print(f"   - 204_202507081101 (version_timestamp)")  
                print(f"   - 465_all_202502170030_NG_uboot_fail (å¸¶å¾Œç¶´)")
                print(f"   - 466_202502171018_NG_uboot_fail (å¸¶å¾Œç¶´)")
                print(f"   ç›®éŒ„å‘½ååˆ†æ:")
                
                # è©³ç´°åˆ†æç‚ºä»€éº¼æ²’æœ‰è­˜åˆ¥åˆ°
                recognized_count = 0
                for i, item in enumerate(all_dirs[:10]):
                    dir_name = item.filename
                    
                    if re.match(r'^\d+_all_\d{12}', dir_name):
                        recognized_count += 1
                        print(f"   âœ… {dir_name} â†’ ç¬¦åˆ version_all_timestamp æ ¼å¼")
                    elif re.match(r'^\d+_\d{12}', dir_name):
                        recognized_count += 1
                        print(f"   âœ… {dir_name} â†’ ç¬¦åˆ version_timestamp æ ¼å¼")
                    elif re.match(r'^\d+$', dir_name):
                        recognized_count += 1
                        print(f"   âœ… {dir_name} â†’ ç´”æ•¸å­—æ ¼å¼")
                    else:
                        print(f"   âŒ {dir_name} â†’ ä¸ç¬¦åˆæ”¯æ´çš„ç‰ˆæœ¬æ ¼å¼")
                
                if recognized_count > 0:
                    print(f"\nğŸ’¡ å»ºè­°: ç™¼ç¾ {recognized_count} å€‹ç¬¦åˆç‰ˆæœ¬æ ¼å¼çš„ç›®éŒ„")
                    print(f"   é€™äº›æ‡‰è©²æœƒè¢«æ–°çš„è­˜åˆ¥é‚è¼¯æ­£ç¢ºè­˜åˆ¥")
        
        except Exception as e:
            print(f"âŒ åˆ†æç‰ˆæœ¬ç›®éŒ„å¤±æ•—: {e}")
    
    def run_interactive(self):
        """åŸ·è¡Œäº’å‹•å¼ä»‹é¢"""
        print("\næ­¡è¿ä½¿ç”¨ Manifest å®šç‰ˆå·¥å…·ï¼")
        print(f"ç‰ˆæœ¬: {__version__}")
        
        # æª¢æŸ¥æ˜¯å¦æœ‰é è¨­é…ç½®
        has_complete_defaults = all([
            config_manager.default_execution_config.get('mapping_table'),
            os.path.exists(config_manager.default_execution_config.get('mapping_table', ''))
        ])
        
        if has_complete_defaults:
            print("\nğŸ“Œ åµæ¸¬åˆ°å®Œæ•´çš„é è¨­é…ç½®")
            if input("æ˜¯å¦è¦ä½¿ç”¨é è¨­é…ç½®å¿«é€ŸåŸ·è¡Œ? (y/N): ").strip().lower() == 'y':
                self.quick_execute_with_defaults()
                return
        
        while True:
            try:
                choice = self.display_menu()
                
                if choice == '0':
                    print("\nğŸ‘‹ å†è¦‹ï¼")
                    break
                elif choice == '1':
                    self.load_mapping_table()
                elif choice == '2':
                    self.setup_sftp()
                elif choice == '3':
                    self.select_db_type()
                elif choice == '4':
                    self.select_dbs()
                elif choice == '5':
                    self.setup_db_versions()
                elif choice == '6':
                    self.execute_pinning()
                elif choice == '7':
                    self.display_current_settings()
                elif choice == '8':
                    self.quick_execute_with_defaults()
                elif choice == '9':
                    self.setup_advanced_options()
                elif choice == '10':
                    self.test_jira_connection()
                elif choice == '11':
                    self.test_sftp_connection()
                elif choice == '12':
                    self.test_version_detection()
                else:
                    print("âŒ ç„¡æ•ˆçš„é¸æ“‡ï¼Œè«‹é‡æ–°è¼¸å…¥")
                    
            except KeyboardInterrupt:
                print("\n\nâš ï¸ ä½¿ç”¨è€…ä¸­æ–·")
                if input("ç¢ºå®šè¦çµæŸç¨‹å¼å—? (Y/n): ").strip().lower() != 'n':
                    break
            except Exception as e:
                self.logger.error(f"ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
                print(f"âŒ ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
                if input("æ˜¯å¦ç¹¼çºŒ? (Y/n): ").strip().lower() == 'n':
                    break
        
        # æ¸…ç†è³‡æº
        resource_manager.cleanup_all()

# =====================================
# ===== ä¸»ç¨‹å¼ =====
# =====================================

def main():
    """ä¸»ç¨‹å¼å…¥å£ï¼ˆæ”¹å–„ç‰ˆï¼‰"""
    parser = argparse.ArgumentParser(
        description='Manifest å®šç‰ˆå·¥å…· - è‡ªå‹•åŒ– repo å®šç‰ˆè™•ç†',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=f"""
ç‰ˆæœ¬: {__version__}
ä½œè€…: {__author__}
æ—¥æœŸ: {__date__}

ç¯„ä¾‹:
  # ä½¿ç”¨äº’å‹•å¼ä»‹é¢
  python {sys.argv[0]}
  
  # è™•ç†æ‰€æœ‰ DB
  python {sys.argv[0]} -m all_chip_mapping_table.xlsx -o ./output
  
  # è™•ç†æ‰€æœ‰ master é¡å‹çš„ DB
  python {sys.argv[0]} -m all_chip_mapping_table.xlsx -t master -o ./output
  
  # è™•ç†æŒ‡å®šçš„ DB
  python {sys.argv[0]} -m mapping.xlsx -d DB2302,DB2575 -o ./output
  
  # æŒ‡å®š DB ç‰ˆæœ¬
  python {sys.argv[0]} -m mapping.xlsx -d DB2302#3,DB2575#186
  
  # æ¸¬è©¦æ¨¡å¼ï¼ˆä¸å¯¦éš›åŸ·è¡Œï¼‰
  python {sys.argv[0]} -m mapping.xlsx --dry-run
  
  # å•Ÿç”¨ debug æ¨¡å¼
  python {sys.argv[0]} -m mapping.xlsx --debug
        """
    )
    
    # åŸºæœ¬åƒæ•¸
    parser.add_argument('-m', '--mapping', 
                        type=str,
                        help='Mapping table Excel æª”æ¡ˆè·¯å¾‘')
    
    parser.add_argument('-o', '--output', 
                        type=str,
                        help=f'è¼¸å‡ºç›®éŒ„ (é è¨­: {config_manager.path_config["default_output_dir"]})')
    
    parser.add_argument('-t', '--type',
                        choices=['all', 'master', 'premp', 'mp', 'mpbackup'],
                        default='all',
                        help='è¦è™•ç†çš„ DB é¡å‹ (é è¨­: all)')
    
    parser.add_argument('-d', '--dbs', 
                        type=str,
                        help='è¦è™•ç†çš„ DB åˆ—è¡¨ï¼Œé€—è™Ÿåˆ†éš” (å¯åŒ…å«ç‰ˆæœ¬ï¼Œå¦‚: DB2302#3,DB2575)')
    
    parser.add_argument('-v', '--versions', 
                        type=str,
                        help='DB ç‰ˆæœ¬è¨­å®šï¼Œæ ¼å¼: DB2302#3,DB2575#186')
    
    # SFTP è¨­å®šåƒæ•¸
    parser.add_argument('--sftp-host', 
                        type=str,
                        help=f'SFTP ä¼ºæœå™¨ä½å€')
    
    parser.add_argument('--sftp-port', 
                        type=int,
                        help=f'SFTP é€£æ¥åŸ ')
    
    parser.add_argument('--sftp-user', 
                        type=str,
                        help=f'SFTP ä½¿ç”¨è€…åç¨±')
    
    parser.add_argument('--sftp-password', 
                        type=str,
                        help='SFTP å¯†ç¢¼')
    
    parser.add_argument('--sftp-timeout', 
                        type=int,
                        help=f'SFTP é€£ç·šé€¾æ™‚ç§’æ•¸')
    
    # å¹³è¡Œè™•ç†è¨­å®š
    parser.add_argument('--parallel', 
                        type=int,
                        metavar='N',
                        help=f'å¹³è¡Œè™•ç†çš„ worker æ•¸é‡')
    
    parser.add_argument('--no-parallel', 
                        action='store_true',
                        help='é—œé–‰å¹³è¡Œè™•ç†ï¼Œä½¿ç”¨å¾ªåºè™•ç†')
    
    # Repo è¨­å®š
    parser.add_argument('--repo-jobs', 
                        type=int,
                        help=f'repo sync çš„ä¸¦è¡Œæ•¸')
    
    parser.add_argument('--repo-retry', 
                        type=int,
                        help=f'repo sync å¤±æ•—é‡è©¦æ¬¡æ•¸')
    
    # å…¶ä»–é¸é …
    parser.add_argument('--report-name', 
                        type=str,
                        help=f'å ±å‘Šæª”æ¡ˆåç¨±')
    
    parser.add_argument('--dry-run', 
                        action='store_true',
                        help='æ¸¬è©¦æ¨¡å¼ï¼Œåªé¡¯ç¤ºå°‡è¦åŸ·è¡Œçš„å‹•ä½œï¼Œä¸å¯¦éš›åŸ·è¡Œ')
    
    parser.add_argument('--debug', 
                        action='store_true',
                        help='å•Ÿç”¨ debug æ¨¡å¼ï¼Œé¡¯ç¤ºè©³ç´°æ—¥èªŒ')
    
    parser.add_argument('--version', 
                        action='version',
                        version=f'%(prog)s {__version__}')
    
    # è§£æåƒæ•¸
    args = parser.parse_args()
    
    # ===== è¨­å®šæ—¥èªŒç­‰ç´š =====
    if args.debug:
        config_manager.log_config['level'] = logging.DEBUG
        logging.getLogger().setLevel(logging.DEBUG)
        for handler in logging.getLogger().handlers:
            handler.setLevel(logging.DEBUG)
        print("ğŸ” Debug æ¨¡å¼å·²å•Ÿç”¨")
    
    # ===== æ›´æ–°é…ç½® =====
    overrides = {}
    
    if args.sftp_host:
        overrides['sftp_host'] = args.sftp_host
    if args.sftp_port:
        overrides['sftp_port'] = args.sftp_port
    if args.sftp_user:
        overrides['sftp_username'] = args.sftp_user
    if args.sftp_password:
        overrides['sftp_password'] = args.sftp_password
    if args.sftp_timeout:
        overrides['sftp_timeout'] = args.sftp_timeout
    
    if args.no_parallel:
        overrides['parallel_enable_parallel'] = False
    if args.parallel:
        overrides['parallel_max_workers'] = args.parallel
        overrides['parallel_enable_parallel'] = True
    
    if args.repo_jobs:
        overrides['repo_sync_jobs'] = args.repo_jobs
    if args.repo_retry:
        overrides['repo_sync_retry'] = args.repo_retry
    
    if overrides:
        config_manager.apply_overrides(overrides, source='command_line')
    
    if args.report_name:
        config_manager.path_config['report_filename'] = args.report_name
    
    # ===== é©—è­‰é…ç½® =====
    valid, errors = config_manager.validate_config()
    if not valid:
        print("âŒ é…ç½®é©—è­‰å¤±æ•—:")
        for error in errors:
            print(f"  - {error}")
        sys.exit(1)
    
    # ===== æª¢æŸ¥æ˜¯å¦ç‚ºæ¸¬è©¦æ¨¡å¼ =====
    if args.dry_run:
        print("\n" + "="*60)
        print("ğŸ§ª æ¸¬è©¦æ¨¡å¼ (Dry Run) - ä¸æœƒå¯¦éš›åŸ·è¡Œä»»ä½•æ“ä½œ")
        print("="*60)
    
    # ===== æ±ºå®šåŸ·è¡Œæ¨¡å¼ =====
    if args.mapping:
        # å‘½ä»¤åˆ—æ¨¡å¼
        print("\n" + "="*60)
        print(f"ğŸ“‹ Manifest å®šç‰ˆå·¥å…· v{__version__} - å‘½ä»¤åˆ—æ¨¡å¼")
        print("="*60)
        
        # å»ºç«‹å·¥å…·å¯¦ä¾‹
        tool = ManifestPinningTool()
        
        # å¦‚æœæ˜¯æ¸¬è©¦æ¨¡å¼ï¼Œè¨­å®šæ¨™è¨˜
        if args.dry_run:
            tool.dry_run = True
        
        try:
            # Step 1: è¼‰å…¥ mapping table
            print(f"\nğŸ“‚ è¼‰å…¥ mapping table: {args.mapping}")
            if not os.path.exists(args.mapping):
                print(f"âŒ æª”æ¡ˆä¸å­˜åœ¨: {args.mapping}")
                sys.exit(1)
            
            if not tool.load_mapping_table(args.mapping):
                print("âŒ ç„¡æ³•è¼‰å…¥ mapping table")
                sys.exit(1)
            
            print(f"âœ… æˆåŠŸè¼‰å…¥ mapping table")
            
            # Step 2: è¨­å®šè¼¸å‡ºç›®éŒ„
            tool.output_dir = args.output or config_manager.path_config['default_output_dir']
            os.makedirs(tool.output_dir, exist_ok=True)
            print(f"ğŸ“ è¼¸å‡ºç›®éŒ„: {tool.output_dir}")
            
            # Step 3: é€£ç·šåˆ° SFTP
            print(f"\nğŸŒ é€£ç·šåˆ° SFTP ä¼ºæœå™¨: {config_manager.sftp_config['host']}")
            if not tool.sftp_manager.connect():
                print("âŒ ç„¡æ³•é€£ç·šåˆ° SFTP ä¼ºæœå™¨")
                sys.exit(1)
            print("âœ… SFTP é€£ç·šæˆåŠŸ")
            
            try:
                # Step 4: æ±ºå®šè¦è™•ç†çš„ DB åˆ—è¡¨
                db_list = []
                db_versions = {}
                
                if args.dbs:
                    # ä½¿ç”¨æŒ‡å®šçš„ DB
                    db_specs = [db.strip() for db in args.dbs.split(',')]
                    
                    for db_spec in db_specs:
                        if '#' in db_spec:
                            # DB åç¨±åŒ…å«ç‰ˆæœ¬
                            db_name, version = db_spec.split('#', 1)
                            db_list.append(db_name)
                            db_versions[db_name] = version
                        else:
                            db_list.append(db_spec)
                    
                    print(f"\nğŸ“Œ ä½¿ç”¨æŒ‡å®šçš„ DB åˆ—è¡¨: {', '.join(db_list)}")
                else:
                    # ä½¿ç”¨æ‰€æœ‰æŒ‡å®šé¡å‹çš„ DB
                    all_db_infos = tool.get_all_dbs(args.type)
                    db_list = list(set([db.db_info for db in all_db_infos]))
                    
                    if args.type == 'all':
                        print(f"\nğŸ“Œ ä½¿ç”¨æ‰€æœ‰ DBï¼Œå…± {len(db_list)} å€‹")
                    else:
                        print(f"\nğŸ“Œ ä½¿ç”¨æ‰€æœ‰ {args.type} é¡å‹çš„ DBï¼Œå…± {len(db_list)} å€‹")
                
                # Step 5: è™•ç†é¡å¤–çš„ç‰ˆæœ¬è¨­å®š
                if args.versions:
                    version_specs = [v.strip() for v in args.versions.split(',')]
                    for version_spec in version_specs:
                        if '#' in version_spec:
                            db_name, version = version_spec.split('#', 1)
                            db_versions[db_name] = version
                    
                    print(f"ğŸ“Œ è¨­å®šäº† {len(db_versions)} å€‹ DB çš„ç‰ˆæœ¬")
                
                # Step 6: ç¢ºèªè™•ç†è³‡è¨Š
                print("\n" + "-"*40)
                print("ğŸ“‹ æº–å‚™è™•ç†ä»¥ä¸‹ DB:")
                for i, db in enumerate(db_list, 1):
                    version_info = f" (ç‰ˆæœ¬: {db_versions[db]})" if db in db_versions else " (æœ€æ–°ç‰ˆæœ¬)"
                    print(f"  {i:3d}. {db}{version_info}")
                print("-"*40)
                
                if not db_list:
                    print("âŒ æ²’æœ‰æ‰¾åˆ°è¦è™•ç†çš„ DB")
                    sys.exit(1)
                
                # Step 7: è©¢å•ç¢ºèªï¼ˆé™¤éæ˜¯æ¸¬è©¦æ¨¡å¼ï¼‰
                if not args.dry_run:
                    if sys.stdin.isatty():  # æª¢æŸ¥æ˜¯å¦åœ¨äº’å‹•å¼ç’°å¢ƒ
                        confirm = input(f"\nç¢ºèªè¦è™•ç† {len(db_list)} å€‹ DB? (Y/n): ").strip().lower()
                        if confirm == 'n':
                            print("âŒ ä½¿ç”¨è€…å–æ¶ˆæ“ä½œ")
                            sys.exit(0)
                
                # Step 8: é–‹å§‹è™•ç†
                print("\n" + "="*60)
                if args.dry_run:
                    print("ğŸ§ª é–‹å§‹æ¸¬è©¦åŸ·è¡Œï¼ˆä¸æœƒå¯¦éš›åŸ·è¡Œæ“ä½œï¼‰")
                else:
                    print("ğŸš€ é–‹å§‹åŸ·è¡Œå®šç‰ˆè™•ç†")
                print("="*60)
                
                start_time = datetime.now()
                
                # åŸ·è¡Œè™•ç†
                tool.process_selected_dbs(db_list, db_versions)
                
                end_time = datetime.now()
                elapsed_time = end_time - start_time
                
                # Step 9: ç”¢ç”Ÿå ±å‘Š
                if not args.dry_run:
                    print("\nğŸ“Š ç”¢ç”Ÿè™•ç†å ±å‘Š...")
                    report_path = os.path.join(
                        tool.output_dir, 
                        config_manager.path_config['report_filename']
                    )
                    tool.generate_report(report_path)
                
                # Step 10: é¡¯ç¤ºçµæœæ‘˜è¦
                print("\n" + "="*60)
                print("âœ¨ è™•ç†å®Œæˆï¼")
                print("="*60)
                print(f"ğŸ“Š ç¸½ DB æ•¸: {tool.report.total_dbs}")
                print(f"âœ… æˆåŠŸ: {tool.report.successful_dbs}")
                print(f"âŒ å¤±æ•—: {tool.report.failed_dbs}")
                print(f"â­ï¸ è·³é: {tool.report.skipped_dbs}")
                print(f"â±ï¸ ç¸½è€—æ™‚: {elapsed_time}")
                print(f"ğŸ“ è¼¸å‡ºç›®éŒ„: {tool.output_dir}")
                if not args.dry_run:
                    print(f"ğŸ“Š å ±å‘Šæª”æ¡ˆ: {report_path}")
                print("="*60)
                
                # å¦‚æœæœ‰å¤±æ•—çš„é …ç›®ï¼Œé¡¯ç¤ºè©³ç´°è³‡è¨Š
                if tool.report.failed_dbs > 0:
                    print("\nâŒ å¤±æ•—çš„ DB:")
                    for db in tool.report.db_details:
                        if db.status == DBStatus.FAILED:
                            print(f"  - {db.module}/{db.db_info}: {db.error_message}")
                
            finally:
                # ç¢ºä¿é—œé–‰ SFTP é€£ç·š
                print("\nğŸ“Œ é—œé–‰ SFTP é€£ç·š...")
                tool.sftp_manager.disconnect()
                
        except KeyboardInterrupt:
            print("\n\nâš ï¸ ä½¿ç”¨è€…ä¸­æ–·åŸ·è¡Œ")
            sys.exit(130)  # 128 + SIGINT
            
        except Exception as e:
            print(f"\nâŒ ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            if args.debug:
                import traceback
                traceback.print_exc()
            sys.exit(1)
        
        finally:
            # æ¸…ç†æ‰€æœ‰è³‡æº
            resource_manager.cleanup_all()
    
    else:
        # äº’å‹•å¼æ¨¡å¼
        print("\n" + "="*60)
        print(f"ğŸ® Manifest å®šç‰ˆå·¥å…· v{__version__} - äº’å‹•å¼ä»‹é¢")
        print("="*60)
        print("æç¤º: ä½¿ç”¨ -h åƒæ•¸æŸ¥çœ‹å‘½ä»¤åˆ—é¸é …")
        print("="*60)
        
        try:
            # å»ºç«‹ä¸¦åŸ·è¡Œäº’å‹•å¼ä»‹é¢
            ui = InteractiveUI()
            
            # å¦‚æœæœ‰è¨­å®šåƒæ•¸ï¼Œå‚³éçµ¦ UI
            if args.output:
                ui.tool.output_dir = args.output
            
            if args.dry_run:
                ui.tool.dry_run = True
                print("ğŸ§ª æ¸¬è©¦æ¨¡å¼å·²å•Ÿç”¨")
            
            # åŸ·è¡Œäº’å‹•å¼ä»‹é¢
            ui.run_interactive()
            
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ å†è¦‹ï¼")
            sys.exit(0)
            
        except Exception as e:
            print(f"\nâŒ ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            if args.debug:
                import traceback
                traceback.print_exc()
            sys.exit(1)
        
        finally:
            # æ¸…ç†æ‰€æœ‰è³‡æº
            resource_manager.cleanup_all()

if __name__ == "__main__":
    main()