#!/usr/bin/env python3
"""
Manifest Pinning Tool - è‡ªå‹•åŒ–å®šç‰ˆå·¥å…·
ç”¨æ–¼å¾ SFTP ä¸‹è¼‰ manifest æª”æ¡ˆä¸¦åŸ·è¡Œ repo å®šç‰ˆæ“ä½œ

Author: Your Name
Date: 2025-01-17
Version: 1.0.0
"""

import os
import sys
import argparse
import pandas as pd
import paramiko
import subprocess
import json
import re
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
import time
import logging
from dataclasses import dataclass, field, asdict

# =====================================
# ===== ä½¿ç”¨è€…è¨­å®šå€å¡Š =====
# =====================================

# SFTP é€£ç·šè¨­å®š
SFTP_CONFIG = {
    'host': 'mmsftpx.realtek.com',
    'port': 22,
    'username': 'lgwar_user',
    'password': 'Ab!123456',
    'timeout': 30,
    'retry_count': 3,
    'retry_delay': 5  # ç§’
}

# JIRA è¨­å®šï¼ˆç”¨æ–¼å–å¾— source code è³‡è¨Šï¼‰
JIRA_CONFIG = {
    'site': 'jira.realtek.com',
    'username': 'vince_lin',
    'password': 'Amon200!Amon200!',  # è«‹å¡«å…¥å¯†ç¢¼
    'api_url': 'https://jira.realtek.com/rest/api/2'
}

# è·¯å¾‘è¨­å®š
PATH_CONFIG = {
    'default_output_dir': './pinning_output',
    'default_mapping_table': './all_chip_mapping_table.xlsx',
    'manifest_pattern': r'manifest_(\d+)\.xml',  # manifest æª”æ¡ˆå‘½åæ¨¡å¼
    'report_filename': 'pinning_report.xlsx'
}

# Repo æŒ‡ä»¤è¨­å®š
REPO_CONFIG = {
    'repo_command': 'repo',  # repo æŒ‡ä»¤è·¯å¾‘
    'sync_jobs': 8,  # repo sync çš„ä¸¦è¡Œæ•¸
    'sync_retry': 2,  # repo sync å¤±æ•—é‡è©¦æ¬¡æ•¸
    'init_timeout': 60,  # repo init è¶…æ™‚æ™‚é–“ï¼ˆç§’ï¼‰
    'sync_timeout': 3600  # repo sync è¶…æ™‚æ™‚é–“ï¼ˆç§’ï¼‰
}

# å¹³è¡Œè™•ç†è¨­å®š
PARALLEL_CONFIG = {
    'max_workers': 4,  # æœ€å¤§ä¸¦è¡Œè™•ç† DB æ•¸é‡
    'enable_parallel': True,  # æ˜¯å¦å•Ÿç”¨å¹³è¡Œè™•ç†
}

# æ—¥èªŒè¨­å®š
LOG_CONFIG = {
    'level': logging.INFO,
    'format': '%(asctime)s - [%(levelname)s] - %(name)s - %(message)s',
    'date_format': '%Y-%m-%d %H:%M:%S'
}

# =====================================
# ===== è³‡æ–™çµæ§‹å®šç¾© =====
# =====================================

class MappingTableReader:
    """è®€å–å’Œè§£æ mapping table çš„é¡åˆ¥"""
    
    def __init__(self):
        self.logger = setup_logger(self.__class__.__name__)
        self.df = None
        
    def load_excel(self, file_path: str) -> bool:
        """è¼‰å…¥ Excel æª”æ¡ˆ"""
        try:
            self.df = pd.read_excel(file_path)
            self.logger.info(f"æˆåŠŸè¼‰å…¥ {len(self.df)} ç­†è³‡æ–™")
            
            # æª¢æŸ¥å¿…è¦æ¬„ä½
            required_columns = ['SN', 'Module', 'DB_Type', 'DB_Info', 'SftpPath']
            missing_columns = [col for col in required_columns if col not in self.df.columns]
            
            if missing_columns:
                self.logger.error(f"ç¼ºå°‘å¿…è¦æ¬„ä½: {missing_columns}")
                return False
                
            return True
            
        except Exception as e:
            self.logger.error(f"è¼‰å…¥ Excel å¤±æ•—: {str(e)}")
            return False
    
    def get_db_info_list(self, db_type: str = 'all') -> List[DBInfo]:
        """
        å–å¾— DB è³‡è¨Šåˆ—è¡¨
        
        Args:
            db_type: 'all', 'master', 'premp', 'mp', 'mpbackup'
        """
        db_list = []
        
        if self.df is None:
            return db_list
        
        # è™•ç†ä¸åŒçš„ DB é¡å‹
        type_columns = {
            'master': ('DB_Type', 'DB_Info', 'DB_Folder', 'SftpPath'),
            'premp': ('premp_DB_Type', 'premp_DB_Info', 'premp_DB_Folder', 'premp_SftpPath'),
            'mp': ('mp_DB_Type', 'mp_DB_Info', 'mp_DB_Folder', 'mp_SftpPath'),
            'mpbackup': ('mpbackup_DB_Type', 'mpbackup_DB_Info', 'mpbackup_DB_Folder', 'mpbackup_SftpPath')
        }
        
        # é¸æ“‡è¦è™•ç†çš„é¡å‹
        if db_type == 'all':
            types_to_process = type_columns.keys()
        else:
            types_to_process = [db_type] if db_type in type_columns else []
        
        for idx, row in self.df.iterrows():
            for dtype in types_to_process:
                cols = type_columns[dtype]
                
                # æª¢æŸ¥è©²é¡å‹çš„æ¬„ä½æ˜¯å¦å­˜åœ¨ä¸”æœ‰å€¼
                if all(col in row and pd.notna(row[col]) for col in cols[1:2]):  # è‡³å°‘æª¢æŸ¥ DB_Info
                    db_info = DBInfo(
                        sn=row['SN'],
                        module=row['Module'],
                        db_type=dtype,
                        db_info=str(row[cols[1]]),  # DB_Info
                        db_folder=str(row[cols[2]]) if cols[2] in row and pd.notna(row[cols[2]]) else '',
                        sftp_path=str(row[cols[3]]) if cols[3] in row and pd.notna(row[cols[3]]) else ''
                    )
                    db_list.append(db_info)
        
        return db_list
    
    def get_db_by_name(self, db_name: str) -> Optional[DBInfo]:
        """æ ¹æ“š DB åç¨±å–å¾—è³‡è¨Š"""
        all_dbs = self.get_db_info_list('all')
        
        for db in all_dbs:
            if db.db_info == db_name:
                return db
        
        return None
    
@dataclass
class DBInfo:
    """DB è³‡è¨Šè³‡æ–™çµæ§‹ï¼ˆä¿®æ”¹ç‰ˆï¼‰"""
    sn: int
    module: str
    db_type: str  # master, premp, mp, mpbackup
    db_info: str  # DBç·¨è™Ÿï¼Œå¦‚ DB2302
    db_folder: str  # è³‡æ–™å¤¾åç¨±
    sftp_path: str  # å¾ Excel è®€å–çš„å®Œæ•´ SFTP è·¯å¾‘
    version: Optional[str] = None  # ä½¿ç”¨è€…æŒ‡å®šçš„ç‰ˆæœ¬è™Ÿ
    jira_link: Optional[str] = None
    source_command: Optional[str] = None
    manifest_file: Optional[str] = None
    local_path: Optional[str] = None
    status: str = "pending"
    error_message: Optional[str] = None
    start_time: Optional[datetime] = None
    end_time: Optional[datetime] = None
    
    def to_dict(self) -> Dict:
        """è½‰æ›ç‚ºå­—å…¸æ ¼å¼"""
        data = asdict(self)
        # è½‰æ› datetime ç‰©ä»¶ç‚ºå­—ä¸²
        if data['start_time']:
            data['start_time'] = data['start_time'].strftime('%Y-%m-%d %H:%M:%S')
        if data['end_time']:
            data['end_time'] = data['end_time'].strftime('%Y-%m-%d %H:%M:%S')
        return data

@dataclass
class PinningReport:
    """å®šç‰ˆå ±å‘Šè³‡æ–™çµæ§‹"""
    total_dbs: int = 0
    successful_dbs: int = 0
    failed_dbs: int = 0
    skipped_dbs: int = 0
    db_details: List[DBInfo] = field(default_factory=list)
    start_time: datetime = field(default_factory=datetime.now)
    end_time: Optional[datetime] = None
    
    def add_db(self, db_info: DBInfo):
        """æ–°å¢ DB è™•ç†çµæœ"""
        self.db_details.append(db_info)
        if db_info.status == 'success':
            self.successful_dbs += 1
        elif db_info.status == 'failed':
            self.failed_dbs += 1
        elif db_info.status == 'skipped':
            self.skipped_dbs += 1
    
    def finalize(self):
        """å®Œæˆå ±å‘Š"""
        self.end_time = datetime.now()
        self.total_dbs = len(self.db_details)

# =====================================
# ===== æ—¥èªŒè¨­å®š =====
# =====================================

def setup_logger(name: str = __name__) -> logging.Logger:
    """è¨­å®šæ—¥èªŒè¨˜éŒ„å™¨"""
    logger = logging.getLogger(name)
    logger.setLevel(LOG_CONFIG['level'])
    
    if not logger.handlers:
        # Console handler
        console_handler = logging.StreamHandler()
        console_handler.setLevel(LOG_CONFIG['level'])
        
        # Formatter
        formatter = logging.Formatter(
            LOG_CONFIG['format'],
            datefmt=LOG_CONFIG['date_format']
        )
        console_handler.setFormatter(formatter)
        
        logger.addHandler(console_handler)
    
    return logger

logger = setup_logger(__name__)

# =====================================
# ===== SFTP ç®¡ç†é¡åˆ¥ =====
# =====================================

class SFTPManager:
    """SFTP é€£ç·šç®¡ç†å™¨"""
    
    def __init__(self, config: Dict = None):
        self.config = config or SFTP_CONFIG
        self.client = None
        self.sftp = None
        self.logger = setup_logger(self.__class__.__name__)
    
    def connect(self) -> bool:
        """å»ºç«‹ SFTP é€£ç·š"""
        for attempt in range(self.config['retry_count']):
            try:
                self.logger.info(f"å˜—è©¦é€£ç·šåˆ° SFTP ä¼ºæœå™¨ {self.config['host']}...")
                
                self.client = paramiko.SSHClient()
                self.client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
                self.client.connect(
                    hostname=self.config['host'],
                    port=self.config['port'],
                    username=self.config['username'],
                    password=self.config['password'],
                    timeout=self.config['timeout']
                )
                self.sftp = self.client.open_sftp()
                
                self.logger.info("SFTP é€£ç·šæˆåŠŸ")
                return True
                
            except Exception as e:
                self.logger.warning(f"é€£ç·šå¤±æ•— (å˜—è©¦ {attempt + 1}/{self.config['retry_count']}): {str(e)}")
                if attempt < self.config['retry_count'] - 1:
                    time.sleep(self.config['retry_delay'])
                else:
                    self.logger.error("SFTP é€£ç·šå¤±æ•—ï¼Œå·²é”æœ€å¤§é‡è©¦æ¬¡æ•¸")
                    return False
        
        return False
    
    def disconnect(self):
        """é—œé–‰ SFTP é€£ç·š"""
        if self.sftp:
            self.sftp.close()
        if self.client:
            self.client.close()
        self.logger.info("SFTP é€£ç·šå·²é—œé–‰")
    
    def list_manifest_files(self, remote_path: str) -> List[Tuple[str, datetime]]:
        """
        åˆ—å‡ºæŒ‡å®šè·¯å¾‘ä¸‹çš„ manifest æª”æ¡ˆ
        è¿”å›: [(æª”æ¡ˆåç¨±, ä¿®æ”¹æ™‚é–“), ...]
        """
        try:
            files = []
            pattern = re.compile(PATH_CONFIG['manifest_pattern'])
            
            for file_attr in self.sftp.listdir_attr(remote_path):
                if pattern.match(file_attr.filename):
                    mod_time = datetime.fromtimestamp(file_attr.st_mtime)
                    files.append((file_attr.filename, mod_time))
            
            # æŒ‰æ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
            files.sort(key=lambda x: x[1], reverse=True)
            return files
            
        except Exception as e:
            self.logger.error(f"åˆ—å‡º manifest æª”æ¡ˆå¤±æ•—: {str(e)}")
            return []
    
    def get_latest_manifest(self, remote_path: str) -> Optional[str]:
        """å–å¾—æœ€æ–°çš„ manifest æª”æ¡ˆåç¨±"""
        files = self.list_manifest_files(remote_path)
        if files:
            return files[0][0]
        return None
    
    def download_file(self, remote_file: str, local_file: str) -> bool:
        """ä¸‹è¼‰æª”æ¡ˆ"""
        try:
            # ç¢ºä¿æœ¬åœ°ç›®éŒ„å­˜åœ¨
            os.makedirs(os.path.dirname(local_file), exist_ok=True)
            
            self.logger.info(f"ä¸‹è¼‰æª”æ¡ˆ: {remote_file} -> {local_file}")
            self.sftp.get(remote_file, local_file)
            
            self.logger.info(f"æª”æ¡ˆä¸‹è¼‰æˆåŠŸ: {local_file}")
            return True
            
        except Exception as e:
            self.logger.error(f"æª”æ¡ˆä¸‹è¼‰å¤±æ•—: {str(e)}")
            return False

    def list_manifest_files_from_path(self, sftp_path: str) -> List[Tuple[str, datetime]]:
        """
        å¾æŒ‡å®šçš„ SFTP è·¯å¾‘åˆ—å‡º manifest æª”æ¡ˆ
        
        Args:
            sftp_path: å®Œæ•´çš„ SFTP è·¯å¾‘ï¼ˆå¾ Excel çš„ SftpPath æ¬„ä½è®€å–ï¼‰
        """
        try:
            if not sftp_path:
                self.logger.error("SFTP è·¯å¾‘ç‚ºç©º")
                return []
            
            files = []
            pattern = re.compile(PATH_CONFIG['manifest_pattern'])
            
            # ç›´æ¥ä½¿ç”¨ Excel ä¸­çš„å®Œæ•´è·¯å¾‘
            self.logger.info(f"æƒæè·¯å¾‘: {sftp_path}")
            
            # åˆ—å‡ºç›®éŒ„å…§å®¹
            for file_attr in self.sftp.listdir_attr(sftp_path):
                if pattern.match(file_attr.filename):
                    mod_time = datetime.fromtimestamp(file_attr.st_mtime)
                    files.append((file_attr.filename, mod_time))
                    self.logger.debug(f"æ‰¾åˆ° manifest: {file_attr.filename} ({mod_time})")
            
            # æŒ‰æ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
            files.sort(key=lambda x: x[1], reverse=True)
            
            self.logger.info(f"å…±æ‰¾åˆ° {len(files)} å€‹ manifest æª”æ¡ˆ")
            return files
            
        except Exception as e:
            self.logger.error(f"åˆ—å‡º manifest æª”æ¡ˆå¤±æ•— ({sftp_path}): {str(e)}")
            return []

    def get_latest_manifest_from_path(self, sftp_path: str) -> Optional[str]:
        """å¾æŒ‡å®šè·¯å¾‘å–å¾—æœ€æ–°çš„ manifest æª”æ¡ˆåç¨±"""
        files = self.list_manifest_files_from_path(sftp_path)
        if files:
            return files[0][0]
        return None
    
    def download_manifest(self, sftp_path: str, manifest_file: str, local_file: str) -> bool:
        """
        ä¸‹è¼‰ manifest æª”æ¡ˆ
        
        Args:
            sftp_path: SFTP åŸºç¤è·¯å¾‘
            manifest_file: manifest æª”æ¡ˆåç¨±
            local_file: æœ¬åœ°å„²å­˜è·¯å¾‘
        """
        try:
            remote_file = f"{sftp_path}/{manifest_file}"
            return self.download_file(remote_file, local_file)
        except Exception as e:
            self.logger.error(f"ä¸‹è¼‰ manifest å¤±æ•—: {str(e)}")
            return False
                
# =====================================
# ===== JIRA ç®¡ç†é¡åˆ¥ =====
# =====================================

class JiraManager:
    """JIRA ç®¡ç†å™¨ï¼ˆç°¡åŒ–ç‰ˆï¼‰"""
    
    def __init__(self):
        self.logger = setup_logger(self.__class__.__name__)
    
    def get_source_info(self, db_name: str, mapping_df: pd.DataFrame) -> Optional[str]:
        """
        å¾ mapping table å–å¾— source code è³‡è¨Š
        é€™è£¡ç°¡åŒ–è™•ç†ï¼Œå¯¦éš›æ‡‰è©²è¦å¾ JIRA API å–å¾—
        """
        try:
            # å°‹æ‰¾å°æ‡‰çš„ DB
            for col in ['DB_Info', 'premp_DB_Info', 'mp_DB_Info', 'mpbackup_DB_Info']:
                if col in mapping_df.columns:
                    mask = mapping_df[col] == db_name
                    if mask.any():
                        row = mapping_df[mask].iloc[0]
                        
                        # é€™è£¡æ‡‰è©²è¦å‘¼å« JIRA API
                        # ç›®å‰å…ˆå›å‚³ç¯„ä¾‹æŒ‡ä»¤
                        return f"repo init -u ssh://mm2sd.rtkbf.com:29418/realtek/android/manifest -b realtek/android-14/master -m atv-google-refplus-wave.xml"
            
            return None
            
        except Exception as e:
            self.logger.error(f"å–å¾— source info å¤±æ•—: {str(e)}")
            return None

# =====================================
# ===== Repo ç®¡ç†é¡åˆ¥ =====
# =====================================

class RepoManager:
    """Repo æŒ‡ä»¤ç®¡ç†å™¨"""
    
    def __init__(self):
        self.logger = setup_logger(self.__class__.__name__)
        self.lock = threading.Lock()
    
    def run_command(self, cmd: str, cwd: str = None, timeout: int = None) -> Tuple[bool, str]:
        """
        åŸ·è¡Œ shell æŒ‡ä»¤
        è¿”å›: (æˆåŠŸèˆ‡å¦, è¼¸å‡ºè¨Šæ¯)
        """
        try:
            self.logger.debug(f"åŸ·è¡ŒæŒ‡ä»¤: {cmd}")
            self.logger.debug(f"å·¥ä½œç›®éŒ„: {cwd}")
            
            result = subprocess.run(
                cmd,
                shell=True,
                cwd=cwd,
                capture_output=True,
                text=True,
                timeout=timeout
            )
            
            if result.returncode == 0:
                return True, result.stdout
            else:
                return False, result.stderr
                
        except subprocess.TimeoutExpired:
            self.logger.error(f"æŒ‡ä»¤åŸ·è¡Œè¶…æ™‚: {cmd}")
            return False, "Command timeout"
        except Exception as e:
            self.logger.error(f"æŒ‡ä»¤åŸ·è¡Œå¤±æ•—: {str(e)}")
            return False, str(e)
    
    def repo_init(self, work_dir: str, init_cmd: str) -> bool:
        """åŸ·è¡Œ repo init"""
        success, output = self.run_command(
            init_cmd,
            cwd=work_dir,
            timeout=REPO_CONFIG['init_timeout']
        )
        
        if success:
            self.logger.info(f"Repo init æˆåŠŸ: {work_dir}")
        else:
            self.logger.error(f"Repo init å¤±æ•—: {work_dir}\n{output}")
        
        return success
    
    def repo_sync(self, work_dir: str) -> bool:
        """åŸ·è¡Œ repo sync"""
        cmd = f"{REPO_CONFIG['repo_command']} sync -j{REPO_CONFIG['sync_jobs']}"
        
        for attempt in range(REPO_CONFIG['sync_retry']):
            self.logger.info(f"åŸ·è¡Œ repo sync (å˜—è©¦ {attempt + 1}/{REPO_CONFIG['sync_retry']}): {work_dir}")
            
            success, output = self.run_command(
                cmd,
                cwd=work_dir,
                timeout=REPO_CONFIG['sync_timeout']
            )
            
            if success:
                self.logger.info(f"Repo sync æˆåŠŸ: {work_dir}")
                return True
            else:
                self.logger.warning(f"Repo sync å¤±æ•— (å˜—è©¦ {attempt + 1}): {work_dir}")
                if attempt < REPO_CONFIG['sync_retry'] - 1:
                    time.sleep(10)
        
        self.logger.error(f"Repo sync å¤±æ•—ï¼Œå·²é”æœ€å¤§é‡è©¦æ¬¡æ•¸: {work_dir}")
        return False
    
    def pin_manifest(self, work_dir: str, manifest_file: str) -> bool:
        """åŸ·è¡Œå®šç‰ˆ"""
        try:
            # è¤‡è£½ manifest æª”æ¡ˆåˆ° .repo/manifests
            manifest_dir = os.path.join(work_dir, '.repo', 'manifests')
            if not os.path.exists(manifest_dir):
                self.logger.error(f"Manifest ç›®éŒ„ä¸å­˜åœ¨: {manifest_dir}")
                return False
            
            import shutil
            dest_file = os.path.join(manifest_dir, os.path.basename(manifest_file))
            shutil.copy2(manifest_file, dest_file)
            self.logger.info(f"è¤‡è£½ manifest æª”æ¡ˆ: {manifest_file} -> {dest_file}")
            
            # åŸ·è¡Œ repo init -m manifest_xxx.xml
            cmd = f"{REPO_CONFIG['repo_command']} init -m {os.path.basename(manifest_file)}"
            success, output = self.run_command(cmd, cwd=work_dir, timeout=REPO_CONFIG['init_timeout'])
            
            if not success:
                self.logger.error(f"å®šç‰ˆ init å¤±æ•—: {work_dir}")
                return False
            
            # åŸ·è¡Œ repo sync
            return self.repo_sync(work_dir)
            
        except Exception as e:
            self.logger.error(f"å®šç‰ˆå¤±æ•—: {str(e)}")
            return False
    
    def export_manifest(self, work_dir: str, output_file: str = "vp_manifest.xml") -> bool:
        """å°å‡ºå®šç‰ˆçµæœ"""
        cmd = f"{REPO_CONFIG['repo_command']} manifest -r -o {output_file}"
        success, output = self.run_command(cmd, cwd=work_dir, timeout=60)
        
        if success:
            self.logger.info(f"æˆåŠŸå°å‡º manifest: {os.path.join(work_dir, output_file)}")
        else:
            self.logger.error(f"å°å‡º manifest å¤±æ•—: {work_dir}")
        
        return success

# =====================================
# ===== ä¸»è¦è™•ç†é¡åˆ¥ =====
# =====================================

class ManifestPinningTool:
    """Manifest å®šç‰ˆå·¥å…·ä¸»é¡åˆ¥"""
    
    def __init__(self):
        self.logger = setup_logger(self.__class__.__name__)
        self.sftp_manager = SFTPManager()
        self.repo_manager = RepoManager()
        self.mapping_reader = MappingTableReader()  # æ–°å¢
        self.report = PinningReport()
        self.output_dir = PATH_CONFIG['default_output_dir']
    
    def load_mapping_table(self, file_path: str) -> bool:
        """è¼‰å…¥ mapping table"""
        return self.mapping_reader.load_excel(file_path)
    
    def get_all_dbs(self, db_type: str = 'all') -> List[DBInfo]:
        """å–å¾—æ‰€æœ‰ DB è³‡è¨Š"""
        return self.mapping_reader.get_db_info_list(db_type)
    
    def parse_db_version(self, db_spec: str) -> Tuple[str, Optional[str]]:
        """
        è§£æ DB ç‰ˆæœ¬è¦æ ¼
        è¼¸å…¥: "DB2302#3" æˆ– "DB2302"
        è¿”å›: (db_name, version)
        """
        if '#' in db_spec:
            parts = db_spec.split('#')
            return parts[0], parts[1]
        return db_spec, None
    
    def process_db(self, db_info: DBInfo) -> DBInfo:
        """è™•ç†å–®ä¸€ DB çš„å®šç‰ˆ"""
        db_info.start_time = datetime.now()
        
        try:
            self.logger.info(f"é–‹å§‹è™•ç† {db_info.module}/{db_info.db_info} (é¡å‹: {db_info.db_type})")
            
            # å»ºç«‹æœ¬åœ°ç›®éŒ„
            local_path = os.path.join(self.output_dir, db_info.module, db_info.db_info)
            os.makedirs(local_path, exist_ok=True)
            db_info.local_path = local_path
            
            # ä½¿ç”¨ Excel ä¸­çš„ SFTP è·¯å¾‘
            if not db_info.sftp_path:
                raise Exception("Excel ä¸­æœªå®šç¾© SFTP è·¯å¾‘")
            
            self.logger.info(f"ä½¿ç”¨ SFTP è·¯å¾‘: {db_info.sftp_path}")
            
            # ç¢ºå®šè¦ä¸‹è¼‰çš„ manifest æª”æ¡ˆ
            if db_info.version:
                manifest_file = f"manifest_{db_info.version}.xml"
                self.logger.info(f"ä½¿ç”¨æŒ‡å®šç‰ˆæœ¬: {manifest_file}")
            else:
                # å–å¾—æœ€æ–°ç‰ˆæœ¬
                manifest_file = self.sftp_manager.get_latest_manifest_from_path(db_info.sftp_path)
                if not manifest_file:
                    raise Exception(f"åœ¨ {db_info.sftp_path} æ‰¾ä¸åˆ° manifest æª”æ¡ˆ")
                
                # å¾æª”åæå–ç‰ˆæœ¬è™Ÿ
                match = re.match(PATH_CONFIG['manifest_pattern'], manifest_file)
                if match:
                    db_info.version = match.group(1)
                
                self.logger.info(f"ä½¿ç”¨æœ€æ–°ç‰ˆæœ¬: {manifest_file}")
            
            db_info.manifest_file = manifest_file
            
            # Step 3: ä¸‹è¼‰ manifest æª”æ¡ˆ
            local_manifest = os.path.join(local_path, manifest_file)
            if not self.sftp_manager.download_manifest(db_info.sftp_path, manifest_file, local_manifest):
                raise Exception("ä¸‹è¼‰ manifest æª”æ¡ˆå¤±æ•—")
            
            # Step 4: å¾ DB_Folder æˆ–å…¶ä»–ä¾†æºå–å¾— repo init æŒ‡ä»¤
            # é€™è£¡éœ€è¦æ ¹æ“šæ‚¨çš„å¯¦éš›éœ€æ±‚ä¾†æ±ºå®šå¦‚ä½•å–å¾— source command
            # å¯èƒ½éœ€è¦å¾ JIRA æˆ–å…¶ä»–åœ°æ–¹å–å¾—
            source_cmd = self.get_source_command(db_info)
            if not source_cmd:
                raise Exception("ç„¡æ³•å–å¾— source command")
            db_info.source_command = source_cmd
            
            # Step 5: åŸ·è¡Œ repo init å’Œ sync
            if not self.repo_manager.repo_init(local_path, source_cmd):
                raise Exception("Repo init å¤±æ•—")
            
            if not self.repo_manager.repo_sync(local_path):
                raise Exception("Repo sync å¤±æ•—")
            
            # Step 6: åŸ·è¡Œå®šç‰ˆ
            if not self.repo_manager.pin_manifest(local_path, local_manifest):
                raise Exception("å®šç‰ˆå¤±æ•—")
            
            # Step 7: å°å‡ºå®šç‰ˆçµæœ
            if not self.repo_manager.export_manifest(local_path):
                raise Exception("å°å‡º manifest å¤±æ•—")
            
            db_info.status = "success"
            self.logger.info(f"âœ… æˆåŠŸå®Œæˆ {db_info.module}/{db_info.db_info} çš„å®šç‰ˆ")
            
        except Exception as e:
            db_info.status = "failed"
            db_info.error_message = str(e)
            self.logger.error(f"âŒ è™•ç† {db_info.module}/{db_info.db_info} å¤±æ•—: {str(e)}")
        
        finally:
            db_info.end_time = datetime.now()
        
        return db_info

    def get_source_command(self, db_info: DBInfo) -> Optional[str]:
        """
        å–å¾— repo init çš„ source command
        é€™å€‹æ–¹æ³•éœ€è¦æ ¹æ“šæ‚¨çš„å¯¦éš›éœ€æ±‚ä¾†å¯¦ä½œ
        """
        # æ–¹æ³•1: å¾ DB_Folder è§£æ
        # ä¾‹å¦‚: DB2302_Merlin7_32Bit_FW_Android14_Ref_Plus_GoogleGMS
        # å¯èƒ½å°æ‡‰åˆ°: repo init -u ssh://mm2sd.rtkbf.com:29418/realtek/android/manifest -b realtek/android-14/master -m xxx.xml
        
        # æ–¹æ³•2: å¾ JIRA å–å¾—ï¼ˆéœ€è¦å¯¦ä½œ JIRA API å‘¼å«ï¼‰
        
        # é€™è£¡å…ˆå›å‚³ä¸€å€‹ç¯„ä¾‹
        return "repo init -u ssh://mm2sd.rtkbf.com:29418/realtek/android/manifest -b realtek/android-14/master -m atv-google-refplus-wave.xml"
    
    def process_selected_dbs(self, db_list: List[str], db_versions: Dict[str, str] = None) -> None:
        """è™•ç†é¸å®šçš„ DB åˆ—è¡¨"""
        db_versions = db_versions or {}
        db_infos_to_process = []
        
        # å–å¾—æ‰€æœ‰ DB è³‡è¨Š
        all_db_infos = self.get_all_dbs('all')
        
        # ç¯©é¸è¦è™•ç†çš„ DB
        for db_name in db_list:
            # è§£æ DB åç¨±å’Œç‰ˆæœ¬
            if '#' in db_name:
                db_name, version = db_name.split('#')
            else:
                version = db_versions.get(db_name)
            
            # å°‹æ‰¾å°æ‡‰çš„ DB è³‡è¨Š
            for db_info in all_db_infos:
                if db_info.db_info == db_name:
                    db_info.version = version
                    db_infos_to_process.append(db_info)
                    break
        
        self.logger.info(f"æº–å‚™è™•ç† {len(db_infos_to_process)} å€‹ DB")
        
        # å¹³è¡Œè™•ç†
        if PARALLEL_CONFIG['enable_parallel']:
            self._process_parallel(db_infos_to_process)
        else:
            self._process_sequential(db_infos_to_process)

    def _process_parallel(self, db_infos: List[DBInfo]):
        """å¹³è¡Œè™•ç† DB åˆ—è¡¨"""
        self.logger.info(f"ä½¿ç”¨å¹³è¡Œè™•ç†ï¼Œæœ€å¤§ worker æ•¸: {PARALLEL_CONFIG['max_workers']}")
        
        with ThreadPoolExecutor(max_workers=PARALLEL_CONFIG['max_workers']) as executor:
            futures = {executor.submit(self.process_db, db_info): db_info for db_info in db_infos}
            
            for future in as_completed(futures):
                db_info = futures[future]
                try:
                    result = future.result()
                    self.report.add_db(result)
                except Exception as e:
                    self.logger.error(f"è™•ç† {db_info.db_info} æ™‚ç™¼ç”Ÿç•°å¸¸: {str(e)}")
                    db_info.status = "failed"
                    db_info.error_message = str(e)
                    self.report.add_db(db_info)
    
    def _process_sequential(self, db_infos: List[DBInfo]):
        """å¾ªåºè™•ç† DB åˆ—è¡¨"""
        self.logger.info("ä½¿ç”¨å¾ªåºè™•ç†")
        for db_info in db_infos:
            result = self.process_db(db_info)
            self.report.add_db(result)

    def process_dbs_parallel(self, db_list: List[str], db_versions: Dict[str, str] = None) -> None:
        """å¹³è¡Œè™•ç†å¤šå€‹ DB"""
        db_versions = db_versions or {}
        db_infos = []
        
        # æº–å‚™ DB è³‡è¨Š
        for db_spec in db_list:
            db_name, version = self.parse_db_version(db_spec)
            
            # å¦‚æœæ²’æœ‰æŒ‡å®šç‰ˆæœ¬ï¼Œä½¿ç”¨ db_versions ä¸­çš„è¨­å®š
            if not version and db_name in db_versions:
                version = db_versions[db_name]
            
            # æ‰¾å‡º module åç¨±
            module = self.get_module_for_db(db_name)
            if not module:
                self.logger.warning(f"æ‰¾ä¸åˆ° {db_name} çš„ moduleï¼Œè·³é")
                continue
            
            db_info = DBInfo(
                module=module,
                db_name=db_name,
                version=version
            )
            db_infos.append(db_info)
        
        # å¹³è¡Œè™•ç†
        if PARALLEL_CONFIG['enable_parallel']:
            self.logger.info(f"ä½¿ç”¨å¹³è¡Œè™•ç†ï¼Œæœ€å¤§ worker æ•¸: {PARALLEL_CONFIG['max_workers']}")
            
            with ThreadPoolExecutor(max_workers=PARALLEL_CONFIG['max_workers']) as executor:
                futures = {executor.submit(self.process_db, db_info): db_info for db_info in db_infos}
                
                for future in as_completed(futures):
                    db_info = futures[future]
                    try:
                        result = future.result()
                        self.report.add_db(result)
                    except Exception as e:
                        self.logger.error(f"è™•ç† {db_info.db_name} æ™‚ç™¼ç”Ÿç•°å¸¸: {str(e)}")
                        db_info.status = "failed"
                        db_info.error_message = str(e)
                        self.report.add_db(db_info)
        else:
            # å¾ªåºè™•ç†
            self.logger.info("ä½¿ç”¨å¾ªåºè™•ç†")
            for db_info in db_infos:
                result = self.process_db(db_info)
                self.report.add_db(result)
    
    def get_module_for_db(self, db_name: str) -> Optional[str]:
        """æ‰¾å‡º DB å°æ‡‰çš„ module"""
        if self.mapping_df is None:
            return None
        
        for col in ['DB_Info', 'premp_DB_Info', 'mp_DB_Info', 'mpbackup_DB_Info']:
            if col in self.mapping_df.columns:
                mask = self.mapping_df[col] == db_name
                if mask.any():
                    return self.mapping_df[mask].iloc[0]['Module']
        
        return None
    
    def generate_report(self, output_file: str = None) -> None:
        """ç”¢ç”Ÿå ±å‘Š"""
        self.report.finalize()
        
        if not output_file:
            output_file = os.path.join(self.output_dir, PATH_CONFIG['report_filename'])
        
        try:
            # å»ºç«‹å ±å‘Š DataFrame
            report_data = []
            for db in self.report.db_details:
                report_data.append(db.to_dict())
            
            df = pd.DataFrame(report_data)
            
            # å»ºç«‹æ‘˜è¦è³‡è¨Š
            summary = {
                'é …ç›®': ['ç¸½ DB æ•¸', 'æˆåŠŸ', 'å¤±æ•—', 'è·³é', 'é–‹å§‹æ™‚é–“', 'çµæŸæ™‚é–“', 'ç¸½è€—æ™‚'],
                'æ•¸å€¼': [
                    self.report.total_dbs,
                    self.report.successful_dbs,
                    self.report.failed_dbs,
                    self.report.skipped_dbs,
                    self.report.start_time.strftime('%Y-%m-%d %H:%M:%S'),
                    self.report.end_time.strftime('%Y-%m-%d %H:%M:%S') if self.report.end_time else 'N/A',
                    str(self.report.end_time - self.report.start_time) if self.report.end_time else 'N/A'
                ]
            }
            summary_df = pd.DataFrame(summary)
            
            # å¯«å…¥ Excel
            with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
                summary_df.to_excel(writer, sheet_name='æ‘˜è¦', index=False)
                df.to_excel(writer, sheet_name='è©³ç´°è³‡è¨Š', index=False)
            
            self.logger.info(f"å ±å‘Šå·²ç”¢ç”Ÿ: {output_file}")
            
            # é¡¯ç¤ºæ‘˜è¦
            print("\n" + "="*60)
            print("å®šç‰ˆè™•ç†çµæœæ‘˜è¦")
            print("="*60)
            for item, value in zip(summary['é …ç›®'], summary['æ•¸å€¼']):
                print(f"{item}: {value}")
            print("="*60)
            
        except Exception as e:
            self.logger.error(f"ç”¢ç”Ÿå ±å‘Šå¤±æ•—: {str(e)}")
    
    def run(self, args: argparse.Namespace) -> None:
        """åŸ·è¡Œä¸»æµç¨‹"""
        try:
            # è¨­å®šè¼¸å‡ºç›®éŒ„
            self.output_dir = args.output or PATH_CONFIG['default_output_dir']
            os.makedirs(self.output_dir, exist_ok=True)
            
            # è¼‰å…¥ mapping table
            mapping_file = args.mapping or PATH_CONFIG['default_mapping_table']
            if not self.load_mapping_table(mapping_file):
                raise Exception("ç„¡æ³•è¼‰å…¥ mapping table")
            
            # é€£ç·šåˆ° SFTP
            if not self.sftp_manager.connect():
                raise Exception("ç„¡æ³•é€£ç·šåˆ° SFTP")
            
            # æ±ºå®šè¦è™•ç†çš„ DB åˆ—è¡¨
            if args.dbs:
                # ä½¿ç”¨æŒ‡å®šçš„ DB
                db_list = args.dbs.split(',')
            else:
                # ä½¿ç”¨æ‰€æœ‰ DB
                db_list = self.get_all_dbs()
            
            self.logger.info(f"æº–å‚™è™•ç† {len(db_list)} å€‹ DB")
            
            # è™•ç† DB ç‰ˆæœ¬è¨­å®š
            db_versions = {}
            if args.versions:
                for item in args.versions.split(','):
                    if '#' in item:
                        db, ver = item.split('#')
                        db_versions[db] = ver
            
            # é–‹å§‹è™•ç†
            self.process_dbs_parallel(db_list, db_versions)
            
            # ç”¢ç”Ÿå ±å‘Š
            self.generate_report()
            
        except Exception as e:
            self.logger.error(f"åŸ·è¡Œå¤±æ•—: {str(e)}")
            
        finally:
            # é—œé–‰ SFTP é€£ç·š
            self.sftp_manager.disconnect()

# =====================================
# ===== äº’å‹•å¼ä»‹é¢ =====
# =====================================

class InteractiveUI:
    """äº’å‹•å¼ä½¿ç”¨è€…ä»‹é¢"""
    
    def __init__(self):
        self.tool = ManifestPinningTool()
        self.logger = setup_logger(self.__class__.__name__)
        self.selected_dbs = []
        self.db_versions = {}
    
    def display_menu(self) -> str:
        """é¡¯ç¤ºä¸»é¸å–®"""
        print("\n" + "="*60)
        print("Manifest å®šç‰ˆå·¥å…· - ä¸»é¸å–®")
        print("="*60)
        print("1. è¼‰å…¥ mapping table")
        print("2. è¨­å®š SFTP é€£ç·šè³‡è¨Š")
        print("3. é¸æ“‡ DB é¡å‹ (master/premp/mp/mpbackup/all)")
        print("4. é¸æ“‡è¦å®šç‰ˆçš„ DB")
        print("5. è¨­å®š DB ç‰ˆæœ¬")
        print("6. é–‹å§‹åŸ·è¡Œå®šç‰ˆ")
        print("7. é¡¯ç¤ºç›®å‰è¨­å®š")
        print("0. çµæŸç¨‹å¼")
        print("="*60)
        
        return input("è«‹é¸æ“‡åŠŸèƒ½: ").strip()

    def select_db_type(self) -> str:
        """é¸æ“‡ DB é¡å‹"""
        print("\né¸æ“‡ DB é¡å‹:")
        print("1. All (æ‰€æœ‰é¡å‹)")
        print("2. Master")
        print("3. PreMP")
        print("4. MP")
        print("5. MP Backup")
        
        choice = input("è«‹é¸æ“‡: ").strip()
        
        type_map = {
            '1': 'all',
            '2': 'master',
            '3': 'premp',
            '4': 'mp',
            '5': 'mpbackup'
        }
        
        return type_map.get(choice, 'all')
        
    def load_mapping_table(self):
        """è¼‰å…¥ mapping table"""
        file_path = input(f"è«‹è¼¸å…¥ mapping table è·¯å¾‘ [{PATH_CONFIG['default_mapping_table']}]: ").strip()
        if not file_path:
            file_path = PATH_CONFIG['default_mapping_table']
        
        if self.tool.load_mapping_table(file_path):
            print(f"âœ… æˆåŠŸè¼‰å…¥ mapping tableï¼Œå…± {len(self.tool.mapping_df)} ç­†è³‡æ–™")
            all_dbs = self.tool.get_all_dbs()
            print(f"   æ‰¾åˆ° {len(all_dbs)} å€‹ DB")
        else:
            print("âŒ è¼‰å…¥å¤±æ•—")
    
    def setup_sftp(self):
        """è¨­å®š SFTP é€£ç·šè³‡è¨Š"""
        print("\nç›®å‰ SFTP è¨­å®š:")
        print(f"  Host: {SFTP_CONFIG['host']}")
        print(f"  Port: {SFTP_CONFIG['port']}")
        print(f"  Username: {SFTP_CONFIG['username']}")
        
        if input("\næ˜¯å¦è¦ä¿®æ”¹è¨­å®š? (y/N): ").strip().lower() == 'y':
            SFTP_CONFIG['host'] = input(f"Host [{SFTP_CONFIG['host']}]: ").strip() or SFTP_CONFIG['host']
            SFTP_CONFIG['port'] = int(input(f"Port [{SFTP_CONFIG['port']}]: ").strip() or SFTP_CONFIG['port'])
            SFTP_CONFIG['username'] = input(f"Username [{SFTP_CONFIG['username']}]: ").strip() or SFTP_CONFIG['username']
            password = input("Password (ç•™ç©ºä¿æŒåŸå€¼): ").strip()
            if password:
                SFTP_CONFIG['password'] = password
            
            print("âœ… SFTP è¨­å®šå·²æ›´æ–°")
    
    def select_dbs(self, db_type: str = 'all') -> List[str]:
        """é¸æ“‡è¦å®šç‰ˆçš„ DB"""
        if not self.tool.mapping_reader.df:
            print("âŒ è«‹å…ˆè¼‰å…¥ mapping table")
            return []
        
        all_db_infos = self.tool.get_all_dbs(db_type)
        unique_dbs = list(set([db.db_info for db in all_db_infos]))
        
        print(f"\næ‰¾åˆ° {len(unique_dbs)} å€‹ä¸é‡è¤‡çš„ DB (é¡å‹: {db_type})")
        
        # é¡¯ç¤º DB åˆ—è¡¨
        for i, db in enumerate(unique_dbs, 1):
            print(f"{i:3d}. {db}")
        
        print("\né¸æ“‡æ–¹å¼:")
        print("1. å…¨é¸")
        print("2. è¼¸å…¥ DB ç·¨è™Ÿåˆ—è¡¨ (é€—è™Ÿåˆ†éš”)")
        print("3. è¼¸å…¥ DB åç¨±åˆ—è¡¨ (é€—è™Ÿåˆ†éš”)")
        
        choice = input("è«‹é¸æ“‡: ").strip()
        
        if choice == '1':
            return unique_dbs
        elif choice == '2':
            indices = input("è«‹è¼¸å…¥ç·¨è™Ÿ (å¦‚: 1,3,5): ").strip()
            selected = []
            for idx_str in indices.split(','):
                try:
                    idx = int(idx_str.strip()) - 1
                    if 0 <= idx < len(unique_dbs):
                        selected.append(unique_dbs[idx])
                except:
                    pass
            return selected
        elif choice == '3':
            db_names = input("è«‹è¼¸å…¥ DB åç¨± (å¦‚: DB2302,DB2575): ").strip()
            return [db.strip() for db in db_names.split(',')]
        else:
            return []
    
    def setup_db_versions(self, db_list: List[str]) -> Dict[str, str]:
        """è¨­å®š DB ç‰ˆæœ¬"""
        versions = {}
        
        print("\nè¨­å®š DB ç‰ˆæœ¬ (ç•™ç©ºä½¿ç”¨æœ€æ–°ç‰ˆæœ¬)")
        for db in db_list:
            version = input(f"{db} çš„ç‰ˆæœ¬ [æœ€æ–°]: ").strip()
            if version:
                versions[db] = version
        
        return versions
    
    def run_interactive(self):
        """åŸ·è¡Œäº’å‹•å¼ä»‹é¢"""
        db_list = []
        db_versions = {}
        
        while True:
            choice = self.display_menu()
            
            if choice == '0':
                print("çµæŸç¨‹å¼")
                break
            elif choice == '1':
                self.load_mapping_table()
            elif choice == '2':
                self.setup_sftp()
            elif choice == '3':
                db_list = self.select_dbs()
                print(f"å·²é¸æ“‡ {len(db_list)} å€‹ DB")
            elif choice == '4':
                if db_list:
                    db_versions = self.setup_db_versions(db_list)
                else:
                    print("è«‹å…ˆé¸æ“‡ DB")
            elif choice == '5':
                if not db_list:
                    print("âŒ è«‹å…ˆé¸æ“‡è¦å®šç‰ˆçš„ DB")
                    continue
                
                output_dir = input(f"è¼¸å‡ºç›®éŒ„ [{PATH_CONFIG['default_output_dir']}]: ").strip()
                if not output_dir:
                    output_dir = PATH_CONFIG['default_output_dir']
                
                self.tool.output_dir = output_dir
                
                print("\né–‹å§‹åŸ·è¡Œå®šç‰ˆ...")
                print(f"  DB æ•¸é‡: {len(db_list)}")
                print(f"  è¼¸å‡ºç›®éŒ„: {output_dir}")
                
                if input("\nç¢ºèªé–‹å§‹åŸ·è¡Œ? (Y/n): ").strip().lower() != 'n':
                    # é€£ç·š SFTP
                    if self.tool.sftp_manager.connect():
                        self.tool.process_dbs_parallel(db_list, db_versions)
                        self.tool.generate_report()
                        self.tool.sftp_manager.disconnect()
                    else:
                        print("âŒ SFTP é€£ç·šå¤±æ•—")
            elif choice == '6':
                print("\nç›®å‰è¨­å®š:")
                print(f"  Mapping table: {'å·²è¼‰å…¥' if self.tool.mapping_df is not None else 'æœªè¼‰å…¥'}")
                print(f"  é¸æ“‡çš„ DB: {len(db_list)} å€‹")
                print(f"  è¨­å®šç‰ˆæœ¬çš„ DB: {len(db_versions)} å€‹")
                print(f"  è¼¸å‡ºç›®éŒ„: {self.tool.output_dir}")
            else:
                print("ç„¡æ•ˆçš„é¸æ“‡")

# =====================================
# ===== ä¸»ç¨‹å¼ =====
# =====================================

def main():
    """ä¸»ç¨‹å¼å…¥å£ï¼ˆå®Œæ•´ç‰ˆï¼‰"""
    parser = argparse.ArgumentParser(
        description='Manifest å®šç‰ˆå·¥å…· - è‡ªå‹•åŒ– repo å®šç‰ˆè™•ç†',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¯„ä¾‹:
  # ä½¿ç”¨äº’å‹•å¼ä»‹é¢
  python manifest_pinning_tool.py
  
  # è™•ç†æ‰€æœ‰ DB
  python manifest_pinning_tool.py -m all_chip_mapping_table.xlsx -o ./output
  
  # è™•ç†æ‰€æœ‰ master é¡å‹çš„ DB
  python manifest_pinning_tool.py -m all_chip_mapping_table.xlsx -t master -o ./output
  
  # è™•ç†æŒ‡å®šçš„ DB
  python manifest_pinning_tool.py -m mapping.xlsx -d DB2302,DB2575 -o ./output
  
  # æŒ‡å®š DB ç‰ˆæœ¬ï¼ˆæ–¹å¼1ï¼šåœ¨ DB åç¨±å¾ŒåŠ ç‰ˆæœ¬ï¼‰
  python manifest_pinning_tool.py -m mapping.xlsx -d DB2302#3,DB2575#186
  
  # æŒ‡å®š DB ç‰ˆæœ¬ï¼ˆæ–¹å¼2ï¼šä½¿ç”¨ -v åƒæ•¸ï¼‰
  python manifest_pinning_tool.py -m mapping.xlsx -d DB2302,DB2575 -v DB2302#3,DB2575#186
  
  # æ··åˆæŒ‡å®šï¼ˆDB2302 ç”¨ç‰ˆæœ¬ 3ï¼ŒDB2575 ç”¨æœ€æ–°ç‰ˆï¼‰
  python manifest_pinning_tool.py -m mapping.xlsx -d DB2302#3,DB2575
  
  # è™•ç†ç‰¹å®šé¡å‹çš„ DB
  python manifest_pinning_tool.py -m mapping.xlsx -t premp -o ./output
  
  # ä½¿ç”¨è‡ªè¨‚ SFTP è¨­å®š
  python manifest_pinning_tool.py -m mapping.xlsx --sftp-host 192.168.1.100 --sftp-user myuser
  
  # è¨­å®šå¹³è¡Œè™•ç†æ•¸é‡
  python manifest_pinning_tool.py -m mapping.xlsx --parallel 8
  
  # é—œé–‰å¹³è¡Œè™•ç†ï¼ˆå¾ªåºè™•ç†ï¼‰
  python manifest_pinning_tool.py -m mapping.xlsx --no-parallel
  
  # å•Ÿç”¨ debug æ¨¡å¼
  python manifest_pinning_tool.py -m mapping.xlsx --debug
        """
    )
    
    # åŸºæœ¬åƒæ•¸
    parser.add_argument('-m', '--mapping', 
                        type=str,
                        help='Mapping table Excel æª”æ¡ˆè·¯å¾‘')
    
    parser.add_argument('-o', '--output', 
                        type=str,
                        help=f'è¼¸å‡ºç›®éŒ„ (é è¨­: {PATH_CONFIG["default_output_dir"]})')
    
    parser.add_argument('-t', '--type',
                        choices=['all', 'master', 'premp', 'mp', 'mpbackup'],
                        default='all',
                        help='è¦è™•ç†çš„ DB é¡å‹ (é è¨­: all)')
    
    parser.add_argument('-d', '--dbs', 
                        type=str,
                        help='è¦è™•ç†çš„ DB åˆ—è¡¨ï¼Œé€—è™Ÿåˆ†éš” (å¯åŒ…å«ç‰ˆæœ¬ï¼Œå¦‚: DB2302#3,DB2575)')
    
    parser.add_argument('-v', '--versions', 
                        type=str,
                        help='DB ç‰ˆæœ¬è¨­å®šï¼Œæ ¼å¼: DB2302#3,DB2575#186')
    
    # SFTP è¨­å®šåƒæ•¸
    parser.add_argument('--sftp-host', 
                        type=str,
                        help=f'SFTP ä¼ºæœå™¨ä½å€ (é è¨­: {SFTP_CONFIG["host"]})')
    
    parser.add_argument('--sftp-port', 
                        type=int,
                        help=f'SFTP é€£æ¥åŸ  (é è¨­: {SFTP_CONFIG["port"]})')
    
    parser.add_argument('--sftp-user', 
                        type=str,
                        help=f'SFTP ä½¿ç”¨è€…åç¨± (é è¨­: {SFTP_CONFIG["username"]})')
    
    parser.add_argument('--sftp-password', 
                        type=str,
                        help='SFTP å¯†ç¢¼')
    
    parser.add_argument('--sftp-timeout', 
                        type=int,
                        help=f'SFTP é€£ç·šé€¾æ™‚ç§’æ•¸ (é è¨­: {SFTP_CONFIG["timeout"]})')
    
    # å¹³è¡Œè™•ç†è¨­å®š
    parser.add_argument('--parallel', 
                        type=int,
                        metavar='N',
                        help=f'å¹³è¡Œè™•ç†çš„ worker æ•¸é‡ (é è¨­: {PARALLEL_CONFIG["max_workers"]})')
    
    parser.add_argument('--no-parallel', 
                        action='store_true',
                        help='é—œé–‰å¹³è¡Œè™•ç†ï¼Œä½¿ç”¨å¾ªåºè™•ç†')
    
    # Repo è¨­å®š
    parser.add_argument('--repo-jobs', 
                        type=int,
                        help=f'repo sync çš„ä¸¦è¡Œæ•¸ (é è¨­: {REPO_CONFIG["sync_jobs"]})')
    
    parser.add_argument('--repo-retry', 
                        type=int,
                        help=f'repo sync å¤±æ•—é‡è©¦æ¬¡æ•¸ (é è¨­: {REPO_CONFIG["sync_retry"]})')
    
    # å…¶ä»–é¸é …
    parser.add_argument('--report-name', 
                        type=str,
                        help=f'å ±å‘Šæª”æ¡ˆåç¨± (é è¨­: {PATH_CONFIG["report_filename"]})')
    
    parser.add_argument('--dry-run', 
                        action='store_true',
                        help='æ¸¬è©¦æ¨¡å¼ï¼Œåªé¡¯ç¤ºå°‡è¦åŸ·è¡Œçš„å‹•ä½œï¼Œä¸å¯¦éš›åŸ·è¡Œ')
    
    parser.add_argument('--debug', 
                        action='store_true',
                        help='å•Ÿç”¨ debug æ¨¡å¼ï¼Œé¡¯ç¤ºè©³ç´°æ—¥èªŒ')
    
    parser.add_argument('--version', 
                        action='version',
                        version='%(prog)s 1.0.0')
    
    # è§£æåƒæ•¸
    args = parser.parse_args()
    
    # ===== è¨­å®šæ—¥èªŒç­‰ç´š =====
    if args.debug:
        LOG_CONFIG['level'] = logging.DEBUG
        # é‡æ–°è¨­å®šæ‰€æœ‰ logger çš„ç­‰ç´š
        logging.getLogger().setLevel(logging.DEBUG)
        for handler in logging.getLogger().handlers:
            handler.setLevel(logging.DEBUG)
        print("ğŸ” Debug æ¨¡å¼å·²å•Ÿç”¨")
    
    # ===== æ›´æ–° SFTP è¨­å®š =====
    if args.sftp_host:
        SFTP_CONFIG['host'] = args.sftp_host
        print(f"ğŸ“¡ SFTP ä¸»æ©Ÿè¨­å®šç‚º: {args.sftp_host}")
    
    if args.sftp_port:
        SFTP_CONFIG['port'] = args.sftp_port
        print(f"ğŸ“¡ SFTP é€£æ¥åŸ è¨­å®šç‚º: {args.sftp_port}")
    
    if args.sftp_user:
        SFTP_CONFIG['username'] = args.sftp_user
        print(f"ğŸ‘¤ SFTP ä½¿ç”¨è€…è¨­å®šç‚º: {args.sftp_user}")
    
    if args.sftp_password:
        SFTP_CONFIG['password'] = args.sftp_password
        print("ğŸ”‘ SFTP å¯†ç¢¼å·²æ›´æ–°")
    
    if args.sftp_timeout:
        SFTP_CONFIG['timeout'] = args.sftp_timeout
        print(f"â±ï¸ SFTP é€¾æ™‚è¨­å®šç‚º: {args.sftp_timeout} ç§’")
    
    # ===== æ›´æ–°å¹³è¡Œè™•ç†è¨­å®š =====
    if args.no_parallel:
        PARALLEL_CONFIG['enable_parallel'] = False
        print("ğŸš¶ å·²é—œé–‰å¹³è¡Œè™•ç†ï¼Œå°‡ä½¿ç”¨å¾ªåºè™•ç†")
    
    if args.parallel:
        PARALLEL_CONFIG['max_workers'] = args.parallel
        PARALLEL_CONFIG['enable_parallel'] = True
        print(f"âš¡ å¹³è¡Œè™•ç† worker æ•¸è¨­å®šç‚º: {args.parallel}")
    
    # ===== æ›´æ–° Repo è¨­å®š =====
    if args.repo_jobs:
        REPO_CONFIG['sync_jobs'] = args.repo_jobs
        print(f"ğŸ”„ Repo sync ä¸¦è¡Œæ•¸è¨­å®šç‚º: {args.repo_jobs}")
    
    if args.repo_retry:
        REPO_CONFIG['sync_retry'] = args.repo_retry
        print(f"ğŸ” Repo sync é‡è©¦æ¬¡æ•¸è¨­å®šç‚º: {args.repo_retry}")
    
    # ===== æª¢æŸ¥æ˜¯å¦ç‚ºæ¸¬è©¦æ¨¡å¼ =====
    if args.dry_run:
        print("\n" + "="*60)
        print("ğŸ§ª æ¸¬è©¦æ¨¡å¼ (Dry Run) - ä¸æœƒå¯¦éš›åŸ·è¡Œä»»ä½•æ“ä½œ")
        print("="*60)
    
    # ===== æ±ºå®šåŸ·è¡Œæ¨¡å¼ =====
    if args.mapping:
        # å‘½ä»¤åˆ—æ¨¡å¼
        print("\n" + "="*60)
        print("ğŸ“‹ Manifest å®šç‰ˆå·¥å…· - å‘½ä»¤åˆ—æ¨¡å¼")
        print("="*60)
        
        # å»ºç«‹å·¥å…·å¯¦ä¾‹
        tool = ManifestPinningTool()
        
        # å¦‚æœæ˜¯æ¸¬è©¦æ¨¡å¼ï¼Œè¨­å®šæ¨™è¨˜
        if args.dry_run:
            tool.dry_run = True
        
        try:
            # Step 1: è¼‰å…¥ mapping table
            print(f"\nğŸ“‚ è¼‰å…¥ mapping table: {args.mapping}")
            if not os.path.exists(args.mapping):
                print(f"âŒ æª”æ¡ˆä¸å­˜åœ¨: {args.mapping}")
                sys.exit(1)
            
            if not tool.load_mapping_table(args.mapping):
                print("âŒ ç„¡æ³•è¼‰å…¥ mapping table")
                sys.exit(1)
            
            print(f"âœ… æˆåŠŸè¼‰å…¥ mapping table")
            
            # Step 2: è¨­å®šè¼¸å‡ºç›®éŒ„
            tool.output_dir = args.output or PATH_CONFIG['default_output_dir']
            os.makedirs(tool.output_dir, exist_ok=True)
            print(f"ğŸ“ è¼¸å‡ºç›®éŒ„: {tool.output_dir}")
            
            # Step 3: è¨­å®šå ±å‘Šæª”å
            if args.report_name:
                PATH_CONFIG['report_filename'] = args.report_name
                print(f"ğŸ“Š å ±å‘Šæª”å: {args.report_name}")
            
            # Step 4: é€£ç·šåˆ° SFTP
            print(f"\nğŸŒ é€£ç·šåˆ° SFTP ä¼ºæœå™¨: {SFTP_CONFIG['host']}")
            if not tool.sftp_manager.connect():
                print("âŒ ç„¡æ³•é€£ç·šåˆ° SFTP ä¼ºæœå™¨")
                sys.exit(1)
            print("âœ… SFTP é€£ç·šæˆåŠŸ")
            
            try:
                # Step 5: æ±ºå®šè¦è™•ç†çš„ DB åˆ—è¡¨
                db_list = []
                db_versions = {}
                
                if args.dbs:
                    # ä½¿ç”¨æŒ‡å®šçš„ DB
                    db_specs = [db.strip() for db in args.dbs.split(',')]
                    
                    for db_spec in db_specs:
                        if '#' in db_spec:
                            # DB åç¨±åŒ…å«ç‰ˆæœ¬
                            db_name, version = db_spec.split('#', 1)
                            db_list.append(db_name)
                            db_versions[db_name] = version
                        else:
                            db_list.append(db_spec)
                    
                    print(f"\nğŸ“Œ ä½¿ç”¨æŒ‡å®šçš„ DB åˆ—è¡¨: {', '.join(db_list)}")
                else:
                    # ä½¿ç”¨æ‰€æœ‰æŒ‡å®šé¡å‹çš„ DB
                    all_db_infos = tool.get_all_dbs(args.type)
                    db_list = list(set([db.db_info for db in all_db_infos]))
                    
                    if args.type == 'all':
                        print(f"\nğŸ“Œ ä½¿ç”¨æ‰€æœ‰ DBï¼Œå…± {len(db_list)} å€‹")
                    else:
                        print(f"\nğŸ“Œ ä½¿ç”¨æ‰€æœ‰ {args.type} é¡å‹çš„ DBï¼Œå…± {len(db_list)} å€‹")
                
                # Step 6: è™•ç†é¡å¤–çš„ç‰ˆæœ¬è¨­å®š
                if args.versions:
                    version_specs = [v.strip() for v in args.versions.split(',')]
                    for version_spec in version_specs:
                        if '#' in version_spec:
                            db_name, version = version_spec.split('#', 1)
                            db_versions[db_name] = version
                    
                    print(f"ğŸ“Œ è¨­å®šäº† {len(db_versions)} å€‹ DB çš„ç‰ˆæœ¬")
                
                # Step 7: ç¢ºèªè™•ç†è³‡è¨Š
                print("\n" + "-"*40)
                print("ğŸ“‹ æº–å‚™è™•ç†ä»¥ä¸‹ DB:")
                for i, db in enumerate(db_list, 1):
                    version_info = f" (ç‰ˆæœ¬: {db_versions[db]})" if db in db_versions else " (æœ€æ–°ç‰ˆæœ¬)"
                    print(f"  {i:3d}. {db}{version_info}")
                print("-"*40)
                
                if not db_list:
                    print("âŒ æ²’æœ‰æ‰¾åˆ°è¦è™•ç†çš„ DB")
                    sys.exit(1)
                
                # Step 8: è©¢å•ç¢ºèªï¼ˆé™¤éæ˜¯æ¸¬è©¦æ¨¡å¼ï¼‰
                if not args.dry_run:
                    if sys.stdin.isatty():  # æª¢æŸ¥æ˜¯å¦åœ¨äº’å‹•å¼ç’°å¢ƒ
                        confirm = input(f"\nç¢ºèªè¦è™•ç† {len(db_list)} å€‹ DB? (Y/n): ").strip().lower()
                        if confirm == 'n':
                            print("âŒ ä½¿ç”¨è€…å–æ¶ˆæ“ä½œ")
                            sys.exit(0)
                
                # Step 9: é–‹å§‹è™•ç†
                print("\n" + "="*60)
                if args.dry_run:
                    print("ğŸ§ª é–‹å§‹æ¸¬è©¦åŸ·è¡Œï¼ˆä¸æœƒå¯¦éš›åŸ·è¡Œæ“ä½œï¼‰")
                else:
                    print("ğŸš€ é–‹å§‹åŸ·è¡Œå®šç‰ˆè™•ç†")
                print("="*60)
                
                start_time = datetime.now()
                
                # åŸ·è¡Œè™•ç†
                tool.process_selected_dbs(db_list, db_versions)
                
                end_time = datetime.now()
                elapsed_time = end_time - start_time
                
                # Step 10: ç”¢ç”Ÿå ±å‘Š
                print("\nğŸ“Š ç”¢ç”Ÿè™•ç†å ±å‘Š...")
                report_path = os.path.join(tool.output_dir, PATH_CONFIG['report_filename'])
                tool.generate_report(report_path)
                
                # Step 11: é¡¯ç¤ºçµæœæ‘˜è¦
                print("\n" + "="*60)
                print("âœ¨ è™•ç†å®Œæˆï¼")
                print("="*60)
                print(f"ğŸ“Š ç¸½ DB æ•¸: {tool.report.total_dbs}")
                print(f"âœ… æˆåŠŸ: {tool.report.successful_dbs}")
                print(f"âŒ å¤±æ•—: {tool.report.failed_dbs}")
                print(f"â­ï¸ è·³é: {tool.report.skipped_dbs}")
                print(f"â±ï¸ ç¸½è€—æ™‚: {elapsed_time}")
                print(f"ğŸ“ è¼¸å‡ºç›®éŒ„: {tool.output_dir}")
                print(f"ğŸ“Š å ±å‘Šæª”æ¡ˆ: {report_path}")
                print("="*60)
                
                # å¦‚æœæœ‰å¤±æ•—çš„é …ç›®ï¼Œé¡¯ç¤ºè©³ç´°è³‡è¨Š
                if tool.report.failed_dbs > 0:
                    print("\nâŒ å¤±æ•—çš„ DB:")
                    for db in tool.report.db_details:
                        if db.status == 'failed':
                            print(f"  - {db.module}/{db.db_info}: {db.error_message}")
                
            finally:
                # ç¢ºä¿é—œé–‰ SFTP é€£ç·š
                print("\nğŸ”Œ é—œé–‰ SFTP é€£ç·š...")
                tool.sftp_manager.disconnect()
                
        except KeyboardInterrupt:
            print("\n\nâš ï¸ ä½¿ç”¨è€…ä¸­æ–·åŸ·è¡Œ")
            sys.exit(130)  # 128 + SIGINT
            
        except Exception as e:
            print(f"\nâŒ ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            if args.debug:
                import traceback
                traceback.print_exc()
            sys.exit(1)
    
    else:
        # äº’å‹•å¼æ¨¡å¼
        print("\n" + "="*60)
        print("ğŸ® Manifest å®šç‰ˆå·¥å…· - äº’å‹•å¼ä»‹é¢")
        print("="*60)
        print("æç¤º: ä½¿ç”¨ -h åƒæ•¸æŸ¥çœ‹å‘½ä»¤åˆ—é¸é …")
        print("="*60)
        
        try:
            # å»ºç«‹ä¸¦åŸ·è¡Œäº’å‹•å¼ä»‹é¢
            ui = InteractiveUI()
            
            # å¦‚æœæœ‰è¨­å®šåƒæ•¸ï¼Œå‚³éçµ¦ UI
            if args.output:
                ui.tool.output_dir = args.output
            
            if args.dry_run:
                ui.tool.dry_run = True
                print("ğŸ§ª æ¸¬è©¦æ¨¡å¼å·²å•Ÿç”¨")
            
            # åŸ·è¡Œäº’å‹•å¼ä»‹é¢
            ui.run_interactive()
            
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ å†è¦‹ï¼")
            sys.exit(0)
            
        except Exception as e:
            print(f"\nâŒ ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            if args.debug:
                import traceback
                traceback.print_exc()
            sys.exit(1)

if __name__ == "__main__":
    main()